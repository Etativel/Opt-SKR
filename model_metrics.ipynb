{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['PNEUMONIA', 'NORMAL']\n",
    "img_size = 150\n",
    "def get_training_data(data_dir):\n",
    "    data = [] \n",
    "    for label in labels: \n",
    "        path = os.path.join(data_dir, label)\n",
    "        class_num = labels.index(label)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size\n",
    "                data.append([resized_arr, class_num])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_11228\\771166761.py:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(data)\n"
     ]
    }
   ],
   "source": [
    "train = get_training_data('../data/train')      \n",
    "test = get_training_data('../data/test')\n",
    "val = get_training_data('../data/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n",
      "g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\seaborn\\_core.py:1478: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  order = pd.unique(vector)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='count'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l = []\n",
    "for i in train:\n",
    "    if(i[1] == 0):\n",
    "        l.append(\"Pneumonia\")\n",
    "    else:\n",
    "        l.append(\"Normal\")\n",
    "sns.set_style('darkgrid')\n",
    "sns.countplot(l)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "x_val = []\n",
    "y_val = []\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for feature, label in train:\n",
    "    x_train.append(feature)\n",
    "    y_train.append(label)\n",
    "\n",
    "for feature, label in test:\n",
    "    x_test.append(feature)\n",
    "    y_test.append(label)\n",
    "    \n",
    "for feature, label in val:\n",
    "    x_val.append(feature)\n",
    "    y_val.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "x_train = np.array(x_train) / 255\n",
    "x_val = np.array(x_val) / 255\n",
    "x_test = np.array(x_test) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize data for deep learning \n",
    "x_train = x_train.reshape(-1, img_size, img_size, 1)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_val = x_val.reshape(-1, img_size, img_size, 1)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "x_test = x_test.reshape(-1, img_size, img_size, 1)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_11228\\411226287.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(augmented_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count after augmentation: 7069\n"
     ]
    }
   ],
   "source": [
    "def load_augmented_data(augmented_dir, label, img_size):\n",
    "    augmented_data = []\n",
    "    for img in os.listdir(augmented_dir):\n",
    "        try:\n",
    "            img_arr = cv2.imread(os.path.join(augmented_dir, img), cv2.IMREAD_GRAYSCALE)\n",
    "            resized_arr = cv2.resize(img_arr, (img_size, img_size))\n",
    "            augmented_data.append([resized_arr, label])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return np.array(augmented_data)\n",
    "\n",
    "# Define parameters\n",
    "data_dir = '../data/train'  # Adjust this path to your dataset\n",
    "save_dir = '../data/augmented_normal/NORMAL'  # Directory to save augmented images\n",
    "label = 'NORMAL'  # Class label to augment\n",
    "img_size = 150  # Image size (adjust if different)\n",
    "additional_images_needed = 2690  # Number of additional images needed\n",
    "batch_size = 32  # Number of images to generate per original image\n",
    "\n",
    "# Perform augmentation\n",
    "# augment_images(data_dir, save_dir, label, img_size, additional_images_needed, batch_size)\n",
    "\n",
    "# Load augmented 'Normal' images (assuming label for 'Normal' is 1)\n",
    "augmented_normal_data = load_augmented_data(save_dir, label=1, img_size=img_size)\n",
    "\n",
    "# Convert to appropriate format and normalize\n",
    "x_augmented_normal = np.array([i[0] for i in augmented_normal_data]) / 255\n",
    "x_augmented_normal = x_augmented_normal.reshape(-1, img_size, img_size, 1)\n",
    "y_augmented_normal = np.array([i[1] for i in augmented_normal_data])\n",
    "\n",
    "# Append to existing training data\n",
    "x_train = np.concatenate((x_train, x_augmented_normal), axis=0)\n",
    "y_train = np.concatenate((y_train, y_augmented_normal), axis=0)\n",
    "\n",
    "# Shuffle the dataset\n",
    "indices = np.arange(x_train.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "x_train = x_train[indices]\n",
    "y_train = y_train[indices]\n",
    "\n",
    "# Count after augmentation\n",
    "print(\"Count after augmentation:\", len(x_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train All Best Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=[[14,46,62,2,5,7],\n",
    "# [29,45,88,4,4,5],\n",
    "# [29,45,70,4,4,13],\n",
    "# [29,45,70,4,4,13],\n",
    "# [15,48,88,3,5,5],\n",
    "# [15,48,88,3,5,5],\n",
    "# [15,48,88,3,5,5],\n",
    "# [15,48,88,3,5,5],\n",
    "# [15,48,88,3,5,5],\n",
    "# [15,48,88,3,5,5],\n",
    "# [15,48,88,3,5,5],\n",
    "# [33,47,73,4,8,20],\n",
    "# [33,47,73,4,8,20],\n",
    "# [35,36,75,4,6,19],\n",
    "# [35,36,75,4,6,19],\n",
    "# [35,36,75,4,6,19],\n",
    "# [35,36,75,4,6,19],\n",
    "# [35,36,75,4,6,19],\n",
    "# [35,36,75,4,6,19],\n",
    "# [35,36,75,4,6,19],\n",
    "# [35,36,75,4,6,19],\n",
    "# [35,36,75,4,6,19],\n",
    "# [40,44,84,5,13,20],\n",
    "# [44,36,84,4,8,18],\n",
    "# [44,36,84,4,8,18],\n",
    "# [44,36,84,4,8,18],\n",
    "# [44,36,84,4,8,18],\n",
    "# [44,36,84,4,8,18],\n",
    "# [44,36,84,4,8,18],\n",
    "# [45,37,85,4,10,20],\n",
    "# [45,37,85,4,10,20],\n",
    "# [45,37,85,4,10,20],\n",
    "# [45,37,85,4,10,20],\n",
    "# [45,37,85,4,10,20],\n",
    "# [45,37,85,4,10,20],\n",
    "# [45,37,85,4,10,20],\n",
    "# [45,37,85,4,10,20],\n",
    "# [45,37,85,4,10,20],\n",
    "# [45,37,85,4,10,20],\n",
    "# [45,37,85,4,10,20],\n",
    "# [45,37,85,4,10,20],\n",
    "# [45,37,85,4,10,20],\n",
    "# [54,44,87,8,14,20],\n",
    "# [54,41,92,6,16,20],\n",
    "# [60,46,87,4,15,20],\n",
    "# [58,41,97,6,14,20],\n",
    "# [58,41,97,6,14,20],\n",
    "# [58,41,97,6,14,20],\n",
    "# [60,47,92,5,14,16],\n",
    "# [60,47,92,5,14,16]]\n",
    "\n",
    "model = [[14, 46, 62, 2, 5, 7],\n",
    " [29, 45, 88, 4, 4, 5],\n",
    " [29, 45, 70, 4, 4, 13],\n",
    " [15, 48, 88, 3, 5, 5],\n",
    " [33, 47, 73, 4, 8, 20],\n",
    " [35, 36, 75, 4, 6, 19],\n",
    " [40, 44, 84, 5, 13, 20],\n",
    " [44, 36, 84, 4, 8, 18],\n",
    " [45, 37, 85, 4, 10, 20],\n",
    " [54, 44, 87, 8, 14, 20],\n",
    " [54, 41, 92, 6, 16, 20],\n",
    " [60, 46, 87, 4, 15, 20],\n",
    " [58, 41, 97, 6, 14, 20],\n",
    " [60, 47, 92, 5, 14, 16]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clahe=[[29,45,75,4,4,5],\n",
    "        [29,45,75,4,4,5],\n",
    "        [29,45,75,4,4,5],\n",
    "        [29,45,75,4,4,5],\n",
    "        [29,45,75,4,4,5],\n",
    "        [32,49,75,5,4,5],\n",
    "        [32,49,75,5,4,5],\n",
    "        [32,49,75,5,4,5],\n",
    "        [32,49,75,5,4,5],\n",
    "        [38,47,79,4,5,13],\n",
    "        [37,47,77,4,4,11],\n",
    "        [41,47,82,4,4,16],\n",
    "        [40,47,79,4,4,13],\n",
    "        [40,47,79,4,4,13],\n",
    "        [40,47,79,4,4,13],\n",
    "        [32,56,80,4,4,18],\n",
    "        [32,56,80,4,4,18],\n",
    "        [32,56,80,4,4,18],\n",
    "        [32,56,80,4,4,18],\n",
    "        [35,59,80,4,7,17],\n",
    "        [35,59,80,4,7,17],\n",
    "        [37,59,80,4,7,15],\n",
    "        [38,61,83,4,9,18],\n",
    "        [38,61,83,4,9,18],\n",
    "        [38,61,83,4,9,18],\n",
    "        [38,61,83,4,9,18],\n",
    "        [38,61,97,4,9,18],\n",
    "        [38,61,97,4,9,18],\n",
    "        [38,61,97,4,9,18],\n",
    "        [38,61,98,4,9,16],\n",
    "        [38,61,98,4,9,16],\n",
    "        [38,61,98,4,9,16],\n",
    "        [44,65,83,11,9,20],\n",
    "        [44,65,83,11,9,20],\n",
    "        [44,65,83,11,9,20],\n",
    "        [44,65,83,11,9,20],\n",
    "        [44,65,83,11,9,20],\n",
    "        [44,65,83,11,9,20],\n",
    "        [44,65,83,11,9,20],\n",
    "        [44,65,83,11,9,20],\n",
    "        [44,65,83,11,9,20],\n",
    "        [44,65,83,11,9,20],\n",
    "        [41,66,97,7,10,19],\n",
    "        [41,66,97,7,10,19],\n",
    "        [41,66,97,7,10,19],\n",
    "        [43,73,100,14,17,19],\n",
    "        [43,73,100,14,17,19],\n",
    "        [43,73,100,14,17,19],\n",
    "        [43,73,100,14,17,19],\n",
    "        [43,73,100,14,17,19],\n",
    "        [43,73,100,14,17,19],\n",
    "        [43,73,100,14,17,19],\n",
    "        [43,73,100,14,17,19]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[29, 45, 75, 4, 4, 5],\n",
       " [32, 49, 75, 5, 4, 5],\n",
       " [38, 47, 79, 4, 5, 13],\n",
       " [37, 47, 77, 4, 4, 11],\n",
       " [41, 47, 82, 4, 4, 16],\n",
       " [40, 47, 79, 4, 4, 13],\n",
       " [32, 56, 80, 4, 4, 18],\n",
       " [35, 59, 80, 4, 7, 17],\n",
       " [37, 59, 80, 4, 7, 15],\n",
       " [38, 61, 83, 4, 9, 18],\n",
       " [38, 61, 97, 4, 9, 18],\n",
       " [38, 61, 98, 4, 9, 16],\n",
       " [44, 65, 83, 11, 9, 20],\n",
       " [41, 66, 97, 7, 10, 19],\n",
       " [43, 73, 100, 14, 17, 19]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seen = set()\n",
    "result = []\n",
    "\n",
    "for sublist in model_clahe:\n",
    "    # Convert the sublist to a tuple to be able to use it in a set\n",
    "    tuple_version = tuple(sublist)\n",
    "    \n",
    "    # Only add the sublist to the result if it hasn't been seen\n",
    "    if tuple_version not in seen:\n",
    "        result.append(sublist)\n",
    "        seen.add(tuple_version)\n",
    "\n",
    "# Print the result\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification_accuracy = (TP + TN) / float(TP + TN + FP + FN)\n",
    "# classification_error = (FP + FN) / float(TP + TN + FP + FN)\n",
    "# precision = TP / float(TP + FP)\n",
    "# recall = TP / float(TP + FN)\n",
    "# true_positive_rate = TP / float(TP + FN)\n",
    "# false_positive_rate = FP / float(FP + TN)\n",
    "# specificity = TN / (TN + FP)\n",
    "# F1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "True_Positive = []\n",
    "True_Negative = []\n",
    "False_Positive = []\n",
    "False_negative = []\n",
    "acc = []\n",
    "error = []\n",
    "precision = []\n",
    "recall = []\n",
    "TP_rate = []\n",
    "FP_rate = []\n",
    "specificity = []\n",
    "wrong_prediction = []\n",
    "F1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 150, 150, 14)      70        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 75, 75, 14)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 75, 75, 46)        16146     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 75, 75, 46)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 38, 38, 46)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 38, 38, 62)        139810    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 38, 38, 62)        0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 19, 19, 62)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 22382)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               2865024   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,021,179\n",
      "Trainable params: 3,021,179\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "111/111 [==============================] - 13s 76ms/step - loss: 0.3339 - accuracy: 0.8310 - val_loss: 0.1723 - val_accuracy: 0.9316 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "111/111 [==============================] - 7s 66ms/step - loss: 0.1452 - accuracy: 0.9485 - val_loss: 0.1494 - val_accuracy: 0.9504 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "111/111 [==============================] - 7s 67ms/step - loss: 0.1144 - accuracy: 0.9587 - val_loss: 0.1291 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "111/111 [==============================] - 7s 67ms/step - loss: 0.0967 - accuracy: 0.9651 - val_loss: 0.1208 - val_accuracy: 0.9573 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "111/111 [==============================] - 7s 66ms/step - loss: 0.0930 - accuracy: 0.9668 - val_loss: 0.1183 - val_accuracy: 0.9590 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "111/111 [==============================] - 7s 67ms/step - loss: 0.0704 - accuracy: 0.9747 - val_loss: 0.1353 - val_accuracy: 0.9419 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "110/111 [============================>.] - ETA: 0s - loss: 0.0648 - accuracy: 0.9768\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "111/111 [==============================] - 7s 67ms/step - loss: 0.0646 - accuracy: 0.9769 - val_loss: 0.1295 - val_accuracy: 0.9538 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "111/111 [==============================] - 7s 67ms/step - loss: 0.0432 - accuracy: 0.9843 - val_loss: 0.0767 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
      "Epoch 9/10\n",
      "111/111 [==============================] - 7s 67ms/step - loss: 0.0374 - accuracy: 0.9868 - val_loss: 0.0921 - val_accuracy: 0.9675 - lr: 3.0000e-04\n",
      "Epoch 10/10\n",
      "111/111 [==============================] - 8s 68ms/step - loss: 0.0347 - accuracy: 0.9885 - val_loss: 0.0742 - val_accuracy: 0.9761 - lr: 3.0000e-04\n",
      "19/19 [==============================] - 1s 17ms/step\n",
      "############################### Model number 0 finished ###############################\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 150, 150, 29)      493       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 75, 75, 29)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 75, 75, 45)        20925     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 75, 75, 45)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 38, 38, 45)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 38, 38, 88)        99088     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 38, 38, 88)        0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 19, 19, 88)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 31768)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               4066432   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,187,067\n",
      "Trainable params: 4,187,067\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "111/111 [==============================] - 11s 86ms/step - loss: 0.3702 - accuracy: 0.8205 - val_loss: 0.2467 - val_accuracy: 0.9145 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "111/111 [==============================] - 8s 75ms/step - loss: 0.1279 - accuracy: 0.9530 - val_loss: 0.1470 - val_accuracy: 0.9504 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "111/111 [==============================] - 8s 74ms/step - loss: 0.1077 - accuracy: 0.9638 - val_loss: 0.1208 - val_accuracy: 0.9538 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "111/111 [==============================] - 8s 75ms/step - loss: 0.0984 - accuracy: 0.9653 - val_loss: 0.1105 - val_accuracy: 0.9692 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "111/111 [==============================] - 8s 75ms/step - loss: 0.0754 - accuracy: 0.9720 - val_loss: 0.1594 - val_accuracy: 0.9350 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "110/111 [============================>.] - ETA: 0s - loss: 0.0752 - accuracy: 0.9736\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "111/111 [==============================] - 8s 75ms/step - loss: 0.0753 - accuracy: 0.9735 - val_loss: 0.1192 - val_accuracy: 0.9573 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "111/111 [==============================] - 8s 75ms/step - loss: 0.0506 - accuracy: 0.9812 - val_loss: 0.0908 - val_accuracy: 0.9709 - lr: 3.0000e-04\n",
      "Epoch 8/10\n",
      "111/111 [==============================] - 8s 76ms/step - loss: 0.0430 - accuracy: 0.9851 - val_loss: 0.1096 - val_accuracy: 0.9607 - lr: 3.0000e-04\n",
      "Epoch 9/10\n",
      "111/111 [==============================] - 8s 75ms/step - loss: 0.0377 - accuracy: 0.9857 - val_loss: 0.0850 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
      "Epoch 10/10\n",
      "111/111 [==============================] - 8s 76ms/step - loss: 0.0333 - accuracy: 0.9874 - val_loss: 0.0968 - val_accuracy: 0.9641 - lr: 3.0000e-04\n",
      "19/19 [==============================] - 1s 21ms/step\n",
      "############################### Model number 1 finished ###############################\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 150, 150, 29)      493       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 75, 75, 29)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 75, 75, 45)        20925     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 75, 75, 45)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 38, 38, 45)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 38, 38, 70)        532420    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 38, 38, 70)        0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 19, 19, 70)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25270)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               3234688   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,788,655\n",
      "Trainable params: 3,788,655\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "111/111 [==============================] - 19s 147ms/step - loss: 0.3387 - accuracy: 0.8302 - val_loss: 0.1482 - val_accuracy: 0.9624 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "  2/111 [..............................] - ETA: 14s - loss: 0.1398 - accuracy: 0.9453"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'gradient_tape/sequential/max_pooling2d/MaxPool/MaxPoolGrad' defined at (most recent call last):\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 359, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 446, in do_execute\n      res = shell.run_cell(\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_11228\\1282362333.py\", line 31, in <module>\n      model.fit(x_train, y_train, batch_size=64, epochs=10, validation_data=(x_val, y_val), callbacks=[learning_rate_reduction])\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 997, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 576, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 634, in _compute_gradients\n      grads_and_vars = self._get_gradients(\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 510, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/sequential/max_pooling2d/MaxPool/MaxPoolGrad'\nOOM when allocating tensor with shape[64,29,150,150] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/sequential/max_pooling2d/MaxPool/MaxPoolGrad}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_14293]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[0;32m     30\u001b[0m learning_rate_reduction \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.000001\u001b[39m)\n\u001b[1;32m---> 31\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlearning_rate_reduction\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(x_test)\n\u001b[0;32m     34\u001b[0m predictions \u001b[38;5;241m=\u001b[39m predictions\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mg:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mg:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'gradient_tape/sequential/max_pooling2d/MaxPool/MaxPoolGrad' defined at (most recent call last):\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 359, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 446, in do_execute\n      res = shell.run_cell(\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_11228\\1282362333.py\", line 31, in <module>\n      model.fit(x_train, y_train, batch_size=64, epochs=10, validation_data=(x_val, y_val), callbacks=[learning_rate_reduction])\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 997, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 576, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 634, in _compute_gradients\n      grads_and_vars = self._get_gradients(\n    File \"g:\\Anaconda\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 510, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/sequential/max_pooling2d/MaxPool/MaxPoolGrad'\nOOM when allocating tensor with shape[64,29,150,150] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/sequential/max_pooling2d/MaxPool/MaxPoolGrad}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_14293]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.backend import clear_session\n",
    "import pandas as pd\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "   x = tf.convert_to_tensor(x_train, np.float32)\n",
    "   y = tf.convert_to_tensor(y_train, np.float32)\n",
    "\n",
    "counter = 0\n",
    "for bestParam in model:\n",
    "    with tf.device('/gpu:0'):  # Ensure using GPU\n",
    "        clear_session()  # Clear the previous model from the session\n",
    "        model = Sequential([\n",
    "            Conv2D(bestParam[0], (bestParam[3], bestParam[3]), strides=1, padding='same', activation='relu', input_shape=(150, 150, 1)),\n",
    "            MaxPool2D((2, 2), strides=2, padding='same'),\n",
    "            Conv2D(bestParam[1], (bestParam[4], bestParam[4]), strides=1, padding='same', activation='relu'),\n",
    "            Dropout(0.1),\n",
    "            MaxPool2D((2, 2), strides=2, padding='same'),\n",
    "            Conv2D(bestParam[2], (bestParam[5], bestParam[5]), strides=1, padding='same', activation='relu'),\n",
    "            Dropout(0.2),\n",
    "            MaxPool2D((2, 2), strides=2, padding='same'),\n",
    "            Flatten(),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dropout(0.2),\n",
    "            Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        model.summary()\n",
    "\n",
    "        learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=2, verbose=1, factor=0.3, min_lr=0.000001)\n",
    "        model.fit(x_train, y_train, batch_size=64, epochs=10, validation_data=(x_val, y_val), callbacks=[learning_rate_reduction])\n",
    "\n",
    "        predictions = model.predict(x_test)\n",
    "        predictions = predictions.reshape(1,-1)[0]\n",
    "        predictions[:15]\n",
    "\n",
    "\n",
    "\n",
    "        # Predictions are probabilities, convert them to binary labels\n",
    "        binary_predictions = [1 if i > 0.5 else 0 for i in predictions]\n",
    "        cm = confusion_matrix(y_test,binary_predictions)\n",
    "        TP = cm[0][0]  # True Positives\n",
    "        TN = cm[1][1]  # True Negatives\n",
    "        FP = cm[0][1]  # False Positives\n",
    "        FN = cm[1][0]  # False Negatives\n",
    "        classification_accuracy = (TP + TN) / float(TP + TN + FP + FN)\n",
    "        classification_error = (FP + FN) / float(TP + TN + FP + FN)\n",
    "        precision_calc = TP / float(TP + FP)\n",
    "        recall_calc = TP / float(TP + FN)\n",
    "        true_positive_rate = TP / float(TP + FN)\n",
    "        false_positive_rate = FP / float(FP + TN)\n",
    "        specificity_calc = TN / (TN + FP)\n",
    "        F1_score = 2 * (precision_calc * recall_calc) / (precision_calc + recall_calc)\n",
    "        wrong_calc = FN + FP\n",
    "\n",
    "        True_Positive.append(TP)\n",
    "        True_Negative.append(TN)\n",
    "        False_Positive.append(FP)\n",
    "        False_negative.append(FN)\n",
    "        acc.append(classification_accuracy)\n",
    "        error.append(classification_error)\n",
    "        precision.append(precision_calc)\n",
    "        recall.append(recall_calc)\n",
    "        TP_rate.append(true_positive_rate)\n",
    "        FP_rate.append(false_positive_rate)\n",
    "        specificity.append(specificity_calc)\n",
    "        F1.append(F1_score)\n",
    "        wrong_prediction.append(wrong_calc)\n",
    "\n",
    "        print(f'############################### Model number {counter} finished ###############################')\n",
    "        counter+=1\n",
    "\n",
    "        df = {\n",
    "            'TP': True_Positive,\n",
    "            'TN': True_Negative,\n",
    "            'FP': False_Positive,\n",
    "            'FN': False_negative,\n",
    "            'acc': acc,\n",
    "            'error': error,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'TP_rate': TP_rate,\n",
    "            'FP_rate': FP_rate,\n",
    "            'specificity': specificity,\n",
    "            'F1_score': F1,\n",
    "            'wrong_prediction' : wrong_prediction\n",
    "        }\n",
    "\n",
    "        df = pd.DataFrame(df)\n",
    "        df.to_csv('model_metrics.csv', index=False)\n",
    "        df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

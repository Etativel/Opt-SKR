{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkg0vp6jXd1d",
        "outputId": "dbfba486-5438-4b5f-df33-5dec5a31f7e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install numpy==1.23.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwY50_LoWenh",
        "outputId": "87b61f92-535e-4901-f380-acdbed804ac1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.23.3 in /usr/local/lib/python3.10/dist-packages (1.23.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "uGW37YG_YGv3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau\n"
      ],
      "metadata": {
        "id": "UrYrsk1Jx7sk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.config.list_physical_devices())\n",
        "print(np.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tarGtwEQx-zP",
        "outputId": "e82f1c53-766b-44a0-a337-3b6d4c7f3dc4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "1.23.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olEUAG-vyAe6",
        "outputId": "6741b6b6-b740-4645-ddee-421154e87086"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['PNEUMONIA', 'NORMAL']\n",
        "img_size = 150\n",
        "def get_training_data(data_dir):\n",
        "    data = []\n",
        "    for label in labels:\n",
        "        path = os.path.join(data_dir, label)\n",
        "        class_num = labels.index(label)\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
        "                resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size\n",
        "                data.append([resized_arr, class_num])\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "    return np.array(data,dtype=\"object\")"
      ],
      "metadata": {
        "id": "wHWQkxXoyAcR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = get_training_data('/content/drive/MyDrive/pneumonia_data/train')\n",
        "test = get_training_data('/content/drive/MyDrive/pneumonia_data/test')\n",
        "val = get_training_data('/content/drive/MyDrive/pneumonia_data/val')"
      ],
      "metadata": {
        "id": "wlcNm95xyAZg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l = []\n",
        "for i in train:\n",
        "    if(i[1] == 0):\n",
        "        l.append(\"Pneumonia\")\n",
        "    else:\n",
        "        l.append(\"Normal\")\n",
        "sns.set_style('darkgrid')\n",
        "sns.countplot(l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "4HheQUBSyAWv",
        "outputId": "b2f2c666-e69a-4ccd-9426-4dadf1e910ad"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='count'>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (5,5))\n",
        "plt.imshow(train[0][0], cmap='gray')\n",
        "plt.title(labels[train[0][1]])\n",
        "\n",
        "plt.figure(figsize = (5,5))\n",
        "plt.imshow(train[-1][0], cmap='gray')\n",
        "plt.title(labels[train[-1][1]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 936
        },
        "id": "VH5DbBmVyAUA",
        "outputId": "9167682f-6512-4636-c211-3e131d3d307a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'NORMAL')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "x_val = []\n",
        "y_val = []\n",
        "\n",
        "x_test = []\n",
        "y_test = []\n",
        "\n",
        "for feature, label in train:\n",
        "    x_train.append(feature)\n",
        "    y_train.append(label)\n",
        "\n",
        "for feature, label in test:\n",
        "    x_test.append(feature)\n",
        "    y_test.append(label)\n",
        "\n",
        "for feature, label in val:\n",
        "    x_val.append(feature)\n",
        "    y_val.append(label)"
      ],
      "metadata": {
        "id": "_67s-egRyARQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the data\n",
        "x_train = np.array(x_train) / 255\n",
        "x_val = np.array(x_val) / 255\n",
        "x_test = np.array(x_test) / 255"
      ],
      "metadata": {
        "id": "IuhS_8MtyAOa"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# resize data for deep learning\n",
        "x_train = x_train.reshape(-1, img_size, img_size, 1)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "x_val = x_val.reshape(-1, img_size, img_size, 1)\n",
        "y_val = np.array(y_val)\n",
        "\n",
        "x_test = x_test.reshape(-1, img_size, img_size, 1)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "print(\"Count before augmentation:\", len(x_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bayWbAebyALa",
        "outputId": "0924adf9-2ec1-47e1-f2f0-74e0b54784c2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count before augmentation: 4684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pq0jhyTN1G0L",
        "outputId": "6b2f8b1b-32d6-4ac6-c99c-64e2aef5ab43"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.23.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install numpy==1.23.3"
      ],
      "metadata": {
        "id": "eoj7bfNl1O5S"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_augmented_data(augmented_dir, label, img_size):\n",
        "    augmented_data = []\n",
        "    for img in os.listdir(augmented_dir):\n",
        "        try:\n",
        "            img_arr = cv2.imread(os.path.join(augmented_dir, img), cv2.IMREAD_GRAYSCALE)\n",
        "            resized_arr = cv2.resize(img_arr, (img_size, img_size))\n",
        "            augmented_data.append([resized_arr, label])\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "    return np.array(augmented_data)\n",
        "\n",
        "# Define parameters\n",
        "save_dir = '/content/drive/MyDrive/pneumonia_data/augmented_normal/NORMAL'  # Directory to save augmented images\n",
        "label = 'NORMAL'  # Class label to augment\n",
        "img_size = 150  # Image size (adjust if different)\n",
        "additional_images_needed = 2690  # Number of additional images needed\n",
        "batch_size = 32  # Number of images to generate per original image\n",
        "\n",
        "# Load augmented 'Normal' images (assuming label for 'Normal' is 1)\n",
        "augmented_normal_data = load_augmented_data(save_dir, label=1, img_size=img_size)\n",
        "\n",
        "# Convert to appropriate format and normalize\n",
        "x_augmented_normal = np.array([i[0] for i in augmented_normal_data]) / 255\n",
        "x_augmented_normal = x_augmented_normal.reshape(-1, img_size, img_size, 1)\n",
        "y_augmented_normal = np.array([i[1] for i in augmented_normal_data])\n",
        "\n",
        "# Append to existing training data\n",
        "x_train = np.concatenate((x_train, x_augmented_normal), axis=0)\n",
        "y_train = np.concatenate((y_train, y_augmented_normal), axis=0)\n",
        "\n",
        "# Shuffle the dataset\n",
        "indices = np.arange(x_train.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "x_train = x_train[indices]\n",
        "y_train = y_train[indices]\n",
        "\n",
        "# Count after augmentation\n",
        "print(\"Count after augmentation:\", len(x_train))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCqCJYmgyADg",
        "outputId": "d287d0c4-40af-4dd3-8616-a6997a239d84"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-a42946c7df30>:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  return np.array(augmented_data)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count after augmentation: 7069\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimization"
      ],
      "metadata": {
        "id": "FaD5knv9zW24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "class CNN(Sequential):\n",
        "    def __init__(self, nfilters, sfilters):\n",
        "        super().__init__()\n",
        "        tf.random.set_seed(0)\n",
        "        self.add(Conv2D(nfilters[0], kernel_size=(sfilters[0], sfilters[0]), padding='same', activation='relu', input_shape=(150, 150, 1)))\n",
        "        self.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "        self.add(Conv2D(nfilters[1], kernel_size=(sfilters[1], sfilters[1]), padding='same', activation='relu'))\n",
        "        self.add(Dropout(0.1))\n",
        "        self.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "        self.add(Conv2D(nfilters[2], kernel_size=(sfilters[2], sfilters[2]), padding='same', activation='relu'))\n",
        "        self.add(Dropout(0.2))\n",
        "        self.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "        self.add(Flatten())\n",
        "        self.add(Dropout(0.2))\n",
        "        self.add(Dense(128, activation='relu'))\n",
        "        self.add(Dense(units=1, activation='sigmoid'))\n",
        "        self.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "fE1lZUq5y_Dy"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Genetic:\n",
        "    def __init__(self, pop_size, nlayers, max_nfilters, max_sfilters):\n",
        "        self.pop_size = pop_size\n",
        "        self.nlayers = nlayers\n",
        "        self.max_nfilters = max_nfilters\n",
        "        self.max_sfilters = max_sfilters\n",
        "        self.max_acc = 0\n",
        "        self.best_arch = np.zeros((1, 6))\n",
        "        self.gen_acc = []\n",
        "\n",
        "\n",
        "    # def generate_population(self):\n",
        "    #     np.random.seed(0)\n",
        "\n",
        "    #     # Membuat partisi untuk nfilter\n",
        "    #     partition_size_nfilter = self.max_nfilters // self.pop_size\n",
        "    #     pop_nlayers = np.array([\n",
        "    #         np.random.randint(1 + i * partition_size_nfilter, (i + 1) * partition_size_nfilter, self.nlayers)\n",
        "    #         for i in range(self.pop_size)\n",
        "    #     ])\n",
        "\n",
        "    #     # Membuat partisi untuk sfilter\n",
        "    #     partition_size_sfilter = self.max_sfilters // self.pop_size\n",
        "    #     pop_sfilters = np.array([\n",
        "    #         np.random.randint(1 + i * partition_size_sfilter, (i + 1) * partition_size_sfilter, self.nlayers)\n",
        "    #         for i in range(self.pop_size)\n",
        "    #     ])\n",
        "\n",
        "    #     # Menggabungkan kedua set parameter\n",
        "    #     pop_total = np.concatenate((pop_nlayers, pop_sfilters), axis=1)\n",
        "    #     return pop_total\n",
        "\n",
        "    def generate_unique_values(self, max_value, taken_values):\n",
        "        partition_size = max_value // self.nlayers\n",
        "        unique_values = []\n",
        "        for j in range(self.nlayers):\n",
        "            start = j * partition_size + 1\n",
        "            if j == self.nlayers - 1:  # Ensure the last partition reaches the max value\n",
        "                end = max_value + 1\n",
        "            else:\n",
        "                end = start + partition_size\n",
        "\n",
        "            # Generate a unique value within the partition\n",
        "            value = np.random.randint(start, end)\n",
        "            while value in taken_values:  # Ensure uniqueness\n",
        "                value += 1\n",
        "                if value >= end:  # Reset if exceeds partition\n",
        "                    value = start\n",
        "\n",
        "            taken_values.add(value)\n",
        "            unique_values.append(value)\n",
        "\n",
        "        return unique_values\n",
        "\n",
        "    def generate_population(self):\n",
        "        np.random.seed(0)\n",
        "\n",
        "        # Initialize population array\n",
        "        pop_total = np.zeros((self.pop_size, self.nlayers * 2), dtype=int)\n",
        "\n",
        "        for i in range(self.pop_size):\n",
        "            taken_values_nfilters = set()\n",
        "            taken_values_sfilters = set()\n",
        "\n",
        "            # Generate unique nfilters and sfilters for each individual\n",
        "            nfilters = self.generate_unique_values(self.max_nfilters, taken_values_nfilters)\n",
        "            sfilters = self.generate_unique_values(self.max_sfilters, taken_values_sfilters)\n",
        "\n",
        "            # Combine nfilters and sfilters for the individual\n",
        "            pop_total[i] = nfilters + sfilters\n",
        "\n",
        "        return pop_total\n",
        "\n",
        "\n",
        "    def select_parents(self, pop, nparents, fitness):\n",
        "        parents = np.zeros((nparents, pop.shape[1]))\n",
        "        for i in range(nparents):\n",
        "            best = np.argmax(fitness)\n",
        "            parents[i] = pop[best]\n",
        "            fitness[best] = -99999\n",
        "        return parents\n",
        "\n",
        "    def crossover(self, parents):\n",
        "        nchild = self.pop_size - parents.shape[0]\n",
        "        nparents = parents.shape[0]\n",
        "        child = np.zeros((nchild, parents.shape[1]))\n",
        "        for i in range(nchild):\n",
        "            first = i % nparents\n",
        "            second = (i + 1) % nparents\n",
        "            child[i, :2] = parents[first][:2]\n",
        "            child[i, 2] = parents[second][2]\n",
        "            child[i, 3:5] = parents[first][3:5]\n",
        "            child[i, 5] = parents[second][5]\n",
        "        return child\n",
        "\n",
        "    def mutation(self, child):\n",
        "        for i in range(child.shape[0]):\n",
        "            val = np.random.randint(1, 6)\n",
        "            ind = np.random.randint(1, 4) - 1\n",
        "            if child[i][ind] + val > 100:\n",
        "                child[i][ind] -= val\n",
        "            else:\n",
        "                child[i][ind] += val\n",
        "            val = np.random.randint(1, 4)\n",
        "            ind = np.random.randint(4, 7) - 1\n",
        "            if child[i][ind] + val > 20:\n",
        "                child[i][ind] -= val\n",
        "            else:\n",
        "                child[i][ind] += val\n",
        "        return child\n",
        "\n",
        "    def fitness(self, pop, X, Y, epochs):\n",
        "        pop_acc = []\n",
        "        for i in range(pop.shape[0]):\n",
        "            nfilters = pop[i][0:3]\n",
        "            sfilters = pop[i][3:]\n",
        "            model = CNN(nfilters, sfilters)\n",
        "            learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=2, verbose=1, factor=0.3, min_lr=0.000001)\n",
        "            history = model.fit(X, Y, batch_size=64, epochs=epochs, validation_data=[x_val, y_val], callbacks=[learning_rate_reduction])\n",
        "            acc = max(history.history['accuracy'])\n",
        "            pop_acc.append(acc * 100)\n",
        "        if max(pop_acc) > self.max_acc:\n",
        "            self.max_acc = max(pop_acc)\n",
        "            self.best_arch = pop[np.argmax(pop_acc)]\n",
        "        self.gen_acc.append(max(pop_acc))\n",
        "        return pop_acc\n",
        "\n",
        "    def smooth_curve(self, factor, gen):\n",
        "        smoothed_points = []\n",
        "        for point in self.gen_acc:\n",
        "            if smoothed_points:\n",
        "                prev = smoothed_points[-1]\n",
        "                smoothed_points.append(prev * factor + point * (1 - factor))\n",
        "            else:\n",
        "                smoothed_points.append(point)\n",
        "        plt.plot(range(gen + 1), smoothed_points, 'g', label='Smoothed training acc')\n",
        "        plt.xticks(np.arange(gen + 1))\n",
        "        plt.legend()\n",
        "        plt.title('Fitness Accuracy vs Generations')\n",
        "        plt.xlabel('Generations')\n",
        "        plt.ylabel('Fitness (%)')\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "aMa13A7PzWUQ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pop_size = 10\n",
        "nlayers = 3\n",
        "max_nfilters = 100\n",
        "max_sfilters = 10\n",
        "epochs = 10\n",
        "num_generations = 20\n",
        "\n",
        "genCNN = Genetic(pop_size, nlayers, max_nfilters, max_sfilters)\n",
        "# pop = genCNN.generate_population()\n",
        "pop = np.array([[44, 36, 80,  6,  8, 20],\n",
        "       [43, 36, 83,  4,  8, 20],\n",
        "       [40, 44, 80,  4, 13, 20],\n",
        "       [38, 41, 84,  5, 10, 20],\n",
        "       [40, 44, 84,  5, 13, 20],\n",
        "       [44, 40, 83,  8,  8, 20],\n",
        "       [43, 36, 82,  4,  8, 19],\n",
        "       [42, 44, 84,  6, 13, 20],\n",
        "       [43, 41, 84,  5, 11, 20],\n",
        "       [40, 45, 80,  5, 14, 20]])\n",
        "\n",
        "\n",
        "# pop = np.array(result_pop)\n",
        "\n",
        "pop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2oJ4rR5y_Ai",
        "outputId": "31be9878-1f1c-4585-b30e-ec15ee85f578"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[44, 36, 80,  6,  8, 20],\n",
              "       [43, 36, 83,  4,  8, 20],\n",
              "       [40, 44, 80,  4, 13, 20],\n",
              "       [38, 41, 84,  5, 10, 20],\n",
              "       [40, 44, 84,  5, 13, 20],\n",
              "       [44, 40, 83,  8,  8, 20],\n",
              "       [43, 36, 82,  4,  8, 19],\n",
              "       [42, 44, 84,  6, 13, 20],\n",
              "       [43, 41, 84,  5, 11, 20],\n",
              "       [40, 45, 80,  5, 14, 20]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/cpu:0'):\n",
        "   x = tf.convert_to_tensor(x_train, np.float32)\n",
        "   y = tf.convert_to_tensor(y_train, np.float32)\n",
        "\n",
        "bestModelEachGeneration = []\n",
        "\n",
        "for i in range(num_generations + 1):\n",
        "    print(pop)\n",
        "    pop_acc = genCNN.fitness(pop, x, y, epochs)\n",
        "    print('Best Accuracy at the generation {}: {}'.format(i, genCNN.max_acc))\n",
        "    parents = genCNN.select_parents(pop, 5, pop_acc.copy())\n",
        "    child = genCNN.crossover(parents)\n",
        "    child = genCNN.mutation(child)\n",
        "    pop = np.concatenate((parents, child), axis=0).astype('int')\n",
        "    bestModelEachGeneration.append(genCNN.best_arch)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UFNltAF5y-9r",
        "outputId": "9fbb2f3b-676b-451f-be72-7a563571ee20"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.6928 - accuracy: 0.5165 - val_loss: 0.7023 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6927 - accuracy: 0.5165\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.6927 - accuracy: 0.5165 - val_loss: 0.7064 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7069 - val_accuracy: 0.2701 - lr: 3.0000e-04\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.5165\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7073 - val_accuracy: 0.2701 - lr: 3.0000e-04\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7074 - val_accuracy: 0.2701 - lr: 9.0000e-05\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.5165\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7072 - val_accuracy: 0.2701 - lr: 9.0000e-05\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7073 - val_accuracy: 0.2701 - lr: 2.7000e-05\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.5165\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7073 - val_accuracy: 0.2701 - lr: 2.7000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7073 - val_accuracy: 0.2701 - lr: 8.1000e-06\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 8s 40ms/step - loss: 0.8391 - accuracy: 0.5036 - val_loss: 0.6962 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 3s 31ms/step - loss: 0.6929 - accuracy: 0.5165 - val_loss: 0.6994 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "109/111 [============================>.] - ETA: 0s - loss: 0.6928 - accuracy: 0.5162\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 3s 31ms/step - loss: 0.6927 - accuracy: 0.5165 - val_loss: 0.7030 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 3s 31ms/step - loss: 0.6927 - accuracy: 0.5165 - val_loss: 0.7036 - val_accuracy: 0.2701 - lr: 3.0000e-04\n",
            "Epoch 5/10\n",
            "109/111 [============================>.] - ETA: 0s - loss: 0.6927 - accuracy: 0.5165\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 3s 31ms/step - loss: 0.6927 - accuracy: 0.5165 - val_loss: 0.7043 - val_accuracy: 0.2701 - lr: 3.0000e-04\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 3s 31ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7044 - val_accuracy: 0.2701 - lr: 9.0000e-05\n",
            "Epoch 7/10\n",
            "109/111 [============================>.] - ETA: 0s - loss: 0.6926 - accuracy: 0.5171\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 3s 31ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7045 - val_accuracy: 0.2701 - lr: 9.0000e-05\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 3s 31ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7045 - val_accuracy: 0.2701 - lr: 2.7000e-05\n",
            "Epoch 9/10\n",
            "109/111 [============================>.] - ETA: 0s - loss: 0.6927 - accuracy: 0.5156\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "111/111 [==============================] - 3s 31ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7046 - val_accuracy: 0.2701 - lr: 2.7000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 3s 31ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7046 - val_accuracy: 0.2701 - lr: 8.1000e-06\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 10s 48ms/step - loss: 0.6637 - accuracy: 0.7461 - val_loss: 0.2978 - val_accuracy: 0.8889 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1671 - accuracy: 0.9359 - val_loss: 0.1448 - val_accuracy: 0.9453 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1313 - accuracy: 0.9536 - val_loss: 0.1481 - val_accuracy: 0.9556 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1313 - accuracy: 0.9529 - val_loss: 0.1690 - val_accuracy: 0.9368 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.1089 - accuracy: 0.9615\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1089 - accuracy: 0.9615 - val_loss: 0.1335 - val_accuracy: 0.9504 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0817 - accuracy: 0.9718 - val_loss: 0.1028 - val_accuracy: 0.9641 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0775 - accuracy: 0.9738 - val_loss: 0.0965 - val_accuracy: 0.9658 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0706 - accuracy: 0.9744 - val_loss: 0.0920 - val_accuracy: 0.9624 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0675 - accuracy: 0.9769\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0675 - accuracy: 0.9769 - val_loss: 0.0858 - val_accuracy: 0.9658 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0623 - accuracy: 0.9775 - val_loss: 0.0919 - val_accuracy: 0.9607 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 9s 45ms/step - loss: 0.7095 - accuracy: 0.6183 - val_loss: 0.3210 - val_accuracy: 0.8632 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.2148 - accuracy: 0.9119 - val_loss: 0.1453 - val_accuracy: 0.9556 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1444 - accuracy: 0.9465 - val_loss: 0.1306 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1072 - accuracy: 0.9608 - val_loss: 0.0831 - val_accuracy: 0.9726 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0922 - accuracy: 0.9660 - val_loss: 0.0873 - val_accuracy: 0.9726 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0826 - accuracy: 0.9713\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0826 - accuracy: 0.9713 - val_loss: 0.1144 - val_accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0661 - accuracy: 0.9761 - val_loss: 0.0741 - val_accuracy: 0.9761 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0525 - accuracy: 0.9812 - val_loss: 0.0828 - val_accuracy: 0.9692 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0473 - accuracy: 0.9832\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0473 - accuracy: 0.9832 - val_loss: 0.0829 - val_accuracy: 0.9709 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0391 - accuracy: 0.9842 - val_loss: 0.0692 - val_accuracy: 0.9709 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 13s 59ms/step - loss: 1.1216 - accuracy: 0.6878 - val_loss: 0.3588 - val_accuracy: 0.8564 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.3058 - accuracy: 0.8769 - val_loss: 0.3172 - val_accuracy: 0.8923 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.2263 - accuracy: 0.9112 - val_loss: 0.1703 - val_accuracy: 0.9402 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.1453 - accuracy: 0.9458 - val_loss: 0.1097 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0968 - accuracy: 0.9682 - val_loss: 0.0831 - val_accuracy: 0.9726 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0775 - accuracy: 0.9752 - val_loss: 0.0964 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0756 - accuracy: 0.9724\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0756 - accuracy: 0.9724 - val_loss: 0.1627 - val_accuracy: 0.9470 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0506 - accuracy: 0.9825 - val_loss: 0.0744 - val_accuracy: 0.9709 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0416 - accuracy: 0.9839\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0416 - accuracy: 0.9839 - val_loss: 0.1109 - val_accuracy: 0.9573 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0326 - accuracy: 0.9895 - val_loss: 0.0720 - val_accuracy: 0.9744 - lr: 9.0000e-05\n",
            "Best Accuracy at the generation 0: 99.17951822280884\n",
            "[[40 44 84  5 13 20]\n",
            " [38 41 84  5 10 20]\n",
            " [44 36 80  6  8 20]\n",
            " [40 45 80  5 14 20]\n",
            " [43 36 83  4  8 20]\n",
            " [42 44 84  5 14 20]\n",
            " [38 42 80  7 10 20]\n",
            " [47 36 80  7  8 20]\n",
            " [40 47 83  5 14 19]\n",
            " [44 36 84  4  8 18]]\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 5s 35ms/step - loss: 0.8294 - accuracy: 0.6953 - val_loss: 0.3185 - val_accuracy: 0.8650 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.2035 - accuracy: 0.9187 - val_loss: 0.2044 - val_accuracy: 0.9214 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.1545 - accuracy: 0.9431 - val_loss: 0.1964 - val_accuracy: 0.9385 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.1279 - accuracy: 0.9539 - val_loss: 0.1497 - val_accuracy: 0.9419 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.1141 - accuracy: 0.9574 - val_loss: 0.1404 - val_accuracy: 0.9521 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0982 - accuracy: 0.9648 - val_loss: 0.1100 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0915 - accuracy: 0.9675 - val_loss: 0.1322 - val_accuracy: 0.9487 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0794 - accuracy: 0.9694 - val_loss: 0.0957 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0763 - accuracy: 0.9745 - val_loss: 0.0731 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0725 - accuracy: 0.9758 - val_loss: 0.1033 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 5s 35ms/step - loss: 0.8439 - accuracy: 0.5680 - val_loss: 0.4010 - val_accuracy: 0.8239 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.1913 - accuracy: 0.9222 - val_loss: 0.1717 - val_accuracy: 0.9231 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.1352 - accuracy: 0.9509 - val_loss: 0.1483 - val_accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.1101 - accuracy: 0.9586 - val_loss: 0.1198 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.1126 - accuracy: 0.9600 - val_loss: 0.1100 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "109/111 [============================>.] - ETA: 0s - loss: 0.0918 - accuracy: 0.9688\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0915 - accuracy: 0.9687 - val_loss: 0.1268 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0738 - accuracy: 0.9723 - val_loss: 0.0861 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0646 - accuracy: 0.9775 - val_loss: 0.0796 - val_accuracy: 0.9778 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0638 - accuracy: 0.9781 - val_loss: 0.0896 - val_accuracy: 0.9744 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "109/111 [============================>.] - ETA: 0s - loss: 0.0604 - accuracy: 0.9801\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0604 - accuracy: 0.9801 - val_loss: 0.0811 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 5s 35ms/step - loss: 0.6199 - accuracy: 0.6977 - val_loss: 0.1956 - val_accuracy: 0.9368 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.1459 - accuracy: 0.9460 - val_loss: 0.1606 - val_accuracy: 0.9385 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1167 - accuracy: 0.9563 - val_loss: 0.1234 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0963 - accuracy: 0.9663 - val_loss: 0.1359 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0918 - accuracy: 0.9668 - val_loss: 0.1011 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0706 - accuracy: 0.9758 - val_loss: 0.0916 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0642 - accuracy: 0.9772 - val_loss: 0.1032 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0623 - accuracy: 0.9775 - val_loss: 0.0895 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "109/111 [============================>.] - ETA: 0s - loss: 0.0485 - accuracy: 0.9825\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0482 - accuracy: 0.9827 - val_loss: 0.1019 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0301 - accuracy: 0.9900 - val_loss: 0.0687 - val_accuracy: 0.9624 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 36ms/step - loss: 0.9598 - accuracy: 0.7046 - val_loss: 0.2712 - val_accuracy: 0.9060 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1702 - accuracy: 0.9359 - val_loss: 0.1761 - val_accuracy: 0.9368 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1538 - accuracy: 0.9414 - val_loss: 0.1435 - val_accuracy: 0.9556 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1310 - accuracy: 0.9518 - val_loss: 0.1975 - val_accuracy: 0.9179 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1230 - accuracy: 0.9539 - val_loss: 0.1119 - val_accuracy: 0.9607 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1082 - accuracy: 0.9628 - val_loss: 0.1462 - val_accuracy: 0.9470 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.1026 - accuracy: 0.9629\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1026 - accuracy: 0.9629 - val_loss: 0.1335 - val_accuracy: 0.9487 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0837 - accuracy: 0.9699 - val_loss: 0.1118 - val_accuracy: 0.9624 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0779 - accuracy: 0.9738 - val_loss: 0.1048 - val_accuracy: 0.9675 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0746 - accuracy: 0.9717 - val_loss: 0.0952 - val_accuracy: 0.9692 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 5s 34ms/step - loss: 0.5615 - accuracy: 0.7134 - val_loss: 0.2000 - val_accuracy: 0.9350 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.1524 - accuracy: 0.9448 - val_loss: 0.1100 - val_accuracy: 0.9607 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.1452 - accuracy: 0.9485 - val_loss: 0.1504 - val_accuracy: 0.9453 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "109/111 [============================>.] - ETA: 0s - loss: 0.1035 - accuracy: 0.9632\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.1031 - accuracy: 0.9632 - val_loss: 0.1198 - val_accuracy: 0.9470 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0778 - accuracy: 0.9726 - val_loss: 0.1133 - val_accuracy: 0.9487 - lr: 3.0000e-04\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0718 - accuracy: 0.9752\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0718 - accuracy: 0.9752 - val_loss: 0.0946 - val_accuracy: 0.9607 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0642 - accuracy: 0.9786 - val_loss: 0.0793 - val_accuracy: 0.9709 - lr: 9.0000e-05\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0600 - accuracy: 0.9792 - val_loss: 0.0858 - val_accuracy: 0.9658 - lr: 9.0000e-05\n",
            "Epoch 9/10\n",
            "109/111 [============================>.] - ETA: 0s - loss: 0.0590 - accuracy: 0.9798\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0585 - accuracy: 0.9801 - val_loss: 0.1028 - val_accuracy: 0.9573 - lr: 9.0000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0569 - accuracy: 0.9810 - val_loss: 0.0905 - val_accuracy: 0.9590 - lr: 2.7000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 11s 52ms/step - loss: 1.0593 - accuracy: 0.6292 - val_loss: 0.3542 - val_accuracy: 0.8564 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.3056 - accuracy: 0.8703 - val_loss: 0.2456 - val_accuracy: 0.8974 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.2358 - accuracy: 0.9059 - val_loss: 0.2028 - val_accuracy: 0.9282 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1995 - accuracy: 0.9199 - val_loss: 0.1839 - val_accuracy: 0.9128 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1531 - accuracy: 0.9382 - val_loss: 0.1538 - val_accuracy: 0.9299 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1265 - accuracy: 0.9523 - val_loss: 0.1274 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1076 - accuracy: 0.9598 - val_loss: 0.1408 - val_accuracy: 0.9487 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0888 - accuracy: 0.9672 - val_loss: 0.1016 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0724 - accuracy: 0.9721 - val_loss: 0.0891 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0617 - accuracy: 0.9755\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0617 - accuracy: 0.9755 - val_loss: 0.0814 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 10s 50ms/step - loss: 0.8378 - accuracy: 0.5616 - val_loss: 0.6201 - val_accuracy: 0.8017 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.4608 - accuracy: 0.7642 - val_loss: 0.2604 - val_accuracy: 0.8940 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.3719 - accuracy: 0.8307 - val_loss: 0.2427 - val_accuracy: 0.8957 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.2508 - accuracy: 0.8964 - val_loss: 0.2053 - val_accuracy: 0.9214 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1826 - accuracy: 0.9283 - val_loss: 0.1316 - val_accuracy: 0.9487 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1203 - accuracy: 0.9577 - val_loss: 0.1251 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0933 - accuracy: 0.9660 - val_loss: 0.1047 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0886 - accuracy: 0.9686 - val_loss: 0.0692 - val_accuracy: 0.9846 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0683 - accuracy: 0.9747 - val_loss: 0.0826 - val_accuracy: 0.9761 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0665 - accuracy: 0.9748\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0665 - accuracy: 0.9748 - val_loss: 0.0709 - val_accuracy: 0.9846 - lr: 0.0010\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 8s 43ms/step - loss: 0.7362 - accuracy: 0.7612 - val_loss: 0.3361 - val_accuracy: 0.8684 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1713 - accuracy: 0.9341 - val_loss: 0.1584 - val_accuracy: 0.9419 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1479 - accuracy: 0.9445 - val_loss: 0.1438 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1235 - accuracy: 0.9557 - val_loss: 0.1522 - val_accuracy: 0.9487 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1119 - accuracy: 0.9594 - val_loss: 0.0977 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0946 - accuracy: 0.9666 - val_loss: 0.1158 - val_accuracy: 0.9761 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0918 - accuracy: 0.9675 - val_loss: 0.1239 - val_accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0890 - accuracy: 0.9668\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0890 - accuracy: 0.9668 - val_loss: 0.1077 - val_accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0598 - accuracy: 0.9786 - val_loss: 0.0886 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0535 - accuracy: 0.9815\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0535 - accuracy: 0.9815 - val_loss: 0.0867 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 13s 58ms/step - loss: 0.7238 - accuracy: 0.7486 - val_loss: 0.1390 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1378 - accuracy: 0.9482 - val_loss: 0.0839 - val_accuracy: 0.9726 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1153 - accuracy: 0.9577 - val_loss: 0.1034 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.1003 - accuracy: 0.9619\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1003 - accuracy: 0.9619 - val_loss: 0.1094 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0755 - accuracy: 0.9731 - val_loss: 0.1082 - val_accuracy: 0.9573 - lr: 3.0000e-04\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0648 - accuracy: 0.9768 - val_loss: 0.0745 - val_accuracy: 0.9795 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0609 - accuracy: 0.9762 - val_loss: 0.0620 - val_accuracy: 0.9829 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0577 - accuracy: 0.9791 - val_loss: 0.0664 - val_accuracy: 0.9778 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0518 - accuracy: 0.9805\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0518 - accuracy: 0.9805 - val_loss: 0.0645 - val_accuracy: 0.9761 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0435 - accuracy: 0.9834 - val_loss: 0.0637 - val_accuracy: 0.9761 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 8s 41ms/step - loss: 0.7047 - accuracy: 0.7209 - val_loss: 0.3466 - val_accuracy: 0.8530 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.2164 - accuracy: 0.9119 - val_loss: 0.1235 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1118 - accuracy: 0.9622 - val_loss: 0.0917 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0916 - accuracy: 0.9662 - val_loss: 0.0905 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0762 - accuracy: 0.9733 - val_loss: 0.0659 - val_accuracy: 0.9829 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0589 - accuracy: 0.9785 - val_loss: 0.1444 - val_accuracy: 0.9368 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "109/111 [============================>.] - ETA: 0s - loss: 0.0511 - accuracy: 0.9821\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0517 - accuracy: 0.9820 - val_loss: 0.0794 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0326 - accuracy: 0.9883 - val_loss: 0.0903 - val_accuracy: 0.9658 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 0.9917\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0230 - accuracy: 0.9917 - val_loss: 0.0925 - val_accuracy: 0.9658 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0185 - accuracy: 0.9946 - val_loss: 0.0751 - val_accuracy: 0.9675 - lr: 9.0000e-05\n",
            "Best Accuracy at the generation 1: 99.46244359016418\n",
            "[[44 36 84  4  8 18]\n",
            " [44 36 80  6  8 20]\n",
            " [40 47 83  5 14 19]\n",
            " [47 36 80  7  8 20]\n",
            " [43 36 83  4  8 20]\n",
            " [44 36 82  5  8 20]\n",
            " [44 40 83  6 11 19]\n",
            " [41 47 80  6 14 20]\n",
            " [47 36 87  7  8 19]\n",
            " [43 37 84  4 10 18]]\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 5s 35ms/step - loss: 0.5969 - accuracy: 0.7333 - val_loss: 0.3503 - val_accuracy: 0.8496 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.2004 - accuracy: 0.9155 - val_loss: 0.2077 - val_accuracy: 0.9231 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1635 - accuracy: 0.9356 - val_loss: 0.2096 - val_accuracy: 0.9333 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1433 - accuracy: 0.9485 - val_loss: 0.1573 - val_accuracy: 0.9368 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1237 - accuracy: 0.9567 - val_loss: 0.1307 - val_accuracy: 0.9453 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1122 - accuracy: 0.9600 - val_loss: 0.1511 - val_accuracy: 0.9504 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1129 - accuracy: 0.9583 - val_loss: 0.1359 - val_accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0931 - accuracy: 0.9670 - val_loss: 0.1152 - val_accuracy: 0.9556 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "109/111 [============================>.] - ETA: 0s - loss: 0.0910 - accuracy: 0.9666\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0901 - accuracy: 0.9670 - val_loss: 0.1089 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0714 - accuracy: 0.9740 - val_loss: 0.0994 - val_accuracy: 0.9556 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 35ms/step - loss: 0.8612 - accuracy: 0.5059 - val_loss: 0.7083 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.6927 - accuracy: 0.5165 - val_loss: 0.7057 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6928 - accuracy: 0.5165\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.6928 - accuracy: 0.5165 - val_loss: 0.7049 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.6927 - accuracy: 0.5165 - val_loss: 0.7051 - val_accuracy: 0.2701 - lr: 3.0000e-04\n",
            "Epoch 5/10\n",
            "109/111 [============================>.] - ETA: 0s - loss: 0.6927 - accuracy: 0.5165\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.6927 - accuracy: 0.5165 - val_loss: 0.7046 - val_accuracy: 0.2701 - lr: 3.0000e-04\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7049 - val_accuracy: 0.2701 - lr: 9.0000e-05\n",
            "Epoch 7/10\n",
            "109/111 [============================>.] - ETA: 0s - loss: 0.6926 - accuracy: 0.5171\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7047 - val_accuracy: 0.2701 - lr: 9.0000e-05\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7048 - val_accuracy: 0.2701 - lr: 2.7000e-05\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.5165\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7049 - val_accuracy: 0.2701 - lr: 2.7000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7050 - val_accuracy: 0.2701 - lr: 8.1000e-06\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 36ms/step - loss: 0.6890 - accuracy: 0.6642 - val_loss: 0.2901 - val_accuracy: 0.8752 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.2444 - accuracy: 0.9013 - val_loss: 0.1469 - val_accuracy: 0.9556 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1604 - accuracy: 0.9390 - val_loss: 0.1226 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1067 - accuracy: 0.9625 - val_loss: 0.0761 - val_accuracy: 0.9761 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0887 - accuracy: 0.9679 - val_loss: 0.0869 - val_accuracy: 0.9761 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0666 - accuracy: 0.9781\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0666 - accuracy: 0.9781 - val_loss: 0.0903 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0467 - accuracy: 0.9826 - val_loss: 0.0541 - val_accuracy: 0.9846 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0388 - accuracy: 0.9868 - val_loss: 0.0589 - val_accuracy: 0.9812 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 0.9871\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0342 - accuracy: 0.9871 - val_loss: 0.0671 - val_accuracy: 0.9795 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0261 - accuracy: 0.9909 - val_loss: 0.0516 - val_accuracy: 0.9846 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 37ms/step - loss: 0.7770 - accuracy: 0.6587 - val_loss: 0.4100 - val_accuracy: 0.7915 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.3541 - accuracy: 0.8482 - val_loss: 0.2525 - val_accuracy: 0.8872 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.2146 - accuracy: 0.9170 - val_loss: 0.1780 - val_accuracy: 0.9419 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1377 - accuracy: 0.9489 - val_loss: 0.0922 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1025 - accuracy: 0.9644 - val_loss: 0.0931 - val_accuracy: 0.9726 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0868 - accuracy: 0.9700 - val_loss: 0.0895 - val_accuracy: 0.9726 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0741 - accuracy: 0.9731 - val_loss: 0.0883 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0638 - accuracy: 0.9784 - val_loss: 0.1052 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0553 - accuracy: 0.9805\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0553 - accuracy: 0.9805 - val_loss: 0.0904 - val_accuracy: 0.9726 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0339 - accuracy: 0.9885 - val_loss: 0.0616 - val_accuracy: 0.9795 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 5s 34ms/step - loss: 0.8039 - accuracy: 0.6988 - val_loss: 0.2798 - val_accuracy: 0.8940 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.1562 - accuracy: 0.9407 - val_loss: 0.1604 - val_accuracy: 0.9368 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.1181 - accuracy: 0.9563 - val_loss: 0.1017 - val_accuracy: 0.9726 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0940 - accuracy: 0.9656 - val_loss: 0.0769 - val_accuracy: 0.9726 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "109/111 [============================>.] - ETA: 0s - loss: 0.0939 - accuracy: 0.9634\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0937 - accuracy: 0.9636 - val_loss: 0.0794 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0669 - accuracy: 0.9754 - val_loss: 0.0698 - val_accuracy: 0.9778 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0568 - accuracy: 0.9802 - val_loss: 0.0588 - val_accuracy: 0.9812 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0504 - accuracy: 0.9819 - val_loss: 0.0651 - val_accuracy: 0.9778 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "109/111 [============================>.] - ETA: 0s - loss: 0.0492 - accuracy: 0.9821\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0487 - accuracy: 0.9823 - val_loss: 0.0632 - val_accuracy: 0.9761 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0389 - accuracy: 0.9861 - val_loss: 0.0581 - val_accuracy: 0.9778 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 8s 43ms/step - loss: 0.7427 - accuracy: 0.6763 - val_loss: 0.2692 - val_accuracy: 0.9248 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1639 - accuracy: 0.9390 - val_loss: 0.1182 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1265 - accuracy: 0.9549 - val_loss: 0.1161 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.1092 - accuracy: 0.9600\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1092 - accuracy: 0.9600 - val_loss: 0.1599 - val_accuracy: 0.9436 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0868 - accuracy: 0.9685 - val_loss: 0.1035 - val_accuracy: 0.9556 - lr: 3.0000e-04\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0770 - accuracy: 0.9740\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0770 - accuracy: 0.9740 - val_loss: 0.0932 - val_accuracy: 0.9675 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0677 - accuracy: 0.9768 - val_loss: 0.0798 - val_accuracy: 0.9726 - lr: 9.0000e-05\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0659 - accuracy: 0.9771 - val_loss: 0.0863 - val_accuracy: 0.9641 - lr: 9.0000e-05\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0652 - accuracy: 0.9771\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0652 - accuracy: 0.9771 - val_loss: 0.1088 - val_accuracy: 0.9504 - lr: 9.0000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0624 - accuracy: 0.9778 - val_loss: 0.0955 - val_accuracy: 0.9573 - lr: 2.7000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 11s 52ms/step - loss: 0.7513 - accuracy: 0.7058 - val_loss: 0.3104 - val_accuracy: 0.8410 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1793 - accuracy: 0.9284 - val_loss: 0.1237 - val_accuracy: 0.9556 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1206 - accuracy: 0.9542 - val_loss: 0.1088 - val_accuracy: 0.9761 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0988 - accuracy: 0.9631 - val_loss: 0.0688 - val_accuracy: 0.9726 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.5531 - accuracy: 0.8993\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.5531 - accuracy: 0.8993 - val_loss: 0.1544 - val_accuracy: 0.9436 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1153 - accuracy: 0.9571 - val_loss: 0.1378 - val_accuracy: 0.9538 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.1025 - accuracy: 0.9607\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1025 - accuracy: 0.9607 - val_loss: 0.1330 - val_accuracy: 0.9521 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0916 - accuracy: 0.9677 - val_loss: 0.1257 - val_accuracy: 0.9607 - lr: 9.0000e-05\n",
            "Epoch 9/10\n",
            "109/111 [============================>.] - ETA: 0s - loss: 0.0884 - accuracy: 0.9669\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0880 - accuracy: 0.9669 - val_loss: 0.1221 - val_accuracy: 0.9607 - lr: 9.0000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0849 - accuracy: 0.9697 - val_loss: 0.1205 - val_accuracy: 0.9624 - lr: 2.7000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 14s 61ms/step - loss: 0.6974 - accuracy: 0.6596 - val_loss: 0.2812 - val_accuracy: 0.8923 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.2057 - accuracy: 0.9204 - val_loss: 0.1483 - val_accuracy: 0.9487 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1466 - accuracy: 0.9440 - val_loss: 0.1094 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1159 - accuracy: 0.9583 - val_loss: 0.0862 - val_accuracy: 0.9795 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0918 - accuracy: 0.9670 - val_loss: 0.0957 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0856 - accuracy: 0.9692\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0856 - accuracy: 0.9692 - val_loss: 0.1860 - val_accuracy: 0.9111 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0640 - accuracy: 0.9784 - val_loss: 0.0579 - val_accuracy: 0.9897 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0511 - accuracy: 0.9820 - val_loss: 0.0692 - val_accuracy: 0.9795 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0433 - accuracy: 0.9854\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0433 - accuracy: 0.9854 - val_loss: 0.0816 - val_accuracy: 0.9641 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0363 - accuracy: 0.9874 - val_loss: 0.0672 - val_accuracy: 0.9795 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 8s 43ms/step - loss: 0.7993 - accuracy: 0.5627 - val_loss: 0.4430 - val_accuracy: 0.7949 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.5191 - accuracy: 0.7854 - val_loss: 0.4248 - val_accuracy: 0.8120 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.3042 - accuracy: 0.8694 - val_loss: 0.2119 - val_accuracy: 0.9248 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1635 - accuracy: 0.9370 - val_loss: 0.1041 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1069 - accuracy: 0.9597 - val_loss: 0.0922 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0935 - accuracy: 0.9653 - val_loss: 0.1066 - val_accuracy: 0.9607 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0745 - accuracy: 0.9726\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0745 - accuracy: 0.9726 - val_loss: 0.0993 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0493 - accuracy: 0.9806 - val_loss: 0.0849 - val_accuracy: 0.9624 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0406 - accuracy: 0.9843\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0406 - accuracy: 0.9843 - val_loss: 0.0905 - val_accuracy: 0.9607 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0332 - accuracy: 0.9888 - val_loss: 0.0758 - val_accuracy: 0.9726 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 10s 50ms/step - loss: 0.5024 - accuracy: 0.7625 - val_loss: 0.1487 - val_accuracy: 0.9607 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.1372 - accuracy: 0.9520 - val_loss: 0.1095 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0992 - accuracy: 0.9638 - val_loss: 0.1047 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0875 - accuracy: 0.9677 - val_loss: 0.0725 - val_accuracy: 0.9812 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0723 - accuracy: 0.9730 - val_loss: 0.0690 - val_accuracy: 0.9726 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0721 - accuracy: 0.9743 - val_loss: 0.1019 - val_accuracy: 0.9829 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0582 - accuracy: 0.9785 - val_loss: 0.0760 - val_accuracy: 0.9761 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0489 - accuracy: 0.9827\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0489 - accuracy: 0.9827 - val_loss: 0.0748 - val_accuracy: 0.9778 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0304 - accuracy: 0.9892 - val_loss: 0.0747 - val_accuracy: 0.9709 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "109/111 [============================>.] - ETA: 0s - loss: 0.0238 - accuracy: 0.9918\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0238 - accuracy: 0.9918 - val_loss: 0.0507 - val_accuracy: 0.9829 - lr: 3.0000e-04\n",
            "Best Accuracy at the generation 2: 99.46244359016418\n",
            "[[43 37 84  4 10 18]\n",
            " [40 47 83  5 14 19]\n",
            " [47 36 87  7  8 19]\n",
            " [47 36 80  7  8 20]\n",
            " [41 47 80  6 14 20]\n",
            " [43 42 83  7 10 19]\n",
            " [40 50 87  5 14 20]\n",
            " [48 36 80  7  8 18]\n",
            " [47 38 80 10  8 20]\n",
            " [43 47 84  7 14 18]]\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 35ms/step - loss: 0.7943 - accuracy: 0.5559 - val_loss: 0.4261 - val_accuracy: 0.7709 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.2486 - accuracy: 0.9004 - val_loss: 0.1393 - val_accuracy: 0.9453 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1398 - accuracy: 0.9491 - val_loss: 0.1136 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1050 - accuracy: 0.9624 - val_loss: 0.1415 - val_accuracy: 0.9504 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0955 - accuracy: 0.9653\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0955 - accuracy: 0.9653 - val_loss: 0.0891 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0668 - accuracy: 0.9775 - val_loss: 0.0824 - val_accuracy: 0.9795 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0591 - accuracy: 0.9781 - val_loss: 0.0756 - val_accuracy: 0.9761 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0509 - accuracy: 0.9813\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0509 - accuracy: 0.9813 - val_loss: 0.0821 - val_accuracy: 0.9744 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0424 - accuracy: 0.9847 - val_loss: 0.0724 - val_accuracy: 0.9795 - lr: 9.0000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0402 - accuracy: 0.9867\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0402 - accuracy: 0.9867 - val_loss: 0.0701 - val_accuracy: 0.9778 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 5s 36ms/step - loss: 0.8968 - accuracy: 0.6342 - val_loss: 0.3319 - val_accuracy: 0.8889 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.2791 - accuracy: 0.8812 - val_loss: 0.2085 - val_accuracy: 0.9248 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1575 - accuracy: 0.9403 - val_loss: 0.1230 - val_accuracy: 0.9812 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1130 - accuracy: 0.9574 - val_loss: 0.0759 - val_accuracy: 0.9829 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0937 - accuracy: 0.9662 - val_loss: 0.0599 - val_accuracy: 0.9880 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0745 - accuracy: 0.9726 - val_loss: 0.0691 - val_accuracy: 0.9897 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0646 - accuracy: 0.9758 - val_loss: 0.0684 - val_accuracy: 0.9778 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0541 - accuracy: 0.9802\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0541 - accuracy: 0.9802 - val_loss: 0.0795 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0300 - accuracy: 0.9890 - val_loss: 0.0644 - val_accuracy: 0.9778 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0244 - accuracy: 0.9919\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0244 - accuracy: 0.9919 - val_loss: 0.0515 - val_accuracy: 0.9795 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 36ms/step - loss: 0.7476 - accuracy: 0.6753 - val_loss: 0.3006 - val_accuracy: 0.8701 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.2520 - accuracy: 0.8969 - val_loss: 0.1473 - val_accuracy: 0.9487 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1087 - accuracy: 0.9600 - val_loss: 0.0932 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0826 - accuracy: 0.9734 - val_loss: 0.0707 - val_accuracy: 0.9778 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0709 - accuracy: 0.9733 - val_loss: 0.0906 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0550 - accuracy: 0.9792\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0550 - accuracy: 0.9792 - val_loss: 0.0963 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0396 - accuracy: 0.9853 - val_loss: 0.0661 - val_accuracy: 0.9744 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0278 - accuracy: 0.9898\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0278 - accuracy: 0.9898 - val_loss: 0.0751 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0205 - accuracy: 0.9931 - val_loss: 0.0660 - val_accuracy: 0.9778 - lr: 9.0000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 0.9938\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0197 - accuracy: 0.9938 - val_loss: 0.0674 - val_accuracy: 0.9761 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 36ms/step - loss: 0.6532 - accuracy: 0.7526 - val_loss: 0.1788 - val_accuracy: 0.9265 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.1526 - accuracy: 0.9392 - val_loss: 0.1151 - val_accuracy: 0.9556 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.1471 - accuracy: 0.9441 - val_loss: 0.1179 - val_accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1127 - accuracy: 0.9604 - val_loss: 0.1083 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.1109 - accuracy: 0.9605 - val_loss: 0.1067 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.1050 - accuracy: 0.9658 - val_loss: 0.1056 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0920 - accuracy: 0.9658\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0920 - accuracy: 0.9658 - val_loss: 0.1083 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0715 - accuracy: 0.9748 - val_loss: 0.0719 - val_accuracy: 0.9709 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0631 - accuracy: 0.9779 - val_loss: 0.0739 - val_accuracy: 0.9812 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0618 - accuracy: 0.9768 - val_loss: 0.0814 - val_accuracy: 0.9658 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 37ms/step - loss: 0.7322 - accuracy: 0.6656 - val_loss: 0.4761 - val_accuracy: 0.7812 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.2256 - accuracy: 0.9106 - val_loss: 0.2006 - val_accuracy: 0.9248 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1490 - accuracy: 0.9457 - val_loss: 0.1600 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1233 - accuracy: 0.9587 - val_loss: 0.1411 - val_accuracy: 0.9453 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.1093 - accuracy: 0.9631\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1093 - accuracy: 0.9631 - val_loss: 0.1101 - val_accuracy: 0.9521 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0827 - accuracy: 0.9734 - val_loss: 0.0986 - val_accuracy: 0.9709 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0809 - accuracy: 0.9726 - val_loss: 0.0980 - val_accuracy: 0.9692 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0713 - accuracy: 0.9752 - val_loss: 0.0841 - val_accuracy: 0.9795 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0673 - accuracy: 0.9764 - val_loss: 0.0948 - val_accuracy: 0.9692 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0655 - accuracy: 0.9785\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0655 - accuracy: 0.9785 - val_loss: 0.0902 - val_accuracy: 0.9692 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 10s 51ms/step - loss: 0.7763 - accuracy: 0.5001 - val_loss: 0.6987 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.6928 - accuracy: 0.5165 - val_loss: 0.7026 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6927 - accuracy: 0.5165\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.6927 - accuracy: 0.5165 - val_loss: 0.7065 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7070 - val_accuracy: 0.2701 - lr: 3.0000e-04\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.5165\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7073 - val_accuracy: 0.2701 - lr: 3.0000e-04\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7074 - val_accuracy: 0.2701 - lr: 9.0000e-05\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.5165\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7073 - val_accuracy: 0.2701 - lr: 9.0000e-05\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7073 - val_accuracy: 0.2701 - lr: 2.7000e-05\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.5165\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7073 - val_accuracy: 0.2701 - lr: 2.7000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7074 - val_accuracy: 0.2701 - lr: 8.1000e-06\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 13s 58ms/step - loss: 0.8354 - accuracy: 0.5810 - val_loss: 0.3416 - val_accuracy: 0.8598 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.2791 - accuracy: 0.8840 - val_loss: 0.1603 - val_accuracy: 0.9607 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1705 - accuracy: 0.9335 - val_loss: 0.1197 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1050 - accuracy: 0.9611 - val_loss: 0.0766 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0897 - accuracy: 0.9656\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0897 - accuracy: 0.9656 - val_loss: 0.1097 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0590 - accuracy: 0.9799 - val_loss: 0.0758 - val_accuracy: 0.9744 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0476 - accuracy: 0.9846 - val_loss: 0.0664 - val_accuracy: 0.9778 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0394 - accuracy: 0.9878 - val_loss: 0.0663 - val_accuracy: 0.9761 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0363 - accuracy: 0.9880\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0363 - accuracy: 0.9880 - val_loss: 0.0702 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0274 - accuracy: 0.9907 - val_loss: 0.0678 - val_accuracy: 0.9709 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 9s 47ms/step - loss: 0.7308 - accuracy: 0.5006 - val_loss: 0.6978 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.6928 - accuracy: 0.5165 - val_loss: 0.7014 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "109/111 [============================>.] - ETA: 0s - loss: 0.6927 - accuracy: 0.5162\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.6927 - accuracy: 0.5165 - val_loss: 0.7052 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7058 - val_accuracy: 0.2701 - lr: 3.0000e-04\n",
            "Epoch 5/10\n",
            "109/111 [============================>.] - ETA: 0s - loss: 0.6926 - accuracy: 0.5165\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7063 - val_accuracy: 0.2701 - lr: 3.0000e-04\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7064 - val_accuracy: 0.2701 - lr: 9.0000e-05\n",
            "Epoch 7/10\n",
            "109/111 [============================>.] - ETA: 0s - loss: 0.6926 - accuracy: 0.5171\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7063 - val_accuracy: 0.2701 - lr: 9.0000e-05\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7064 - val_accuracy: 0.2701 - lr: 2.7000e-05\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.5165\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7064 - val_accuracy: 0.2701 - lr: 2.7000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7064 - val_accuracy: 0.2701 - lr: 8.1000e-06\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 10s 53ms/step - loss: 1.1001 - accuracy: 0.6584 - val_loss: 0.3097 - val_accuracy: 0.8752 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1951 - accuracy: 0.9225 - val_loss: 0.1743 - val_accuracy: 0.9368 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1543 - accuracy: 0.9392 - val_loss: 0.1958 - val_accuracy: 0.9402 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1318 - accuracy: 0.9492 - val_loss: 0.1396 - val_accuracy: 0.9453 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1190 - accuracy: 0.9569 - val_loss: 0.1436 - val_accuracy: 0.9470 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1052 - accuracy: 0.9617 - val_loss: 0.1712 - val_accuracy: 0.9333 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.1066 - accuracy: 0.9608\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.1066 - accuracy: 0.9608 - val_loss: 0.1777 - val_accuracy: 0.9350 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0844 - accuracy: 0.9682 - val_loss: 0.1032 - val_accuracy: 0.9641 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0709 - accuracy: 0.9734 - val_loss: 0.1171 - val_accuracy: 0.9590 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0686 - accuracy: 0.9762\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0686 - accuracy: 0.9762 - val_loss: 0.1009 - val_accuracy: 0.9641 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 13s 60ms/step - loss: 1.1390 - accuracy: 0.7414 - val_loss: 0.3446 - val_accuracy: 0.8564 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.2122 - accuracy: 0.9184 - val_loss: 0.1809 - val_accuracy: 0.9299 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1293 - accuracy: 0.9540 - val_loss: 0.1547 - val_accuracy: 0.9385 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1076 - accuracy: 0.9615 - val_loss: 0.1219 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1099 - accuracy: 0.9607 - val_loss: 0.1315 - val_accuracy: 0.9487 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0907 - accuracy: 0.9683\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0907 - accuracy: 0.9683 - val_loss: 0.1345 - val_accuracy: 0.9504 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0726 - accuracy: 0.9738 - val_loss: 0.0942 - val_accuracy: 0.9624 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0604 - accuracy: 0.9791 - val_loss: 0.0842 - val_accuracy: 0.9658 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0604 - accuracy: 0.9782 - val_loss: 0.0854 - val_accuracy: 0.9658 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0553 - accuracy: 0.9813 - val_loss: 0.0905 - val_accuracy: 0.9709 - lr: 3.0000e-04\n",
            "Best Accuracy at the generation 3: 99.46244359016418\n",
            "[[47 36 87  7  8 19]\n",
            " [40 47 83  5 14 19]\n",
            " [40 50 87  5 14 20]\n",
            " [43 37 84  4 10 18]\n",
            " [43 47 84  7 14 18]\n",
            " [51 36 83  7  8 16]\n",
            " [45 47 87  5 15 20]\n",
            " [42 50 84  6 14 18]\n",
            " [44 37 84  4 10 19]\n",
            " [43 47 91  7 16 19]]\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 36ms/step - loss: 0.7670 - accuracy: 0.6295 - val_loss: 0.3760 - val_accuracy: 0.8256 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.4447 - accuracy: 0.7943 - val_loss: 0.3389 - val_accuracy: 0.8547 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.2814 - accuracy: 0.8806 - val_loss: 0.2670 - val_accuracy: 0.8974 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1564 - accuracy: 0.9410 - val_loss: 0.1719 - val_accuracy: 0.9350 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0982 - accuracy: 0.9641 - val_loss: 0.0742 - val_accuracy: 0.9761 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0742 - accuracy: 0.9747 - val_loss: 0.0977 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0565 - accuracy: 0.9809\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0565 - accuracy: 0.9809 - val_loss: 0.0821 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0345 - accuracy: 0.9873 - val_loss: 0.0806 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0250 - accuracy: 0.9917\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0250 - accuracy: 0.9917 - val_loss: 0.0801 - val_accuracy: 0.9607 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0184 - accuracy: 0.9942 - val_loss: 0.0696 - val_accuracy: 0.9709 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 36ms/step - loss: 0.8530 - accuracy: 0.5930 - val_loss: 0.3907 - val_accuracy: 0.8393 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.4993 - accuracy: 0.8377 - val_loss: 0.3273 - val_accuracy: 0.8872 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.4292 - accuracy: 0.8836 - val_loss: 0.3479 - val_accuracy: 0.8650 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.3891 - accuracy: 0.9144 - val_loss: 0.2700 - val_accuracy: 0.8991 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.3486 - accuracy: 0.9291 - val_loss: 0.2083 - val_accuracy: 0.9521 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.3034 - accuracy: 0.9505 - val_loss: 0.1745 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.2705 - accuracy: 0.9627 - val_loss: 0.1680 - val_accuracy: 0.9726 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.2515 - accuracy: 0.9639 - val_loss: 0.1428 - val_accuracy: 0.9812 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.2309 - accuracy: 0.9679 - val_loss: 0.1547 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.2188 - accuracy: 0.9702\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.2188 - accuracy: 0.9702 - val_loss: 0.1872 - val_accuracy: 0.9487 - lr: 0.0010\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 38ms/step - loss: 0.6395 - accuracy: 0.7746 - val_loss: 0.2647 - val_accuracy: 0.8974 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1615 - accuracy: 0.9380 - val_loss: 0.1597 - val_accuracy: 0.9350 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1299 - accuracy: 0.9542 - val_loss: 0.1347 - val_accuracy: 0.9607 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1136 - accuracy: 0.9594 - val_loss: 0.1066 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1005 - accuracy: 0.9660 - val_loss: 0.1144 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0919 - accuracy: 0.9682 - val_loss: 0.1071 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0924 - accuracy: 0.9662 - val_loss: 0.1129 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0877 - accuracy: 0.9699\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0877 - accuracy: 0.9699 - val_loss: 0.1051 - val_accuracy: 0.9504 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0621 - accuracy: 0.9788 - val_loss: 0.0924 - val_accuracy: 0.9607 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0564 - accuracy: 0.9803 - val_loss: 0.0836 - val_accuracy: 0.9692 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 5s 36ms/step - loss: 0.6947 - accuracy: 0.5830 - val_loss: 0.4589 - val_accuracy: 0.7915 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.3245 - accuracy: 0.8583 - val_loss: 0.3264 - val_accuracy: 0.8581 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.2003 - accuracy: 0.9228 - val_loss: 0.1542 - val_accuracy: 0.9470 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.1295 - accuracy: 0.9547 - val_loss: 0.1073 - val_accuracy: 0.9607 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0990 - accuracy: 0.9655 - val_loss: 0.1001 - val_accuracy: 0.9607 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0812 - accuracy: 0.9717 - val_loss: 0.0858 - val_accuracy: 0.9726 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0677 - accuracy: 0.9762 - val_loss: 0.0839 - val_accuracy: 0.9778 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0585 - accuracy: 0.9786 - val_loss: 0.1213 - val_accuracy: 0.9521 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0480 - accuracy: 0.9829\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0480 - accuracy: 0.9829 - val_loss: 0.0832 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0263 - accuracy: 0.9915 - val_loss: 0.0769 - val_accuracy: 0.9658 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 37ms/step - loss: 1.3854 - accuracy: 0.6700 - val_loss: 0.3947 - val_accuracy: 0.7470 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.2781 - accuracy: 0.8830 - val_loss: 0.1292 - val_accuracy: 0.9556 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1358 - accuracy: 0.9498 - val_loss: 0.1240 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0916 - accuracy: 0.9676 - val_loss: 0.0738 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0797 - accuracy: 0.9696 - val_loss: 0.0655 - val_accuracy: 0.9761 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0613 - accuracy: 0.9757 - val_loss: 0.1033 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0646 - accuracy: 0.9769 - val_loss: 0.0769 - val_accuracy: 0.9829 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0566 - accuracy: 0.9802 - val_loss: 0.1106 - val_accuracy: 0.9607 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0456 - accuracy: 0.9834\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0456 - accuracy: 0.9834 - val_loss: 0.0734 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0286 - accuracy: 0.9891 - val_loss: 0.0698 - val_accuracy: 0.9778 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 9s 48ms/step - loss: 0.5339 - accuracy: 0.7772 - val_loss: 0.2515 - val_accuracy: 0.9077 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1876 - accuracy: 0.9307 - val_loss: 0.2442 - val_accuracy: 0.8872 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1611 - accuracy: 0.9389 - val_loss: 0.1813 - val_accuracy: 0.9282 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1427 - accuracy: 0.9464 - val_loss: 0.1345 - val_accuracy: 0.9521 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1231 - accuracy: 0.9559 - val_loss: 0.1149 - val_accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1139 - accuracy: 0.9600 - val_loss: 0.1245 - val_accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.1117 - accuracy: 0.9610\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1117 - accuracy: 0.9610 - val_loss: 0.1460 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0857 - accuracy: 0.9707 - val_loss: 0.0999 - val_accuracy: 0.9658 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0729 - accuracy: 0.9734 - val_loss: 0.1110 - val_accuracy: 0.9556 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0678 - accuracy: 0.9762\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0678 - accuracy: 0.9762 - val_loss: 0.1064 - val_accuracy: 0.9624 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 15s 68ms/step - loss: 0.9803 - accuracy: 0.6323 - val_loss: 0.3541 - val_accuracy: 0.8256 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.3686 - accuracy: 0.8401 - val_loss: 0.2439 - val_accuracy: 0.9248 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.1967 - accuracy: 0.9221 - val_loss: 0.1398 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.1199 - accuracy: 0.9569 - val_loss: 0.1378 - val_accuracy: 0.9556 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.1017 - accuracy: 0.9631 - val_loss: 0.0707 - val_accuracy: 0.9795 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0712 - accuracy: 0.9731 - val_loss: 0.0899 - val_accuracy: 0.9726 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0601 - accuracy: 0.9784\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0601 - accuracy: 0.9784 - val_loss: 0.0671 - val_accuracy: 0.9795 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0387 - accuracy: 0.9874 - val_loss: 0.0572 - val_accuracy: 0.9795 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0313 - accuracy: 0.9902 - val_loss: 0.0597 - val_accuracy: 0.9812 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0271 - accuracy: 0.9909 - val_loss: 0.0475 - val_accuracy: 0.9829 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 12s 57ms/step - loss: 1.0903 - accuracy: 0.6195 - val_loss: 0.3795 - val_accuracy: 0.8291 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.2039 - accuracy: 0.9187 - val_loss: 0.1334 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1079 - accuracy: 0.9619 - val_loss: 0.1133 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0969 - accuracy: 0.9648 - val_loss: 0.1045 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0837 - accuracy: 0.9690\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0837 - accuracy: 0.9690 - val_loss: 0.0923 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0563 - accuracy: 0.9801 - val_loss: 0.0765 - val_accuracy: 0.9744 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0485 - accuracy: 0.9833 - val_loss: 0.0784 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0439 - accuracy: 0.9853\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0439 - accuracy: 0.9853 - val_loss: 0.0794 - val_accuracy: 0.9744 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0353 - accuracy: 0.9878 - val_loss: 0.0893 - val_accuracy: 0.9641 - lr: 9.0000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0332 - accuracy: 0.9892\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0332 - accuracy: 0.9892 - val_loss: 0.0754 - val_accuracy: 0.9744 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 10s 50ms/step - loss: 0.8201 - accuracy: 0.6094 - val_loss: 0.4904 - val_accuracy: 0.6564 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.3341 - accuracy: 0.8527 - val_loss: 0.1544 - val_accuracy: 0.9453 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1459 - accuracy: 0.9443 - val_loss: 0.1267 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1119 - accuracy: 0.9584 - val_loss: 0.1259 - val_accuracy: 0.9521 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1037 - accuracy: 0.9635 - val_loss: 0.0857 - val_accuracy: 0.9726 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0854 - accuracy: 0.9699 - val_loss: 0.1156 - val_accuracy: 0.9521 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0787 - accuracy: 0.9709 - val_loss: 0.0800 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0822 - accuracy: 0.9696 - val_loss: 0.1133 - val_accuracy: 0.9504 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0643 - accuracy: 0.9772\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0643 - accuracy: 0.9772 - val_loss: 0.0990 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0462 - accuracy: 0.9827 - val_loss: 0.0762 - val_accuracy: 0.9795 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 15s 68ms/step - loss: 1.5834 - accuracy: 0.7428 - val_loss: 0.2438 - val_accuracy: 0.9179 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.1726 - accuracy: 0.9369 - val_loss: 0.1937 - val_accuracy: 0.9231 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.1434 - accuracy: 0.9486 - val_loss: 0.1529 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.1162 - accuracy: 0.9553 - val_loss: 0.0889 - val_accuracy: 0.9812 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.1007 - accuracy: 0.9628 - val_loss: 0.1081 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0907 - accuracy: 0.9692\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0907 - accuracy: 0.9692 - val_loss: 0.0909 - val_accuracy: 0.9795 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0677 - accuracy: 0.9762 - val_loss: 0.0722 - val_accuracy: 0.9761 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0622 - accuracy: 0.9791\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0622 - accuracy: 0.9791 - val_loss: 0.0755 - val_accuracy: 0.9692 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0542 - accuracy: 0.9805 - val_loss: 0.0829 - val_accuracy: 0.9641 - lr: 9.0000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0549 - accuracy: 0.9802\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0549 - accuracy: 0.9802 - val_loss: 0.0732 - val_accuracy: 0.9692 - lr: 9.0000e-05\n",
            "Best Accuracy at the generation 4: 99.46244359016418\n",
            "[[47 36 87  7  8 19]\n",
            " [43 37 84  4 10 18]\n",
            " [45 47 87  5 15 20]\n",
            " [42 50 84  6 14 18]\n",
            " [43 47 84  7 14 18]\n",
            " [47 39 84  8  8 18]\n",
            " [45 37 87  4 10 17]\n",
            " [45 47 87  5 15 20]\n",
            " [42 50 85  6 14 19]\n",
            " [43 47 90  9 14 19]]\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 36ms/step - loss: 0.8334 - accuracy: 0.4998 - val_loss: 0.5742 - val_accuracy: 0.7299 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.2776 - accuracy: 0.8663 - val_loss: 0.1860 - val_accuracy: 0.9316 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1437 - accuracy: 0.9477 - val_loss: 0.1691 - val_accuracy: 0.9504 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1295 - accuracy: 0.9494 - val_loss: 0.1479 - val_accuracy: 0.9504 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1093 - accuracy: 0.9607 - val_loss: 0.1104 - val_accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1002 - accuracy: 0.9628 - val_loss: 0.1272 - val_accuracy: 0.9607 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0917 - accuracy: 0.9672 - val_loss: 0.1138 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0833 - accuracy: 0.9700 - val_loss: 0.1132 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0745 - accuracy: 0.9709\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0745 - accuracy: 0.9709 - val_loss: 0.0963 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0590 - accuracy: 0.9774 - val_loss: 0.1010 - val_accuracy: 0.9675 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 36ms/step - loss: 0.6357 - accuracy: 0.7076 - val_loss: 0.2896 - val_accuracy: 0.8838 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1991 - accuracy: 0.9219 - val_loss: 0.1075 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1145 - accuracy: 0.9588 - val_loss: 0.1039 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0955 - accuracy: 0.9682 - val_loss: 0.0859 - val_accuracy: 0.9812 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0861 - accuracy: 0.9689 - val_loss: 0.0848 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0796 - accuracy: 0.9720\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0796 - accuracy: 0.9720 - val_loss: 0.0790 - val_accuracy: 0.9761 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0564 - accuracy: 0.9810 - val_loss: 0.0592 - val_accuracy: 0.9863 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0473 - accuracy: 0.9842 - val_loss: 0.0609 - val_accuracy: 0.9829 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0402 - accuracy: 0.9868\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0402 - accuracy: 0.9868 - val_loss: 0.0634 - val_accuracy: 0.9812 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0318 - accuracy: 0.9897 - val_loss: 0.0602 - val_accuracy: 0.9812 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 40ms/step - loss: 1.0305 - accuracy: 0.6036 - val_loss: 0.3486 - val_accuracy: 0.8444 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.4231 - accuracy: 0.8128 - val_loss: 0.3994 - val_accuracy: 0.8188 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.2966 - accuracy: 0.8755 - val_loss: 0.2051 - val_accuracy: 0.9248 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1906 - accuracy: 0.9256 - val_loss: 0.1343 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1412 - accuracy: 0.9482 - val_loss: 0.1247 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.1207 - accuracy: 0.9554\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1207 - accuracy: 0.9554 - val_loss: 0.1412 - val_accuracy: 0.9453 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0968 - accuracy: 0.9648 - val_loss: 0.0834 - val_accuracy: 0.9692 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0847 - accuracy: 0.9677 - val_loss: 0.0871 - val_accuracy: 0.9709 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0775 - accuracy: 0.9728 - val_loss: 0.0861 - val_accuracy: 0.9675 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0722 - accuracy: 0.9747 - val_loss: 0.0771 - val_accuracy: 0.9744 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 38ms/step - loss: 0.8518 - accuracy: 0.6028 - val_loss: 0.3704 - val_accuracy: 0.8462 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.3959 - accuracy: 0.8259 - val_loss: 0.3538 - val_accuracy: 0.8359 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.3608 - accuracy: 0.8383 - val_loss: 0.1886 - val_accuracy: 0.9350 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1805 - accuracy: 0.9298 - val_loss: 0.1100 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1227 - accuracy: 0.9528 - val_loss: 0.1315 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0959 - accuracy: 0.9627 - val_loss: 0.1300 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0929 - accuracy: 0.9655 - val_loss: 0.0960 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0715 - accuracy: 0.9748\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0715 - accuracy: 0.9748 - val_loss: 0.1221 - val_accuracy: 0.9470 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0517 - accuracy: 0.9810 - val_loss: 0.0856 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0415 - accuracy: 0.9851 - val_loss: 0.0746 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 37ms/step - loss: 0.8002 - accuracy: 0.5896 - val_loss: 0.5173 - val_accuracy: 0.7248 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.3165 - accuracy: 0.8676 - val_loss: 0.2411 - val_accuracy: 0.9162 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1850 - accuracy: 0.9288 - val_loss: 0.1815 - val_accuracy: 0.9333 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1441 - accuracy: 0.9481 - val_loss: 0.1537 - val_accuracy: 0.9419 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1319 - accuracy: 0.9505 - val_loss: 0.1335 - val_accuracy: 0.9521 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1137 - accuracy: 0.9614 - val_loss: 0.1267 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1070 - accuracy: 0.9628 - val_loss: 0.1735 - val_accuracy: 0.9299 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0994 - accuracy: 0.9648\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0994 - accuracy: 0.9648 - val_loss: 0.1231 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0718 - accuracy: 0.9738 - val_loss: 0.0869 - val_accuracy: 0.9658 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0667 - accuracy: 0.9755 - val_loss: 0.0689 - val_accuracy: 0.9829 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 10s 49ms/step - loss: 0.8037 - accuracy: 0.6246 - val_loss: 0.4609 - val_accuracy: 0.7641 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.2278 - accuracy: 0.9096 - val_loss: 0.1245 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1155 - accuracy: 0.9586 - val_loss: 0.1041 - val_accuracy: 0.9607 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0986 - accuracy: 0.9651 - val_loss: 0.0875 - val_accuracy: 0.9829 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0914 - accuracy: 0.9668 - val_loss: 0.0719 - val_accuracy: 0.9829 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0777 - accuracy: 0.9713\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0777 - accuracy: 0.9713 - val_loss: 0.0821 - val_accuracy: 0.9795 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0559 - accuracy: 0.9810 - val_loss: 0.0666 - val_accuracy: 0.9761 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0463 - accuracy: 0.9834\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0463 - accuracy: 0.9834 - val_loss: 0.0686 - val_accuracy: 0.9829 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0390 - accuracy: 0.9843 - val_loss: 0.0630 - val_accuracy: 0.9744 - lr: 9.0000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0367 - accuracy: 0.9868\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0367 - accuracy: 0.9868 - val_loss: 0.0633 - val_accuracy: 0.9761 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 10s 51ms/step - loss: 0.6208 - accuracy: 0.7618 - val_loss: 0.2166 - val_accuracy: 0.9368 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1516 - accuracy: 0.9426 - val_loss: 0.1101 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1141 - accuracy: 0.9571 - val_loss: 0.1078 - val_accuracy: 0.9778 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0938 - accuracy: 0.9666 - val_loss: 0.1093 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0843 - accuracy: 0.9686\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0843 - accuracy: 0.9686 - val_loss: 0.0835 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0596 - accuracy: 0.9792 - val_loss: 0.0669 - val_accuracy: 0.9778 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0512 - accuracy: 0.9827\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0512 - accuracy: 0.9827 - val_loss: 0.0592 - val_accuracy: 0.9778 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0434 - accuracy: 0.9844 - val_loss: 0.0657 - val_accuracy: 0.9795 - lr: 9.0000e-05\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0399 - accuracy: 0.9851 - val_loss: 0.0641 - val_accuracy: 0.9778 - lr: 9.0000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0375 - accuracy: 0.9874 - val_loss: 0.0591 - val_accuracy: 0.9829 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 41ms/step - loss: 1.2488 - accuracy: 0.6602 - val_loss: 0.4073 - val_accuracy: 0.8171 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.2998 - accuracy: 0.8704 - val_loss: 0.2975 - val_accuracy: 0.8838 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1958 - accuracy: 0.9262 - val_loss: 0.1176 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1270 - accuracy: 0.9535 - val_loss: 0.1022 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1099 - accuracy: 0.9615 - val_loss: 0.0918 - val_accuracy: 0.9778 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0835 - accuracy: 0.9718 - val_loss: 0.0724 - val_accuracy: 0.9795 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0751 - accuracy: 0.9718 - val_loss: 0.1334 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0684 - accuracy: 0.9748\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0684 - accuracy: 0.9748 - val_loss: 0.0966 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0438 - accuracy: 0.9850 - val_loss: 0.0784 - val_accuracy: 0.9675 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0347 - accuracy: 0.9878\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0347 - accuracy: 0.9878 - val_loss: 0.0651 - val_accuracy: 0.9795 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 9s 47ms/step - loss: 0.8667 - accuracy: 0.7028 - val_loss: 0.4221 - val_accuracy: 0.8205 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.2680 - accuracy: 0.8942 - val_loss: 0.1808 - val_accuracy: 0.9402 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1319 - accuracy: 0.9505 - val_loss: 0.1515 - val_accuracy: 0.9521 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0999 - accuracy: 0.9660 - val_loss: 0.1204 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0814 - accuracy: 0.9683 - val_loss: 0.1136 - val_accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0673 - accuracy: 0.9775\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0673 - accuracy: 0.9775 - val_loss: 0.0983 - val_accuracy: 0.9607 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0480 - accuracy: 0.9825 - val_loss: 0.0656 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0352 - accuracy: 0.9873 - val_loss: 0.0732 - val_accuracy: 0.9692 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0296 - accuracy: 0.9890\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0296 - accuracy: 0.9890 - val_loss: 0.0862 - val_accuracy: 0.9692 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0238 - accuracy: 0.9925 - val_loss: 0.0658 - val_accuracy: 0.9726 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 9s 48ms/step - loss: 0.8223 - accuracy: 0.6210 - val_loss: 0.4518 - val_accuracy: 0.7726 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.2503 - accuracy: 0.8950 - val_loss: 0.1214 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1164 - accuracy: 0.9559 - val_loss: 0.0840 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1190 - accuracy: 0.9561 - val_loss: 0.0781 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0869 - accuracy: 0.9645 - val_loss: 0.0718 - val_accuracy: 0.9761 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0714 - accuracy: 0.9731 - val_loss: 0.0981 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0670 - accuracy: 0.9772\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0670 - accuracy: 0.9772 - val_loss: 0.0910 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0412 - accuracy: 0.9843 - val_loss: 0.0701 - val_accuracy: 0.9795 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0351 - accuracy: 0.9861 - val_loss: 0.0736 - val_accuracy: 0.9812 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0294 - accuracy: 0.9876 - val_loss: 0.0536 - val_accuracy: 0.9829 - lr: 3.0000e-04\n",
            "Best Accuracy at the generation 5: 99.46244359016418\n",
            "[[42 50 85  6 14 19]\n",
            " [43 37 84  4 10 18]\n",
            " [45 47 87  5 15 20]\n",
            " [43 47 90  9 14 19]\n",
            " [45 37 87  4 10 17]\n",
            " [46 50 84  6 14 15]\n",
            " [43 41 87  7 10 20]\n",
            " [45 51 90  5 15 20]\n",
            " [43 47 90 12 14 17]\n",
            " [48 37 85  4 11 19]]\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 38ms/step - loss: 0.6840 - accuracy: 0.7052 - val_loss: 0.2145 - val_accuracy: 0.9453 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1914 - accuracy: 0.9256 - val_loss: 0.1429 - val_accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1364 - accuracy: 0.9499 - val_loss: 0.1101 - val_accuracy: 0.9726 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1114 - accuracy: 0.9607 - val_loss: 0.0730 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1042 - accuracy: 0.9614 - val_loss: 0.0858 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0885 - accuracy: 0.9682 - val_loss: 0.1033 - val_accuracy: 0.9778 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0797 - accuracy: 0.9693 - val_loss: 0.1134 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0776 - accuracy: 0.9726\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0776 - accuracy: 0.9726 - val_loss: 0.0897 - val_accuracy: 0.9726 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0493 - accuracy: 0.9812 - val_loss: 0.0750 - val_accuracy: 0.9778 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0448 - accuracy: 0.9840 - val_loss: 0.0611 - val_accuracy: 0.9829 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 7s 37ms/step - loss: 0.5811 - accuracy: 0.7510 - val_loss: 0.2309 - val_accuracy: 0.9145 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1497 - accuracy: 0.9420 - val_loss: 0.1257 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1409 - accuracy: 0.9509 - val_loss: 0.1160 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0999 - accuracy: 0.9649 - val_loss: 0.1005 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0853 - accuracy: 0.9699\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0853 - accuracy: 0.9699 - val_loss: 0.1038 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0615 - accuracy: 0.9789 - val_loss: 0.0735 - val_accuracy: 0.9812 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0566 - accuracy: 0.9805 - val_loss: 0.0741 - val_accuracy: 0.9846 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0468 - accuracy: 0.9829 - val_loss: 0.0746 - val_accuracy: 0.9829 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0426 - accuracy: 0.9859\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0426 - accuracy: 0.9859 - val_loss: 0.0700 - val_accuracy: 0.9795 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0351 - accuracy: 0.9876 - val_loss: 0.0699 - val_accuracy: 0.9829 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 40ms/step - loss: 0.9377 - accuracy: 0.7991 - val_loss: 0.2084 - val_accuracy: 0.9197 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1407 - accuracy: 0.9491 - val_loss: 0.1719 - val_accuracy: 0.9299 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.1290 - accuracy: 0.9540 - val_loss: 0.1779 - val_accuracy: 0.9316 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.1157 - accuracy: 0.9581 - val_loss: 0.1062 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0987 - accuracy: 0.9655 - val_loss: 0.1168 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0898 - accuracy: 0.9682\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0898 - accuracy: 0.9682 - val_loss: 0.1170 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0677 - accuracy: 0.9764 - val_loss: 0.0817 - val_accuracy: 0.9658 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0570 - accuracy: 0.9795 - val_loss: 0.0800 - val_accuracy: 0.9761 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0543 - accuracy: 0.9803 - val_loss: 0.0853 - val_accuracy: 0.9709 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0503 - accuracy: 0.9830\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0503 - accuracy: 0.9830 - val_loss: 0.0822 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 40ms/step - loss: 0.9736 - accuracy: 0.6466 - val_loss: 0.3782 - val_accuracy: 0.8376 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.1627 - accuracy: 0.9359 - val_loss: 0.1423 - val_accuracy: 0.9556 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.1171 - accuracy: 0.9554 - val_loss: 0.1579 - val_accuracy: 0.9436 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0951 - accuracy: 0.9666 - val_loss: 0.0979 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0840 - accuracy: 0.9706 - val_loss: 0.1036 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0774 - accuracy: 0.9686 - val_loss: 0.1434 - val_accuracy: 0.9368 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0661 - accuracy: 0.9765\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0661 - accuracy: 0.9765 - val_loss: 0.0943 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0404 - accuracy: 0.9860 - val_loss: 0.0963 - val_accuracy: 0.9607 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0347 - accuracy: 0.9861\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0347 - accuracy: 0.9861 - val_loss: 0.0956 - val_accuracy: 0.9675 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0270 - accuracy: 0.9900 - val_loss: 0.0930 - val_accuracy: 0.9692 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 36ms/step - loss: 0.6158 - accuracy: 0.7299 - val_loss: 0.2492 - val_accuracy: 0.8991 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.2035 - accuracy: 0.9199 - val_loss: 0.1521 - val_accuracy: 0.9521 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1564 - accuracy: 0.9402 - val_loss: 0.1334 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1213 - accuracy: 0.9574 - val_loss: 0.0840 - val_accuracy: 0.9761 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1055 - accuracy: 0.9635 - val_loss: 0.0776 - val_accuracy: 0.9812 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0893 - accuracy: 0.9676 - val_loss: 0.1306 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0843 - accuracy: 0.9694\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0843 - accuracy: 0.9694 - val_loss: 0.1346 - val_accuracy: 0.9470 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0585 - accuracy: 0.9792 - val_loss: 0.0658 - val_accuracy: 0.9812 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0470 - accuracy: 0.9837\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0470 - accuracy: 0.9837 - val_loss: 0.0760 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0378 - accuracy: 0.9878 - val_loss: 0.0641 - val_accuracy: 0.9761 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 12s 56ms/step - loss: 0.6891 - accuracy: 0.6421 - val_loss: 0.4882 - val_accuracy: 0.7744 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.3064 - accuracy: 0.8679 - val_loss: 0.3688 - val_accuracy: 0.8342 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.2434 - accuracy: 0.9015 - val_loss: 0.2953 - val_accuracy: 0.8701 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.2015 - accuracy: 0.9213 - val_loss: 0.2155 - val_accuracy: 0.9077 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1473 - accuracy: 0.9450 - val_loss: 0.1647 - val_accuracy: 0.9385 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1170 - accuracy: 0.9578 - val_loss: 0.1928 - val_accuracy: 0.9282 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.1138 - accuracy: 0.9577\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1138 - accuracy: 0.9577 - val_loss: 0.2620 - val_accuracy: 0.8957 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0816 - accuracy: 0.9709 - val_loss: 0.0929 - val_accuracy: 0.9709 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0545 - accuracy: 0.9813 - val_loss: 0.0854 - val_accuracy: 0.9709 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0456 - accuracy: 0.9842\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0456 - accuracy: 0.9842 - val_loss: 0.0932 - val_accuracy: 0.9675 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 11s 52ms/step - loss: 0.6544 - accuracy: 0.6591 - val_loss: 0.3399 - val_accuracy: 0.8547 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1943 - accuracy: 0.9252 - val_loss: 0.1635 - val_accuracy: 0.9419 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1416 - accuracy: 0.9477 - val_loss: 0.1309 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1251 - accuracy: 0.9550 - val_loss: 0.1419 - val_accuracy: 0.9453 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.1214 - accuracy: 0.9578\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1214 - accuracy: 0.9578 - val_loss: 0.1176 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0904 - accuracy: 0.9680 - val_loss: 0.1050 - val_accuracy: 0.9744 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0851 - accuracy: 0.9685 - val_loss: 0.1048 - val_accuracy: 0.9709 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0780 - accuracy: 0.9723\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0780 - accuracy: 0.9723 - val_loss: 0.1035 - val_accuracy: 0.9658 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0694 - accuracy: 0.9757 - val_loss: 0.1110 - val_accuracy: 0.9624 - lr: 9.0000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0675 - accuracy: 0.9760\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0675 - accuracy: 0.9760 - val_loss: 0.1070 - val_accuracy: 0.9607 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 14s 65ms/step - loss: 0.8570 - accuracy: 0.6844 - val_loss: 0.3065 - val_accuracy: 0.8906 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.2382 - accuracy: 0.9020 - val_loss: 0.1982 - val_accuracy: 0.9265 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1624 - accuracy: 0.9428 - val_loss: 0.1552 - val_accuracy: 0.9368 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1187 - accuracy: 0.9566 - val_loss: 0.1408 - val_accuracy: 0.9385 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0880 - accuracy: 0.9694 - val_loss: 0.0887 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0760 - accuracy: 0.9747 - val_loss: 0.0804 - val_accuracy: 0.9761 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0609 - accuracy: 0.9779 - val_loss: 0.0803 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0523 - accuracy: 0.9816\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0523 - accuracy: 0.9816 - val_loss: 0.0820 - val_accuracy: 0.9726 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0299 - accuracy: 0.9901 - val_loss: 0.0608 - val_accuracy: 0.9829 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0234 - accuracy: 0.9917 - val_loss: 0.0544 - val_accuracy: 0.9812 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 9s 49ms/step - loss: 0.7820 - accuracy: 0.7304 - val_loss: 0.2958 - val_accuracy: 0.8855 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1676 - accuracy: 0.9375 - val_loss: 0.1850 - val_accuracy: 0.9470 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1472 - accuracy: 0.9426 - val_loss: 0.2201 - val_accuracy: 0.9419 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.1759 - accuracy: 0.9431\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1759 - accuracy: 0.9431 - val_loss: 0.2502 - val_accuracy: 0.9026 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1348 - accuracy: 0.9499 - val_loss: 0.1597 - val_accuracy: 0.9316 - lr: 3.0000e-04\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.1061 - accuracy: 0.9611\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1061 - accuracy: 0.9611 - val_loss: 0.1662 - val_accuracy: 0.9350 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0911 - accuracy: 0.9665 - val_loss: 0.1519 - val_accuracy: 0.9470 - lr: 9.0000e-05\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0890 - accuracy: 0.9692 - val_loss: 0.1328 - val_accuracy: 0.9538 - lr: 9.0000e-05\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0861 - accuracy: 0.9675 - val_loss: 0.1349 - val_accuracy: 0.9521 - lr: 9.0000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0814 - accuracy: 0.9718 - val_loss: 0.1280 - val_accuracy: 0.9590 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 11s 54ms/step - loss: 0.8250 - accuracy: 0.6896 - val_loss: 0.3065 - val_accuracy: 0.8855 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.3472 - accuracy: 0.8448 - val_loss: 0.2021 - val_accuracy: 0.9350 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1849 - accuracy: 0.9288 - val_loss: 0.1489 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1048 - accuracy: 0.9601 - val_loss: 0.0841 - val_accuracy: 0.9761 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0863 - accuracy: 0.9680 - val_loss: 0.1102 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0668 - accuracy: 0.9760\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0668 - accuracy: 0.9760 - val_loss: 0.0827 - val_accuracy: 0.9761 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0435 - accuracy: 0.9859 - val_loss: 0.0651 - val_accuracy: 0.9778 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0322 - accuracy: 0.9888 - val_loss: 0.0706 - val_accuracy: 0.9761 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0279 - accuracy: 0.9905\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0279 - accuracy: 0.9905 - val_loss: 0.0737 - val_accuracy: 0.9761 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0216 - accuracy: 0.9925 - val_loss: 0.0697 - val_accuracy: 0.9726 - lr: 9.0000e-05\n",
            "Best Accuracy at the generation 6: 99.46244359016418\n",
            "[[48 37 85  4 11 19]\n",
            " [45 51 90  5 15 20]\n",
            " [43 47 90  9 14 19]\n",
            " [45 37 87  4 10 17]\n",
            " [43 37 84  4 10 18]\n",
            " [48 38 90  5 11 20]\n",
            " [45 54 90  7 15 19]\n",
            " [43 50 87  9 15 17]\n",
            " [45 37 85  4 10 20]\n",
            " [44 37 85  4 10 17]]\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 36ms/step - loss: 1.0888 - accuracy: 0.5316 - val_loss: 0.5434 - val_accuracy: 0.6855 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.3907 - accuracy: 0.8223 - val_loss: 0.2376 - val_accuracy: 0.8889 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.2157 - accuracy: 0.9196 - val_loss: 0.1569 - val_accuracy: 0.9556 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1279 - accuracy: 0.9533 - val_loss: 0.1183 - val_accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1175 - accuracy: 0.9594 - val_loss: 0.1125 - val_accuracy: 0.9556 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0957 - accuracy: 0.9673 - val_loss: 0.1073 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0861 - accuracy: 0.9689 - val_loss: 0.0839 - val_accuracy: 0.9812 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0887 - accuracy: 0.9680 - val_loss: 0.0944 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0779 - accuracy: 0.9728\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0779 - accuracy: 0.9728 - val_loss: 0.0841 - val_accuracy: 0.9761 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0575 - accuracy: 0.9802 - val_loss: 0.0682 - val_accuracy: 0.9829 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 41ms/step - loss: 0.8615 - accuracy: 0.6755 - val_loss: 0.2910 - val_accuracy: 0.8769 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.2224 - accuracy: 0.9124 - val_loss: 0.1757 - val_accuracy: 0.9299 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1397 - accuracy: 0.9468 - val_loss: 0.1239 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1087 - accuracy: 0.9610 - val_loss: 0.0742 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0905 - accuracy: 0.9660 - val_loss: 0.0915 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.9723\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0764 - accuracy: 0.9723 - val_loss: 0.1134 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0530 - accuracy: 0.9820 - val_loss: 0.0609 - val_accuracy: 0.9829 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0430 - accuracy: 0.9850 - val_loss: 0.0644 - val_accuracy: 0.9778 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0372 - accuracy: 0.9874\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0372 - accuracy: 0.9874 - val_loss: 0.0610 - val_accuracy: 0.9829 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0304 - accuracy: 0.9908 - val_loss: 0.0611 - val_accuracy: 0.9812 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 39ms/step - loss: 1.0916 - accuracy: 0.5726 - val_loss: 0.6405 - val_accuracy: 0.4872 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.5910 - accuracy: 0.6933 - val_loss: 0.5008 - val_accuracy: 0.7726 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.3762 - accuracy: 0.8360 - val_loss: 0.2481 - val_accuracy: 0.9145 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.1993 - accuracy: 0.9252 - val_loss: 0.1615 - val_accuracy: 0.9402 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.1312 - accuracy: 0.9501 - val_loss: 0.1196 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0988 - accuracy: 0.9649 - val_loss: 0.1962 - val_accuracy: 0.9111 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0822 - accuracy: 0.9700 - val_loss: 0.1110 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0729 - accuracy: 0.9721 - val_loss: 0.1068 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0544 - accuracy: 0.9802 - val_loss: 0.0989 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0513 - accuracy: 0.9801 - val_loss: 0.1081 - val_accuracy: 0.9556 - lr: 0.0010\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 37ms/step - loss: 0.9225 - accuracy: 0.6782 - val_loss: 0.2316 - val_accuracy: 0.9026 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.2133 - accuracy: 0.9184 - val_loss: 0.1225 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1236 - accuracy: 0.9530 - val_loss: 0.1215 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1057 - accuracy: 0.9641 - val_loss: 0.0972 - val_accuracy: 0.9726 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0880 - accuracy: 0.9668 - val_loss: 0.0943 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0836 - accuracy: 0.9694\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0836 - accuracy: 0.9694 - val_loss: 0.1583 - val_accuracy: 0.9487 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0659 - accuracy: 0.9765 - val_loss: 0.0751 - val_accuracy: 0.9795 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0503 - accuracy: 0.9816 - val_loss: 0.0695 - val_accuracy: 0.9846 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0472 - accuracy: 0.9843 - val_loss: 0.0853 - val_accuracy: 0.9709 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0440 - accuracy: 0.9837\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0440 - accuracy: 0.9837 - val_loss: 0.0759 - val_accuracy: 0.9829 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 36ms/step - loss: 0.7236 - accuracy: 0.7308 - val_loss: 0.2095 - val_accuracy: 0.9333 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1526 - accuracy: 0.9438 - val_loss: 0.1586 - val_accuracy: 0.9419 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1126 - accuracy: 0.9586 - val_loss: 0.0810 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0891 - accuracy: 0.9697 - val_loss: 0.0815 - val_accuracy: 0.9761 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0822 - accuracy: 0.9702 - val_loss: 0.0826 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0764 - accuracy: 0.9727 - val_loss: 0.0712 - val_accuracy: 0.9829 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0632 - accuracy: 0.9767 - val_loss: 0.0751 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0503 - accuracy: 0.9820\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0503 - accuracy: 0.9820 - val_loss: 0.0711 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0336 - accuracy: 0.9883 - val_loss: 0.0870 - val_accuracy: 0.9658 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0290 - accuracy: 0.9898\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0290 - accuracy: 0.9898 - val_loss: 0.0680 - val_accuracy: 0.9744 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 12s 55ms/step - loss: 0.8803 - accuracy: 0.5769 - val_loss: 0.6007 - val_accuracy: 0.8137 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.4162 - accuracy: 0.8003 - val_loss: 0.3364 - val_accuracy: 0.8444 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.2757 - accuracy: 0.8822 - val_loss: 0.2133 - val_accuracy: 0.9197 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1925 - accuracy: 0.9262 - val_loss: 0.1786 - val_accuracy: 0.9265 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1416 - accuracy: 0.9479 - val_loss: 0.0899 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1089 - accuracy: 0.9627 - val_loss: 0.0903 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0861 - accuracy: 0.9686 - val_loss: 0.1067 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0757 - accuracy: 0.9724 - val_loss: 0.0506 - val_accuracy: 0.9880 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0696 - accuracy: 0.9723 - val_loss: 0.0708 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0562 - accuracy: 0.9806\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0562 - accuracy: 0.9806 - val_loss: 0.0868 - val_accuracy: 0.9761 - lr: 0.0010\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 14s 66ms/step - loss: 0.8735 - accuracy: 0.6823 - val_loss: 0.5362 - val_accuracy: 0.6906 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.2760 - accuracy: 0.8858 - val_loss: 0.1321 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1428 - accuracy: 0.9465 - val_loss: 0.1477 - val_accuracy: 0.9470 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.1099 - accuracy: 0.9594\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1099 - accuracy: 0.9594 - val_loss: 0.1137 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0776 - accuracy: 0.9730 - val_loss: 0.1012 - val_accuracy: 0.9573 - lr: 3.0000e-04\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0693 - accuracy: 0.9764\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0693 - accuracy: 0.9764 - val_loss: 0.1049 - val_accuracy: 0.9470 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0592 - accuracy: 0.9793 - val_loss: 0.0692 - val_accuracy: 0.9778 - lr: 9.0000e-05\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0550 - accuracy: 0.9803 - val_loss: 0.0835 - val_accuracy: 0.9709 - lr: 9.0000e-05\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0544 - accuracy: 0.9796\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0544 - accuracy: 0.9796 - val_loss: 0.0919 - val_accuracy: 0.9607 - lr: 9.0000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0505 - accuracy: 0.9822 - val_loss: 0.0799 - val_accuracy: 0.9726 - lr: 2.7000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 13s 61ms/step - loss: 1.0684 - accuracy: 0.6545 - val_loss: 0.3991 - val_accuracy: 0.8085 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.3281 - accuracy: 0.8581 - val_loss: 0.2307 - val_accuracy: 0.9043 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.2345 - accuracy: 0.9037 - val_loss: 0.2546 - val_accuracy: 0.8889 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1753 - accuracy: 0.9318 - val_loss: 0.1082 - val_accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1205 - accuracy: 0.9557 - val_loss: 0.1208 - val_accuracy: 0.9521 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0876 - accuracy: 0.9689\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0876 - accuracy: 0.9689 - val_loss: 0.1259 - val_accuracy: 0.9521 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0640 - accuracy: 0.9772 - val_loss: 0.0839 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0563 - accuracy: 0.9802 - val_loss: 0.0757 - val_accuracy: 0.9744 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0496 - accuracy: 0.9825 - val_loss: 0.0743 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0434 - accuracy: 0.9846\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0434 - accuracy: 0.9846 - val_loss: 0.0859 - val_accuracy: 0.9692 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 8s 44ms/step - loss: 0.5378 - accuracy: 0.7322 - val_loss: 0.1464 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1221 - accuracy: 0.9553 - val_loss: 0.0766 - val_accuracy: 0.9761 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0897 - accuracy: 0.9662 - val_loss: 0.0877 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0681 - accuracy: 0.9757\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0681 - accuracy: 0.9757 - val_loss: 0.0640 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0443 - accuracy: 0.9832 - val_loss: 0.0896 - val_accuracy: 0.9624 - lr: 3.0000e-04\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0361 - accuracy: 0.9861 - val_loss: 0.0520 - val_accuracy: 0.9812 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0313 - accuracy: 0.9897 - val_loss: 0.0660 - val_accuracy: 0.9744 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 0.9909\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0249 - accuracy: 0.9909 - val_loss: 0.0602 - val_accuracy: 0.9778 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0165 - accuracy: 0.9943 - val_loss: 0.0668 - val_accuracy: 0.9761 - lr: 9.0000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0165 - accuracy: 0.9955\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0165 - accuracy: 0.9955 - val_loss: 0.0558 - val_accuracy: 0.9744 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 7s 41ms/step - loss: 0.5554 - accuracy: 0.7123 - val_loss: 0.1611 - val_accuracy: 0.9350 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1330 - accuracy: 0.9522 - val_loss: 0.1164 - val_accuracy: 0.9504 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1158 - accuracy: 0.9597 - val_loss: 0.1309 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0879 - accuracy: 0.9677 - val_loss: 0.0948 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1028 - accuracy: 0.9627 - val_loss: 0.1149 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0814 - accuracy: 0.9707 - val_loss: 0.1210 - val_accuracy: 0.9419 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0846 - accuracy: 0.9659 - val_loss: 0.1007 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0581 - accuracy: 0.9779 - val_loss: 0.0819 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0537 - accuracy: 0.9806 - val_loss: 0.0700 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0516 - accuracy: 0.9823 - val_loss: 0.0735 - val_accuracy: 0.9812 - lr: 0.0010\n",
            "Best Accuracy at the generation 7: 99.54732060432434\n",
            "[[45 37 85  4 10 20]\n",
            " [45 51 90  5 15 20]\n",
            " [43 37 84  4 10 18]\n",
            " [43 50 87  9 15 17]\n",
            " [45 37 87  4 10 17]\n",
            " [45 37 92  4 10 17]\n",
            " [45 51 89  8 15 18]\n",
            " [43 37 89  5 10 17]\n",
            " [43 53 87  9 15 18]\n",
            " [45 39 85  4 10 18]]\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 37ms/step - loss: 0.5822 - accuracy: 0.7554 - val_loss: 0.1439 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1509 - accuracy: 0.9414 - val_loss: 0.1457 - val_accuracy: 0.9453 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1072 - accuracy: 0.9612 - val_loss: 0.0958 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0967 - accuracy: 0.9635 - val_loss: 0.0664 - val_accuracy: 0.9778 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0926 - accuracy: 0.9673 - val_loss: 0.0588 - val_accuracy: 0.9812 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0791 - accuracy: 0.9713 - val_loss: 0.1496 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0737 - accuracy: 0.9721\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0737 - accuracy: 0.9721 - val_loss: 0.0737 - val_accuracy: 0.9761 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0457 - accuracy: 0.9829 - val_loss: 0.0793 - val_accuracy: 0.9744 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0367 - accuracy: 0.9868\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0367 - accuracy: 0.9868 - val_loss: 0.0881 - val_accuracy: 0.9658 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0308 - accuracy: 0.9883 - val_loss: 0.0772 - val_accuracy: 0.9726 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 41ms/step - loss: 0.8569 - accuracy: 0.7155 - val_loss: 0.1753 - val_accuracy: 0.9436 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.1577 - accuracy: 0.9420 - val_loss: 0.1355 - val_accuracy: 0.9556 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1126 - accuracy: 0.9583 - val_loss: 0.1131 - val_accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0919 - accuracy: 0.9670 - val_loss: 0.0973 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0820 - accuracy: 0.9700 - val_loss: 0.0927 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0780 - accuracy: 0.9730 - val_loss: 0.1029 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0790 - accuracy: 0.9714\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0790 - accuracy: 0.9714 - val_loss: 0.1112 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0529 - accuracy: 0.9813 - val_loss: 0.0765 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0448 - accuracy: 0.9849 - val_loss: 0.0842 - val_accuracy: 0.9692 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0409 - accuracy: 0.9863\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0409 - accuracy: 0.9863 - val_loss: 0.0950 - val_accuracy: 0.9709 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 36ms/step - loss: 0.6075 - accuracy: 0.6711 - val_loss: 0.2040 - val_accuracy: 0.9556 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1726 - accuracy: 0.9359 - val_loss: 0.1258 - val_accuracy: 0.9556 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.1087 - accuracy: 0.9588\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1087 - accuracy: 0.9588 - val_loss: 0.1179 - val_accuracy: 0.9556 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0791 - accuracy: 0.9710 - val_loss: 0.0836 - val_accuracy: 0.9761 - lr: 3.0000e-04\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0663 - accuracy: 0.9741 - val_loss: 0.0892 - val_accuracy: 0.9658 - lr: 3.0000e-04\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0609 - accuracy: 0.9772\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0609 - accuracy: 0.9772 - val_loss: 0.0800 - val_accuracy: 0.9761 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0496 - accuracy: 0.9818 - val_loss: 0.0745 - val_accuracy: 0.9812 - lr: 9.0000e-05\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0455 - accuracy: 0.9829 - val_loss: 0.0777 - val_accuracy: 0.9761 - lr: 9.0000e-05\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0444 - accuracy: 0.9832\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0444 - accuracy: 0.9832 - val_loss: 0.0810 - val_accuracy: 0.9744 - lr: 9.0000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0403 - accuracy: 0.9857 - val_loss: 0.0750 - val_accuracy: 0.9795 - lr: 2.7000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 41ms/step - loss: 1.4992 - accuracy: 0.6830 - val_loss: 0.3756 - val_accuracy: 0.8462 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1866 - accuracy: 0.9263 - val_loss: 0.1477 - val_accuracy: 0.9504 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1365 - accuracy: 0.9482 - val_loss: 0.1401 - val_accuracy: 0.9521 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1140 - accuracy: 0.9573 - val_loss: 0.1350 - val_accuracy: 0.9470 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0968 - accuracy: 0.9663 - val_loss: 0.1111 - val_accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0844 - accuracy: 0.9683 - val_loss: 0.0936 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0883 - accuracy: 0.9685 - val_loss: 0.1312 - val_accuracy: 0.9487 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0951 - accuracy: 0.9658\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0951 - accuracy: 0.9658 - val_loss: 0.1024 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0574 - accuracy: 0.9799 - val_loss: 0.1001 - val_accuracy: 0.9607 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0537 - accuracy: 0.9812\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0537 - accuracy: 0.9812 - val_loss: 0.0831 - val_accuracy: 0.9658 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 37ms/step - loss: 0.6041 - accuracy: 0.7189 - val_loss: 0.1795 - val_accuracy: 0.9402 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1412 - accuracy: 0.9484 - val_loss: 0.1159 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1251 - accuracy: 0.9542 - val_loss: 0.1429 - val_accuracy: 0.9504 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0892 - accuracy: 0.9680\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0892 - accuracy: 0.9680 - val_loss: 0.0821 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0638 - accuracy: 0.9782 - val_loss: 0.0964 - val_accuracy: 0.9590 - lr: 3.0000e-04\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0581 - accuracy: 0.9795\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0581 - accuracy: 0.9795 - val_loss: 0.0830 - val_accuracy: 0.9675 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0494 - accuracy: 0.9825 - val_loss: 0.0753 - val_accuracy: 0.9709 - lr: 9.0000e-05\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0461 - accuracy: 0.9842\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0461 - accuracy: 0.9842 - val_loss: 0.0793 - val_accuracy: 0.9692 - lr: 9.0000e-05\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0422 - accuracy: 0.9844 - val_loss: 0.0761 - val_accuracy: 0.9675 - lr: 2.7000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0421 - accuracy: 0.9854\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0421 - accuracy: 0.9854 - val_loss: 0.0794 - val_accuracy: 0.9675 - lr: 2.7000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 8s 42ms/step - loss: 0.5864 - accuracy: 0.7253 - val_loss: 0.2601 - val_accuracy: 0.9060 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1516 - accuracy: 0.9406 - val_loss: 0.1027 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1091 - accuracy: 0.9614 - val_loss: 0.0891 - val_accuracy: 0.9846 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0867 - accuracy: 0.9679 - val_loss: 0.0781 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0752 - accuracy: 0.9724\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0752 - accuracy: 0.9724 - val_loss: 0.0781 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0506 - accuracy: 0.9819 - val_loss: 0.0633 - val_accuracy: 0.9846 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0442 - accuracy: 0.9850\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0442 - accuracy: 0.9850 - val_loss: 0.0548 - val_accuracy: 0.9846 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0334 - accuracy: 0.9878 - val_loss: 0.0581 - val_accuracy: 0.9846 - lr: 9.0000e-05\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0319 - accuracy: 0.9897\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0319 - accuracy: 0.9897 - val_loss: 0.0551 - val_accuracy: 0.9846 - lr: 9.0000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0290 - accuracy: 0.9907 - val_loss: 0.0528 - val_accuracy: 0.9863 - lr: 2.7000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 9s 50ms/step - loss: 0.8113 - accuracy: 0.6332 - val_loss: 0.3767 - val_accuracy: 0.8342 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.4480 - accuracy: 0.8229 - val_loss: 0.2987 - val_accuracy: 0.8838 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.2862 - accuracy: 0.8766 - val_loss: 0.1818 - val_accuracy: 0.9299 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.2559 - accuracy: 0.8925 - val_loss: 0.2529 - val_accuracy: 0.8991 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 40ms/step - loss: 0.1379 - accuracy: 0.9467 - val_loss: 0.0972 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 40ms/step - loss: 0.1074 - accuracy: 0.9601 - val_loss: 0.1086 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0896 - accuracy: 0.9655\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 40ms/step - loss: 0.0896 - accuracy: 0.9655 - val_loss: 0.1128 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 40ms/step - loss: 0.0666 - accuracy: 0.9747 - val_loss: 0.1068 - val_accuracy: 0.9675 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 40ms/step - loss: 0.0580 - accuracy: 0.9782 - val_loss: 0.1110 - val_accuracy: 0.9624 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 40ms/step - loss: 0.0539 - accuracy: 0.9798 - val_loss: 0.0883 - val_accuracy: 0.9709 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 7s 41ms/step - loss: 0.8290 - accuracy: 0.5833 - val_loss: 0.3530 - val_accuracy: 0.8752 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.4186 - accuracy: 0.8175 - val_loss: 0.4182 - val_accuracy: 0.8188 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.3066 - accuracy: 0.8686\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.3066 - accuracy: 0.8686 - val_loss: 0.2937 - val_accuracy: 0.8718 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.2137 - accuracy: 0.9119 - val_loss: 0.1931 - val_accuracy: 0.9077 - lr: 3.0000e-04\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1787 - accuracy: 0.9279 - val_loss: 0.1750 - val_accuracy: 0.9333 - lr: 3.0000e-04\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1622 - accuracy: 0.9376 - val_loss: 0.1621 - val_accuracy: 0.9402 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1475 - accuracy: 0.9424 - val_loss: 0.1600 - val_accuracy: 0.9487 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1372 - accuracy: 0.9470 - val_loss: 0.1593 - val_accuracy: 0.9419 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.1195 - accuracy: 0.9552\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1195 - accuracy: 0.9552 - val_loss: 0.1455 - val_accuracy: 0.9470 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1012 - accuracy: 0.9619 - val_loss: 0.1296 - val_accuracy: 0.9556 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 14s 63ms/step - loss: 0.8671 - accuracy: 0.7123 - val_loss: 0.3201 - val_accuracy: 0.8667 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.2345 - accuracy: 0.9052 - val_loss: 0.1769 - val_accuracy: 0.9299 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1539 - accuracy: 0.9436 - val_loss: 0.1238 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0932 - accuracy: 0.9660 - val_loss: 0.0874 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0865 - accuracy: 0.9677 - val_loss: 0.0791 - val_accuracy: 0.9726 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0724 - accuracy: 0.9747 - val_loss: 0.0670 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0652 - accuracy: 0.9785 - val_loss: 0.0738 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0597 - accuracy: 0.9781 - val_loss: 0.0615 - val_accuracy: 0.9778 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0468 - accuracy: 0.9840 - val_loss: 0.0810 - val_accuracy: 0.9726 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0489 - accuracy: 0.9819\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0489 - accuracy: 0.9819 - val_loss: 0.0788 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 10s 51ms/step - loss: 0.7619 - accuracy: 0.5196 - val_loss: 0.3965 - val_accuracy: 0.8068 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.3465 - accuracy: 0.8468 - val_loss: 0.1643 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1663 - accuracy: 0.9346 - val_loss: 0.1212 - val_accuracy: 0.9607 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1044 - accuracy: 0.9624 - val_loss: 0.0873 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0921 - accuracy: 0.9680 - val_loss: 0.1550 - val_accuracy: 0.9436 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0760 - accuracy: 0.9734\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0760 - accuracy: 0.9734 - val_loss: 0.0897 - val_accuracy: 0.9726 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0547 - accuracy: 0.9806 - val_loss: 0.0591 - val_accuracy: 0.9829 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0480 - accuracy: 0.9833 - val_loss: 0.0573 - val_accuracy: 0.9846 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0409 - accuracy: 0.9859 - val_loss: 0.0664 - val_accuracy: 0.9778 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.9874\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0370 - accuracy: 0.9874 - val_loss: 0.0638 - val_accuracy: 0.9812 - lr: 3.0000e-04\n",
            "Best Accuracy at the generation 8: 99.54732060432434\n",
            "[[45 37 92  4 10 17]\n",
            " [45 37 85  4 10 20]\n",
            " [45 39 85  4 10 18]\n",
            " [45 51 90  5 15 20]\n",
            " [43 37 84  4 10 18]\n",
            " [45 41 85  4 10 19]\n",
            " [45 41 85  7 10 18]\n",
            " [45 39 94  4 11 20]\n",
            " [45 51 88  5 15 15]\n",
            " [46 37 92  5 10 17]]\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 36ms/step - loss: 0.6917 - accuracy: 0.6562 - val_loss: 0.3302 - val_accuracy: 0.8684 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1966 - accuracy: 0.9205 - val_loss: 0.1573 - val_accuracy: 0.9453 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1364 - accuracy: 0.9470 - val_loss: 0.1376 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1094 - accuracy: 0.9593 - val_loss: 0.1142 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1006 - accuracy: 0.9632 - val_loss: 0.0971 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0872 - accuracy: 0.9699 - val_loss: 0.1041 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0843 - accuracy: 0.9697 - val_loss: 0.1256 - val_accuracy: 0.9385 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0726 - accuracy: 0.9751\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0726 - accuracy: 0.9751 - val_loss: 0.0875 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0533 - accuracy: 0.9819 - val_loss: 0.0916 - val_accuracy: 0.9658 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0482 - accuracy: 0.9825\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0482 - accuracy: 0.9825 - val_loss: 0.0941 - val_accuracy: 0.9658 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 37ms/step - loss: 0.7310 - accuracy: 0.7079 - val_loss: 0.4489 - val_accuracy: 0.7675 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.3033 - accuracy: 0.8734 - val_loss: 0.2341 - val_accuracy: 0.9009 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1651 - accuracy: 0.9359 - val_loss: 0.1169 - val_accuracy: 0.9726 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1078 - accuracy: 0.9617 - val_loss: 0.1004 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0803 - accuracy: 0.9697\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0803 - accuracy: 0.9697 - val_loss: 0.0893 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0530 - accuracy: 0.9809 - val_loss: 0.0661 - val_accuracy: 0.9795 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0451 - accuracy: 0.9827 - val_loss: 0.0578 - val_accuracy: 0.9812 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0393 - accuracy: 0.9870 - val_loss: 0.0674 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 0.9881\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0330 - accuracy: 0.9881 - val_loss: 0.0881 - val_accuracy: 0.9675 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0254 - accuracy: 0.9907 - val_loss: 0.0636 - val_accuracy: 0.9726 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 37ms/step - loss: 0.6834 - accuracy: 0.6912 - val_loss: 0.2631 - val_accuracy: 0.9077 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1843 - accuracy: 0.9300 - val_loss: 0.1164 - val_accuracy: 0.9607 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1183 - accuracy: 0.9594 - val_loss: 0.1240 - val_accuracy: 0.9487 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0971 - accuracy: 0.9652 - val_loss: 0.0940 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0995 - accuracy: 0.9628 - val_loss: 0.1640 - val_accuracy: 0.9299 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0799 - accuracy: 0.9704\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0799 - accuracy: 0.9704 - val_loss: 0.1155 - val_accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0660 - accuracy: 0.9760 - val_loss: 0.0927 - val_accuracy: 0.9590 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0557 - accuracy: 0.9803\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0557 - accuracy: 0.9803 - val_loss: 0.0858 - val_accuracy: 0.9692 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0486 - accuracy: 0.9833 - val_loss: 0.1010 - val_accuracy: 0.9607 - lr: 9.0000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0455 - accuracy: 0.9860\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0455 - accuracy: 0.9860 - val_loss: 0.0976 - val_accuracy: 0.9556 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 41ms/step - loss: 1.1790 - accuracy: 0.7643 - val_loss: 0.2725 - val_accuracy: 0.9111 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.2271 - accuracy: 0.9103 - val_loss: 0.1872 - val_accuracy: 0.9265 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1616 - accuracy: 0.9410 - val_loss: 0.1147 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1294 - accuracy: 0.9503 - val_loss: 0.0655 - val_accuracy: 0.9863 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0985 - accuracy: 0.9628 - val_loss: 0.0677 - val_accuracy: 0.9778 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0873 - accuracy: 0.9689\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0873 - accuracy: 0.9689 - val_loss: 0.0825 - val_accuracy: 0.9778 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0624 - accuracy: 0.9792 - val_loss: 0.0562 - val_accuracy: 0.9829 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0516 - accuracy: 0.9825\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0516 - accuracy: 0.9825 - val_loss: 0.0563 - val_accuracy: 0.9846 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0403 - accuracy: 0.9860 - val_loss: 0.0614 - val_accuracy: 0.9761 - lr: 9.0000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0384 - accuracy: 0.9863\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0384 - accuracy: 0.9863 - val_loss: 0.0570 - val_accuracy: 0.9829 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 5s 36ms/step - loss: 0.7659 - accuracy: 0.5782 - val_loss: 0.4398 - val_accuracy: 0.7726 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.3828 - accuracy: 0.8334 - val_loss: 0.2917 - val_accuracy: 0.8684 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.2068 - accuracy: 0.9170 - val_loss: 0.1219 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1104 - accuracy: 0.9591 - val_loss: 0.0889 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0846 - accuracy: 0.9696 - val_loss: 0.0780 - val_accuracy: 0.9812 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0745 - accuracy: 0.9740 - val_loss: 0.1274 - val_accuracy: 0.9504 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0700 - accuracy: 0.9741\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0700 - accuracy: 0.9741 - val_loss: 0.0893 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0475 - accuracy: 0.9827 - val_loss: 0.0650 - val_accuracy: 0.9744 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0376 - accuracy: 0.9860\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0376 - accuracy: 0.9860 - val_loss: 0.0972 - val_accuracy: 0.9556 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0332 - accuracy: 0.9884 - val_loss: 0.0678 - val_accuracy: 0.9726 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 11s 52ms/step - loss: 0.5658 - accuracy: 0.7646 - val_loss: 0.1542 - val_accuracy: 0.9333 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1327 - accuracy: 0.9508 - val_loss: 0.0966 - val_accuracy: 0.9795 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1065 - accuracy: 0.9597 - val_loss: 0.1266 - val_accuracy: 0.9556 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0999 - accuracy: 0.9645\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0999 - accuracy: 0.9645 - val_loss: 0.0929 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0671 - accuracy: 0.9774 - val_loss: 0.1074 - val_accuracy: 0.9641 - lr: 3.0000e-04\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0599 - accuracy: 0.9788\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0599 - accuracy: 0.9788 - val_loss: 0.0793 - val_accuracy: 0.9778 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0525 - accuracy: 0.9812 - val_loss: 0.0736 - val_accuracy: 0.9795 - lr: 9.0000e-05\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0501 - accuracy: 0.9840\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0501 - accuracy: 0.9840 - val_loss: 0.0832 - val_accuracy: 0.9744 - lr: 9.0000e-05\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0466 - accuracy: 0.9836 - val_loss: 0.0780 - val_accuracy: 0.9778 - lr: 2.7000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0465 - accuracy: 0.9833 - val_loss: 0.0783 - val_accuracy: 0.9812 - lr: 2.7000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 8s 44ms/step - loss: 0.7005 - accuracy: 0.7502 - val_loss: 0.2371 - val_accuracy: 0.9077 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1496 - accuracy: 0.9451 - val_loss: 0.1536 - val_accuracy: 0.9436 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1270 - accuracy: 0.9549 - val_loss: 0.1162 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1023 - accuracy: 0.9625 - val_loss: 0.0922 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0965 - accuracy: 0.9656\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0965 - accuracy: 0.9656 - val_loss: 0.0941 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0684 - accuracy: 0.9768 - val_loss: 0.0777 - val_accuracy: 0.9761 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0655 - accuracy: 0.9767 - val_loss: 0.0686 - val_accuracy: 0.9778 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0580 - accuracy: 0.9786 - val_loss: 0.0759 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0549 - accuracy: 0.9798 - val_loss: 0.0679 - val_accuracy: 0.9795 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0511 - accuracy: 0.9820 - val_loss: 0.0874 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 11s 54ms/step - loss: 1.5617 - accuracy: 0.5079 - val_loss: 0.7074 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.6928 - accuracy: 0.5165 - val_loss: 0.7062 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6928 - accuracy: 0.5165\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.6928 - accuracy: 0.5165 - val_loss: 0.7035 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.6927 - accuracy: 0.5165 - val_loss: 0.7046 - val_accuracy: 0.2701 - lr: 3.0000e-04\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6927 - accuracy: 0.5165\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.6927 - accuracy: 0.5165 - val_loss: 0.7043 - val_accuracy: 0.2701 - lr: 3.0000e-04\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7048 - val_accuracy: 0.2701 - lr: 9.0000e-05\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.5165\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7048 - val_accuracy: 0.2701 - lr: 9.0000e-05\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7049 - val_accuracy: 0.2701 - lr: 2.7000e-05\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.5165\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7051 - val_accuracy: 0.2701 - lr: 2.7000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7052 - val_accuracy: 0.2701 - lr: 8.1000e-06\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 8s 45ms/step - loss: 0.5876 - accuracy: 0.7353 - val_loss: 0.2772 - val_accuracy: 0.8872 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.1848 - accuracy: 0.9304 - val_loss: 0.2084 - val_accuracy: 0.9248 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1449 - accuracy: 0.9479 - val_loss: 0.1770 - val_accuracy: 0.9556 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.1296 - accuracy: 0.9543 - val_loss: 0.1368 - val_accuracy: 0.9487 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.1244 - accuracy: 0.9576\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.1244 - accuracy: 0.9576 - val_loss: 0.1671 - val_accuracy: 0.9402 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0970 - accuracy: 0.9653 - val_loss: 0.1051 - val_accuracy: 0.9624 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0857 - accuracy: 0.9717 - val_loss: 0.1010 - val_accuracy: 0.9658 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0795 - accuracy: 0.9723 - val_loss: 0.0921 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0737 - accuracy: 0.9751 - val_loss: 0.0996 - val_accuracy: 0.9624 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0730 - accuracy: 0.9762\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0730 - accuracy: 0.9762 - val_loss: 0.0850 - val_accuracy: 0.9692 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 8s 46ms/step - loss: 0.7063 - accuracy: 0.6946 - val_loss: 0.2846 - val_accuracy: 0.8632 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1933 - accuracy: 0.9206 - val_loss: 0.1669 - val_accuracy: 0.9385 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1380 - accuracy: 0.9455 - val_loss: 0.1147 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1190 - accuracy: 0.9561 - val_loss: 0.0933 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1177 - accuracy: 0.9532 - val_loss: 0.0919 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0908 - accuracy: 0.9676 - val_loss: 0.1006 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0858 - accuracy: 0.9693\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0858 - accuracy: 0.9693 - val_loss: 0.0873 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0669 - accuracy: 0.9761 - val_loss: 0.0782 - val_accuracy: 0.9692 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0599 - accuracy: 0.9805\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0599 - accuracy: 0.9805 - val_loss: 0.0863 - val_accuracy: 0.9624 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0528 - accuracy: 0.9827 - val_loss: 0.0731 - val_accuracy: 0.9709 - lr: 9.0000e-05\n",
            "Best Accuracy at the generation 9: 99.54732060432434\n",
            "[[45 37 85  4 10 20]\n",
            " [43 37 84  4 10 18]\n",
            " [45 51 90  5 15 20]\n",
            " [45 39 85  4 10 18]\n",
            " [45 41 85  4 10 19]\n",
            " [48 37 84  5 10 18]\n",
            " [43 37 93  4 13 20]\n",
            " [45 55 85  5 15 19]\n",
            " [47 39 85  4 10 17]\n",
            " [45 46 85  6 10 20]]\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 37ms/step - loss: 0.7689 - accuracy: 0.6661 - val_loss: 0.4989 - val_accuracy: 0.6821 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.2403 - accuracy: 0.8953 - val_loss: 0.1832 - val_accuracy: 0.9248 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1418 - accuracy: 0.9486 - val_loss: 0.1382 - val_accuracy: 0.9556 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1081 - accuracy: 0.9615 - val_loss: 0.1201 - val_accuracy: 0.9521 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1092 - accuracy: 0.9619 - val_loss: 0.1001 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0844 - accuracy: 0.9720 - val_loss: 0.1526 - val_accuracy: 0.9282 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0787 - accuracy: 0.9714 - val_loss: 0.0918 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0681 - accuracy: 0.9754 - val_loss: 0.1065 - val_accuracy: 0.9607 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0599 - accuracy: 0.9775 - val_loss: 0.0885 - val_accuracy: 0.9726 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0634 - accuracy: 0.9782 - val_loss: 0.1174 - val_accuracy: 0.9607 - lr: 0.0010\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 5s 35ms/step - loss: 0.5911 - accuracy: 0.6966 - val_loss: 0.3475 - val_accuracy: 0.8803 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.1875 - accuracy: 0.9246 - val_loss: 0.1249 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.1193 - accuracy: 0.9547 - val_loss: 0.1197 - val_accuracy: 0.9607 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0968 - accuracy: 0.9655 - val_loss: 0.0947 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0827 - accuracy: 0.9694 - val_loss: 0.0928 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0749 - accuracy: 0.9737 - val_loss: 0.0976 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0717 - accuracy: 0.9767 - val_loss: 0.1019 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0628 - accuracy: 0.9754 - val_loss: 0.0850 - val_accuracy: 0.9726 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0461 - accuracy: 0.9829 - val_loss: 0.0773 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.0429 - accuracy: 0.9843 - val_loss: 0.0655 - val_accuracy: 0.9795 - lr: 0.0010\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 42ms/step - loss: 1.1922 - accuracy: 0.7106 - val_loss: 0.2014 - val_accuracy: 0.9299 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1657 - accuracy: 0.9366 - val_loss: 0.1430 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1369 - accuracy: 0.9479 - val_loss: 0.1079 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1005 - accuracy: 0.9629 - val_loss: 0.0752 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0897 - accuracy: 0.9673 - val_loss: 0.0863 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0790 - accuracy: 0.9713\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0790 - accuracy: 0.9713 - val_loss: 0.1218 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0547 - accuracy: 0.9801 - val_loss: 0.0656 - val_accuracy: 0.9744 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0455 - accuracy: 0.9837\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0455 - accuracy: 0.9837 - val_loss: 0.0822 - val_accuracy: 0.9709 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0378 - accuracy: 0.9863 - val_loss: 0.0739 - val_accuracy: 0.9778 - lr: 9.0000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0357 - accuracy: 0.9866 - val_loss: 0.0784 - val_accuracy: 0.9744 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 7s 37ms/step - loss: 1.0042 - accuracy: 0.6280 - val_loss: 0.3344 - val_accuracy: 0.8581 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.2581 - accuracy: 0.8901 - val_loss: 0.1250 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1332 - accuracy: 0.9509 - val_loss: 0.0818 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0942 - accuracy: 0.9666 - val_loss: 0.0734 - val_accuracy: 0.9795 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0872 - accuracy: 0.9697 - val_loss: 0.0848 - val_accuracy: 0.9726 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0660 - accuracy: 0.9782\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0660 - accuracy: 0.9782 - val_loss: 0.0919 - val_accuracy: 0.9726 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0458 - accuracy: 0.9830 - val_loss: 0.0584 - val_accuracy: 0.9846 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0384 - accuracy: 0.9860 - val_loss: 0.0633 - val_accuracy: 0.9744 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 0.9891\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0320 - accuracy: 0.9891 - val_loss: 0.0564 - val_accuracy: 0.9812 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0237 - accuracy: 0.9925 - val_loss: 0.0527 - val_accuracy: 0.9778 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 38ms/step - loss: 0.7669 - accuracy: 0.7273 - val_loss: 0.1783 - val_accuracy: 0.9453 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1431 - accuracy: 0.9448 - val_loss: 0.1008 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1148 - accuracy: 0.9569 - val_loss: 0.1163 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0941 - accuracy: 0.9651\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0941 - accuracy: 0.9651 - val_loss: 0.1159 - val_accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0718 - accuracy: 0.9761 - val_loss: 0.0889 - val_accuracy: 0.9744 - lr: 3.0000e-04\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0637 - accuracy: 0.9775 - val_loss: 0.0758 - val_accuracy: 0.9778 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0619 - accuracy: 0.9778 - val_loss: 0.0761 - val_accuracy: 0.9761 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0572 - accuracy: 0.9793 - val_loss: 0.0742 - val_accuracy: 0.9812 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0525 - accuracy: 0.9818 - val_loss: 0.0706 - val_accuracy: 0.9812 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0498 - accuracy: 0.9825\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0498 - accuracy: 0.9825 - val_loss: 0.0718 - val_accuracy: 0.9761 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 8s 45ms/step - loss: 0.6644 - accuracy: 0.7137 - val_loss: 0.2863 - val_accuracy: 0.8940 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1874 - accuracy: 0.9279 - val_loss: 0.1323 - val_accuracy: 0.9556 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1086 - accuracy: 0.9595 - val_loss: 0.0874 - val_accuracy: 0.9829 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0745 - accuracy: 0.9724 - val_loss: 0.0581 - val_accuracy: 0.9863 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0697 - accuracy: 0.9734 - val_loss: 0.0957 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0538 - accuracy: 0.9798\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0538 - accuracy: 0.9798 - val_loss: 0.0968 - val_accuracy: 0.9607 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0351 - accuracy: 0.9868 - val_loss: 0.0536 - val_accuracy: 0.9846 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 0.9921\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0245 - accuracy: 0.9921 - val_loss: 0.0603 - val_accuracy: 0.9744 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0191 - accuracy: 0.9936 - val_loss: 0.0632 - val_accuracy: 0.9744 - lr: 9.0000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 0.9946\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0170 - accuracy: 0.9946 - val_loss: 0.0592 - val_accuracy: 0.9795 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 12s 56ms/step - loss: 0.8199 - accuracy: 0.5008 - val_loss: 0.6981 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.6935 - accuracy: 0.5156 - val_loss: 0.7047 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6968 - accuracy: 0.5093\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.6968 - accuracy: 0.5093 - val_loss: 0.7083 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 32ms/step - loss: 0.6926 - accuracy: 0.5170 - val_loss: 0.7068 - val_accuracy: 0.2769 - lr: 3.0000e-04\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.6828 - accuracy: 0.5472 - val_loss: 0.5779 - val_accuracy: 0.6701 - lr: 3.0000e-04\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.4170 - accuracy: 0.8145 - val_loss: 0.3350 - val_accuracy: 0.8462 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.2507 - accuracy: 0.9001 - val_loss: 0.1481 - val_accuracy: 0.9590 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1447 - accuracy: 0.9475 - val_loss: 0.1158 - val_accuracy: 0.9692 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1107 - accuracy: 0.9602 - val_loss: 0.1093 - val_accuracy: 0.9744 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1020 - accuracy: 0.9655 - val_loss: 0.0926 - val_accuracy: 0.9863 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 14s 66ms/step - loss: 0.6797 - accuracy: 0.8073 - val_loss: 0.1239 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1424 - accuracy: 0.9489 - val_loss: 0.1243 - val_accuracy: 0.9453 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1189 - accuracy: 0.9559 - val_loss: 0.1112 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0984 - accuracy: 0.9644 - val_loss: 0.0968 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0857 - accuracy: 0.9704 - val_loss: 0.0925 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0777 - accuracy: 0.9741 - val_loss: 0.1330 - val_accuracy: 0.9487 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0703 - accuracy: 0.9747\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0703 - accuracy: 0.9747 - val_loss: 0.0994 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0504 - accuracy: 0.9827 - val_loss: 0.0818 - val_accuracy: 0.9692 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0414 - accuracy: 0.9856\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0414 - accuracy: 0.9856 - val_loss: 0.0820 - val_accuracy: 0.9692 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0331 - accuracy: 0.9884 - val_loss: 0.0729 - val_accuracy: 0.9726 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 11s 53ms/step - loss: 0.8435 - accuracy: 0.5037 - val_loss: 0.6967 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.6929 - accuracy: 0.5165 - val_loss: 0.6998 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6927 - accuracy: 0.5165\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.6927 - accuracy: 0.5165 - val_loss: 0.7033 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.6927 - accuracy: 0.5165 - val_loss: 0.7039 - val_accuracy: 0.2701 - lr: 3.0000e-04\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6927 - accuracy: 0.5165\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.6927 - accuracy: 0.5165 - val_loss: 0.7045 - val_accuracy: 0.2701 - lr: 3.0000e-04\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7047 - val_accuracy: 0.2701 - lr: 9.0000e-05\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.5165\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7047 - val_accuracy: 0.2701 - lr: 9.0000e-05\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7048 - val_accuracy: 0.2701 - lr: 2.7000e-05\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.5165\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7048 - val_accuracy: 0.2701 - lr: 2.7000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7048 - val_accuracy: 0.2701 - lr: 8.1000e-06\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 12s 56ms/step - loss: 1.1935 - accuracy: 0.5148 - val_loss: 0.6993 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.6928 - accuracy: 0.5165 - val_loss: 0.7030 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6927 - accuracy: 0.5165\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.6927 - accuracy: 0.5165 - val_loss: 0.7067 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7071 - val_accuracy: 0.2701 - lr: 3.0000e-04\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.5165\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7074 - val_accuracy: 0.2701 - lr: 3.0000e-04\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7075 - val_accuracy: 0.2701 - lr: 9.0000e-05\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.5165\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7074 - val_accuracy: 0.2701 - lr: 9.0000e-05\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7074 - val_accuracy: 0.2701 - lr: 2.7000e-05\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.5165\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7074 - val_accuracy: 0.2701 - lr: 2.7000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7074 - val_accuracy: 0.2701 - lr: 8.1000e-06\n",
            "Best Accuracy at the generation 10: 99.54732060432434\n",
            "[[48 37 84  5 10 18]\n",
            " [45 39 85  4 10 18]\n",
            " [45 55 85  5 15 19]\n",
            " [45 51 90  5 15 20]\n",
            " [43 37 84  4 10 18]\n",
            " [50 37 85  5 10 15]\n",
            " [45 39 86  4 13 19]\n",
            " [45 57 90  5 17 20]\n",
            " [45 51 88  8 15 18]\n",
            " [43 42 84  7 10 18]]\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 37ms/step - loss: 0.8082 - accuracy: 0.5651 - val_loss: 0.5728 - val_accuracy: 0.7214 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.2965 - accuracy: 0.8718 - val_loss: 0.1377 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1296 - accuracy: 0.9512 - val_loss: 0.1135 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1018 - accuracy: 0.9639 - val_loss: 0.0878 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0881 - accuracy: 0.9685 - val_loss: 0.0761 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0689 - accuracy: 0.9767\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0689 - accuracy: 0.9767 - val_loss: 0.1093 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0529 - accuracy: 0.9816 - val_loss: 0.0619 - val_accuracy: 0.9829 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0444 - accuracy: 0.9850 - val_loss: 0.0728 - val_accuracy: 0.9709 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0398 - accuracy: 0.9854\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0398 - accuracy: 0.9854 - val_loss: 0.0830 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0332 - accuracy: 0.9887 - val_loss: 0.0619 - val_accuracy: 0.9778 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 37ms/step - loss: 0.6909 - accuracy: 0.6383 - val_loss: 0.2387 - val_accuracy: 0.9060 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1746 - accuracy: 0.9317 - val_loss: 0.1464 - val_accuracy: 0.9350 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1323 - accuracy: 0.9509 - val_loss: 0.1514 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1031 - accuracy: 0.9636 - val_loss: 0.0977 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0940 - accuracy: 0.9660 - val_loss: 0.0951 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0878 - accuracy: 0.9709 - val_loss: 0.1198 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0905 - accuracy: 0.9696 - val_loss: 0.1420 - val_accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0705 - accuracy: 0.9751\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0705 - accuracy: 0.9751 - val_loss: 0.1260 - val_accuracy: 0.9504 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0530 - accuracy: 0.9825 - val_loss: 0.0946 - val_accuracy: 0.9624 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0469 - accuracy: 0.9834 - val_loss: 0.0816 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 41ms/step - loss: 0.7071 - accuracy: 0.7565 - val_loss: 0.2467 - val_accuracy: 0.9419 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1633 - accuracy: 0.9378 - val_loss: 0.1319 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1413 - accuracy: 0.9505 - val_loss: 0.1187 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1068 - accuracy: 0.9607 - val_loss: 0.0948 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0940 - accuracy: 0.9642\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0940 - accuracy: 0.9642 - val_loss: 0.1052 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0745 - accuracy: 0.9723 - val_loss: 0.0817 - val_accuracy: 0.9761 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0659 - accuracy: 0.9772 - val_loss: 0.0779 - val_accuracy: 0.9778 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0590 - accuracy: 0.9792 - val_loss: 0.0738 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0537 - accuracy: 0.9809\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0537 - accuracy: 0.9809 - val_loss: 0.0717 - val_accuracy: 0.9761 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0465 - accuracy: 0.9830 - val_loss: 0.0789 - val_accuracy: 0.9709 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 41ms/step - loss: 1.1436 - accuracy: 0.7312 - val_loss: 0.3020 - val_accuracy: 0.8650 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.2448 - accuracy: 0.8956 - val_loss: 0.1851 - val_accuracy: 0.9385 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1407 - accuracy: 0.9489 - val_loss: 0.1081 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1145 - accuracy: 0.9576 - val_loss: 0.0774 - val_accuracy: 0.9761 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0822 - accuracy: 0.9696 - val_loss: 0.1007 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0718 - accuracy: 0.9754\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0718 - accuracy: 0.9754 - val_loss: 0.1166 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0513 - accuracy: 0.9819 - val_loss: 0.0554 - val_accuracy: 0.9829 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0424 - accuracy: 0.9843 - val_loss: 0.0526 - val_accuracy: 0.9863 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0370 - accuracy: 0.9860 - val_loss: 0.0764 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0337 - accuracy: 0.9885\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0337 - accuracy: 0.9885 - val_loss: 0.0587 - val_accuracy: 0.9829 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 36ms/step - loss: 0.6315 - accuracy: 0.8015 - val_loss: 0.2452 - val_accuracy: 0.9060 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1708 - accuracy: 0.9380 - val_loss: 0.1855 - val_accuracy: 0.9333 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1523 - accuracy: 0.9475 - val_loss: 0.1809 - val_accuracy: 0.9316 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1336 - accuracy: 0.9543 - val_loss: 0.1662 - val_accuracy: 0.9350 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1139 - accuracy: 0.9625 - val_loss: 0.1223 - val_accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1060 - accuracy: 0.9627 - val_loss: 0.1275 - val_accuracy: 0.9453 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0917 - accuracy: 0.9665 - val_loss: 0.1136 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0780 - accuracy: 0.9735 - val_loss: 0.1479 - val_accuracy: 0.9453 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0849 - accuracy: 0.9697 - val_loss: 0.0843 - val_accuracy: 0.9761 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0725 - accuracy: 0.9747 - val_loss: 0.0965 - val_accuracy: 0.9726 - lr: 0.0010\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 10s 52ms/step - loss: 0.5061 - accuracy: 0.7793 - val_loss: 0.2666 - val_accuracy: 0.9145 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1566 - accuracy: 0.9404 - val_loss: 0.1506 - val_accuracy: 0.9521 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1317 - accuracy: 0.9515 - val_loss: 0.1690 - val_accuracy: 0.9470 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.1090 - accuracy: 0.9610\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1090 - accuracy: 0.9610 - val_loss: 0.1213 - val_accuracy: 0.9521 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0817 - accuracy: 0.9711 - val_loss: 0.1277 - val_accuracy: 0.9453 - lr: 3.0000e-04\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0760 - accuracy: 0.9740 - val_loss: 0.1015 - val_accuracy: 0.9607 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0693 - accuracy: 0.9771 - val_loss: 0.0901 - val_accuracy: 0.9658 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0694 - accuracy: 0.9748 - val_loss: 0.0994 - val_accuracy: 0.9504 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0601 - accuracy: 0.9778\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0601 - accuracy: 0.9778 - val_loss: 0.0959 - val_accuracy: 0.9573 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0520 - accuracy: 0.9816 - val_loss: 0.0885 - val_accuracy: 0.9658 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 12s 55ms/step - loss: 0.9464 - accuracy: 0.5951 - val_loss: 0.3582 - val_accuracy: 0.8479 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.2667 - accuracy: 0.8901 - val_loss: 0.1520 - val_accuracy: 0.9385 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1325 - accuracy: 0.9516 - val_loss: 0.1094 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0937 - accuracy: 0.9682 - val_loss: 0.0977 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0800 - accuracy: 0.9726\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0800 - accuracy: 0.9726 - val_loss: 0.0905 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0598 - accuracy: 0.9802 - val_loss: 0.0694 - val_accuracy: 0.9761 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0536 - accuracy: 0.9810 - val_loss: 0.0682 - val_accuracy: 0.9761 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0463 - accuracy: 0.9837\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0463 - accuracy: 0.9837 - val_loss: 0.0710 - val_accuracy: 0.9761 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0396 - accuracy: 0.9856 - val_loss: 0.0792 - val_accuracy: 0.9778 - lr: 9.0000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0381 - accuracy: 0.9880 - val_loss: 0.0735 - val_accuracy: 0.9726 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 17s 75ms/step - loss: 1.3507 - accuracy: 0.8100 - val_loss: 0.2324 - val_accuracy: 0.9043 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 40ms/step - loss: 0.1437 - accuracy: 0.9468 - val_loss: 0.1270 - val_accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 5s 41ms/step - loss: 0.1147 - accuracy: 0.9587 - val_loss: 0.1598 - val_accuracy: 0.9402 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 40ms/step - loss: 0.0924 - accuracy: 0.9665 - val_loss: 0.0959 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 40ms/step - loss: 0.1113 - accuracy: 0.9614 - val_loss: 0.1311 - val_accuracy: 0.9504 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 40ms/step - loss: 0.0931 - accuracy: 0.9680 - val_loss: 0.1135 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 40ms/step - loss: 0.0807 - accuracy: 0.9714 - val_loss: 0.1045 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 40ms/step - loss: 0.0609 - accuracy: 0.9791 - val_loss: 0.0872 - val_accuracy: 0.9761 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 40ms/step - loss: 0.0534 - accuracy: 0.9806 - val_loss: 0.0941 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0519 - accuracy: 0.9813\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 40ms/step - loss: 0.0519 - accuracy: 0.9813 - val_loss: 0.0945 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 9s 48ms/step - loss: 1.0896 - accuracy: 0.5108 - val_loss: 0.6133 - val_accuracy: 0.7094 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.3096 - accuracy: 0.8587 - val_loss: 0.1365 - val_accuracy: 0.9521 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1446 - accuracy: 0.9450 - val_loss: 0.1446 - val_accuracy: 0.9556 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1121 - accuracy: 0.9601 - val_loss: 0.1295 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1129 - accuracy: 0.9571 - val_loss: 0.0972 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1072 - accuracy: 0.9608 - val_loss: 0.1041 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0817 - accuracy: 0.9714 - val_loss: 0.0951 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0681 - accuracy: 0.9738 - val_loss: 0.0964 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0657 - accuracy: 0.9760\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0657 - accuracy: 0.9760 - val_loss: 0.1144 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0441 - accuracy: 0.9843 - val_loss: 0.0930 - val_accuracy: 0.9761 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 8s 43ms/step - loss: 0.5424 - accuracy: 0.7120 - val_loss: 0.2618 - val_accuracy: 0.8940 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1666 - accuracy: 0.9363 - val_loss: 0.1691 - val_accuracy: 0.9487 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1512 - accuracy: 0.9424 - val_loss: 0.1249 - val_accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1206 - accuracy: 0.9578 - val_loss: 0.1023 - val_accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1121 - accuracy: 0.9583 - val_loss: 0.0942 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0969 - accuracy: 0.9663 - val_loss: 0.1013 - val_accuracy: 0.9761 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0850 - accuracy: 0.9706 - val_loss: 0.0992 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0860 - accuracy: 0.9700\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0860 - accuracy: 0.9700 - val_loss: 0.1375 - val_accuracy: 0.9470 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0604 - accuracy: 0.9776 - val_loss: 0.0802 - val_accuracy: 0.9709 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0518 - accuracy: 0.9815\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0518 - accuracy: 0.9815 - val_loss: 0.0710 - val_accuracy: 0.9761 - lr: 3.0000e-04\n",
            "Best Accuracy at the generation 11: 99.54732060432434\n",
            "[[48 37 84  5 10 18]\n",
            " [45 51 90  5 15 20]\n",
            " [45 39 86  4 13 19]\n",
            " [45 51 88  8 15 18]\n",
            " [45 39 85  4 10 18]\n",
            " [50 37 90  5 13 20]\n",
            " [45 51 91  5 15 16]\n",
            " [49 39 88  4 13 20]\n",
            " [45 54 85  8 16 18]\n",
            " [45 39 86  5 10 18]]\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 37ms/step - loss: 0.6691 - accuracy: 0.7042 - val_loss: 0.3741 - val_accuracy: 0.8188 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.2608 - accuracy: 0.8890 - val_loss: 0.1602 - val_accuracy: 0.9487 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1536 - accuracy: 0.9431 - val_loss: 0.1103 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1023 - accuracy: 0.9635 - val_loss: 0.0762 - val_accuracy: 0.9761 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0848 - accuracy: 0.9686 - val_loss: 0.0653 - val_accuracy: 0.9778 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0738 - accuracy: 0.9750 - val_loss: 0.1162 - val_accuracy: 0.9487 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0615 - accuracy: 0.9785 - val_loss: 0.0615 - val_accuracy: 0.9829 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0478 - accuracy: 0.9833 - val_loss: 0.0711 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0451 - accuracy: 0.9843\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0451 - accuracy: 0.9843 - val_loss: 0.0751 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0271 - accuracy: 0.9915 - val_loss: 0.0489 - val_accuracy: 0.9863 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 41ms/step - loss: 0.8143 - accuracy: 0.7048 - val_loss: 0.3401 - val_accuracy: 0.8803 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.3072 - accuracy: 0.8666 - val_loss: 0.2986 - val_accuracy: 0.8598 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.2336 - accuracy: 0.9031 - val_loss: 0.2043 - val_accuracy: 0.9282 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1812 - accuracy: 0.9277 - val_loss: 0.1378 - val_accuracy: 0.9504 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1419 - accuracy: 0.9486 - val_loss: 0.1162 - val_accuracy: 0.9556 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0977 - accuracy: 0.9653 - val_loss: 0.1045 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0821 - accuracy: 0.9710 - val_loss: 0.1201 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0678 - accuracy: 0.9757\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0678 - accuracy: 0.9757 - val_loss: 0.1629 - val_accuracy: 0.9299 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0406 - accuracy: 0.9857 - val_loss: 0.0735 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0297 - accuracy: 0.9900 - val_loss: 0.0671 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 36ms/step - loss: 1.0350 - accuracy: 0.7157 - val_loss: 0.2615 - val_accuracy: 0.9077 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.2132 - accuracy: 0.9150 - val_loss: 0.1108 - val_accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1143 - accuracy: 0.9590 - val_loss: 0.0940 - val_accuracy: 0.9778 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0812 - accuracy: 0.9704 - val_loss: 0.0577 - val_accuracy: 0.9795 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0654 - accuracy: 0.9761 - val_loss: 0.0778 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0574 - accuracy: 0.9795\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0574 - accuracy: 0.9795 - val_loss: 0.0816 - val_accuracy: 0.9726 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0360 - accuracy: 0.9873 - val_loss: 0.0381 - val_accuracy: 0.9897 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0254 - accuracy: 0.9915 - val_loss: 0.0363 - val_accuracy: 0.9880 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 0.9921\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0220 - accuracy: 0.9921 - val_loss: 0.0509 - val_accuracy: 0.9846 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0157 - accuracy: 0.9953 - val_loss: 0.0434 - val_accuracy: 0.9846 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 41ms/step - loss: 0.8699 - accuracy: 0.7437 - val_loss: 0.1947 - val_accuracy: 0.9197 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1568 - accuracy: 0.9413 - val_loss: 0.2199 - val_accuracy: 0.8974 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.1601 - accuracy: 0.9402 - val_loss: 0.1199 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0986 - accuracy: 0.9646 - val_loss: 0.1525 - val_accuracy: 0.9521 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0954 - accuracy: 0.9676\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0954 - accuracy: 0.9676 - val_loss: 0.1126 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0663 - accuracy: 0.9779 - val_loss: 0.0785 - val_accuracy: 0.9795 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0582 - accuracy: 0.9779 - val_loss: 0.0704 - val_accuracy: 0.9744 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0523 - accuracy: 0.9810\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0523 - accuracy: 0.9810 - val_loss: 0.0752 - val_accuracy: 0.9761 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0462 - accuracy: 0.9842 - val_loss: 0.0737 - val_accuracy: 0.9778 - lr: 9.0000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0427 - accuracy: 0.9844 - val_loss: 0.0651 - val_accuracy: 0.9812 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 37ms/step - loss: 0.7489 - accuracy: 0.4981 - val_loss: 0.6980 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.6928 - accuracy: 0.5165 - val_loss: 0.7014 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6927 - accuracy: 0.5165\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.6927 - accuracy: 0.5165 - val_loss: 0.7052 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7057 - val_accuracy: 0.2701 - lr: 3.0000e-04\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.5165\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7062 - val_accuracy: 0.2701 - lr: 3.0000e-04\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7063 - val_accuracy: 0.2701 - lr: 9.0000e-05\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.5165\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7063 - val_accuracy: 0.2701 - lr: 9.0000e-05\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7063 - val_accuracy: 0.2701 - lr: 2.7000e-05\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.5165\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7064 - val_accuracy: 0.2701 - lr: 2.7000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7064 - val_accuracy: 0.2701 - lr: 8.1000e-06\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 13s 60ms/step - loss: 1.2426 - accuracy: 0.5093 - val_loss: 0.6970 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.6928 - accuracy: 0.5165 - val_loss: 0.7004 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6927 - accuracy: 0.5165\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.6927 - accuracy: 0.5165 - val_loss: 0.7043 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.6927 - accuracy: 0.5165 - val_loss: 0.7050 - val_accuracy: 0.2701 - lr: 3.0000e-04\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.5165\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7055 - val_accuracy: 0.2701 - lr: 3.0000e-04\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7057 - val_accuracy: 0.2701 - lr: 9.0000e-05\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.5165\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7057 - val_accuracy: 0.2701 - lr: 9.0000e-05\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7057 - val_accuracy: 0.2701 - lr: 2.7000e-05\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.5165\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7058 - val_accuracy: 0.2701 - lr: 2.7000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7058 - val_accuracy: 0.2701 - lr: 8.1000e-06\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 8s 46ms/step - loss: 0.8534 - accuracy: 0.4992 - val_loss: 0.6964 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.6929 - accuracy: 0.5165 - val_loss: 0.6999 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6950 - accuracy: 0.5165\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.6950 - accuracy: 0.5165 - val_loss: 0.6985 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.6399 - accuracy: 0.5800 - val_loss: 0.4398 - val_accuracy: 0.7812 - lr: 3.0000e-04\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.2246 - accuracy: 0.9103 - val_loss: 0.1905 - val_accuracy: 0.9265 - lr: 3.0000e-04\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1447 - accuracy: 0.9468 - val_loss: 0.1506 - val_accuracy: 0.9470 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1218 - accuracy: 0.9573 - val_loss: 0.1113 - val_accuracy: 0.9692 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1066 - accuracy: 0.9622 - val_loss: 0.1080 - val_accuracy: 0.9675 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0924 - accuracy: 0.9665 - val_loss: 0.0920 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0856 - accuracy: 0.9694 - val_loss: 0.0954 - val_accuracy: 0.9658 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 13s 60ms/step - loss: 0.6731 - accuracy: 0.7174 - val_loss: 0.2316 - val_accuracy: 0.9265 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1637 - accuracy: 0.9393 - val_loss: 0.1715 - val_accuracy: 0.9419 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1301 - accuracy: 0.9536 - val_loss: 0.1654 - val_accuracy: 0.9436 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1016 - accuracy: 0.9635 - val_loss: 0.1586 - val_accuracy: 0.9470 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0914 - accuracy: 0.9672 - val_loss: 0.1028 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0856 - accuracy: 0.9694 - val_loss: 0.1219 - val_accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0814 - accuracy: 0.9707\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0814 - accuracy: 0.9707 - val_loss: 0.1278 - val_accuracy: 0.9521 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0547 - accuracy: 0.9789 - val_loss: 0.0919 - val_accuracy: 0.9658 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0479 - accuracy: 0.9836\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0479 - accuracy: 0.9836 - val_loss: 0.1035 - val_accuracy: 0.9521 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0392 - accuracy: 0.9864 - val_loss: 0.0896 - val_accuracy: 0.9624 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 14s 66ms/step - loss: 1.2569 - accuracy: 0.7493 - val_loss: 0.3297 - val_accuracy: 0.8752 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 40ms/step - loss: 0.1861 - accuracy: 0.9262 - val_loss: 0.1697 - val_accuracy: 0.9453 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1384 - accuracy: 0.9462 - val_loss: 0.1321 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1030 - accuracy: 0.9625 - val_loss: 0.0987 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0932 - accuracy: 0.9645 - val_loss: 0.1052 - val_accuracy: 0.9607 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0852 - accuracy: 0.9696 - val_loss: 0.1021 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0866 - accuracy: 0.9675 - val_loss: 0.1007 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0727 - accuracy: 0.9733\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0727 - accuracy: 0.9733 - val_loss: 0.1140 - val_accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0522 - accuracy: 0.9813 - val_loss: 0.0898 - val_accuracy: 0.9675 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0466 - accuracy: 0.9826\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0466 - accuracy: 0.9826 - val_loss: 0.0791 - val_accuracy: 0.9658 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 9s 43ms/step - loss: 1.0394 - accuracy: 0.5049 - val_loss: 0.6991 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.6928 - accuracy: 0.5165 - val_loss: 0.7032 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6927 - accuracy: 0.5165\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.6927 - accuracy: 0.5165 - val_loss: 0.7071 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7074 - val_accuracy: 0.2701 - lr: 3.0000e-04\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.5165\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7077 - val_accuracy: 0.2701 - lr: 3.0000e-04\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7077 - val_accuracy: 0.2701 - lr: 9.0000e-05\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.5165\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7076 - val_accuracy: 0.2701 - lr: 9.0000e-05\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7076 - val_accuracy: 0.2701 - lr: 2.7000e-05\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.5165\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7076 - val_accuracy: 0.2701 - lr: 2.7000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7077 - val_accuracy: 0.2701 - lr: 8.1000e-06\n",
            "Best Accuracy at the generation 12: 99.54732060432434\n",
            "[[45 39 86  4 13 19]\n",
            " [48 37 84  5 10 18]\n",
            " [45 51 90  5 15 20]\n",
            " [49 39 88  4 13 20]\n",
            " [45 51 88  8 15 18]\n",
            " [50 39 84  4 15 18]\n",
            " [50 37 90  5 12 20]\n",
            " [46 51 88  5 17 20]\n",
            " [49 39 89  6 13 18]\n",
            " [45 53 86  9 15 19]]\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 36ms/step - loss: 1.0275 - accuracy: 0.5924 - val_loss: 0.3289 - val_accuracy: 0.8564 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.2410 - accuracy: 0.9018 - val_loss: 0.1452 - val_accuracy: 0.9504 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1591 - accuracy: 0.9368 - val_loss: 0.1185 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1163 - accuracy: 0.9573 - val_loss: 0.0996 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0954 - accuracy: 0.9676\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0954 - accuracy: 0.9676 - val_loss: 0.1053 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0707 - accuracy: 0.9774 - val_loss: 0.0756 - val_accuracy: 0.9744 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0634 - accuracy: 0.9788 - val_loss: 0.0722 - val_accuracy: 0.9795 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0558 - accuracy: 0.9818 - val_loss: 0.0636 - val_accuracy: 0.9829 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0532 - accuracy: 0.9816 - val_loss: 0.0875 - val_accuracy: 0.9658 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0460 - accuracy: 0.9851\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0460 - accuracy: 0.9851 - val_loss: 0.0800 - val_accuracy: 0.9709 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 37ms/step - loss: 0.7785 - accuracy: 0.6313 - val_loss: 0.5114 - val_accuracy: 0.6872 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.3661 - accuracy: 0.8400 - val_loss: 0.2483 - val_accuracy: 0.9111 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.2116 - accuracy: 0.9153 - val_loss: 0.1452 - val_accuracy: 0.9504 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1284 - accuracy: 0.9529 - val_loss: 0.1308 - val_accuracy: 0.9521 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1506 - accuracy: 0.9392 - val_loss: 0.1499 - val_accuracy: 0.9402 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1022 - accuracy: 0.9645 - val_loss: 0.1261 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0852 - accuracy: 0.9683 - val_loss: 0.1229 - val_accuracy: 0.9487 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0726 - accuracy: 0.9743 - val_loss: 0.0766 - val_accuracy: 0.9761 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0616 - accuracy: 0.9779 - val_loss: 0.0715 - val_accuracy: 0.9778 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0595 - accuracy: 0.9798 - val_loss: 0.0824 - val_accuracy: 0.9761 - lr: 0.0010\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 41ms/step - loss: 0.9559 - accuracy: 0.6541 - val_loss: 0.2332 - val_accuracy: 0.9128 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.2091 - accuracy: 0.9192 - val_loss: 0.1228 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1375 - accuracy: 0.9503 - val_loss: 0.1020 - val_accuracy: 0.9761 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1076 - accuracy: 0.9604 - val_loss: 0.0943 - val_accuracy: 0.9761 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0948 - accuracy: 0.9665\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0948 - accuracy: 0.9665 - val_loss: 0.0986 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0717 - accuracy: 0.9755 - val_loss: 0.0832 - val_accuracy: 0.9744 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0613 - accuracy: 0.9798\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0613 - accuracy: 0.9798 - val_loss: 0.0741 - val_accuracy: 0.9761 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0526 - accuracy: 0.9820 - val_loss: 0.0792 - val_accuracy: 0.9744 - lr: 9.0000e-05\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0498 - accuracy: 0.9823\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0498 - accuracy: 0.9823 - val_loss: 0.0852 - val_accuracy: 0.9709 - lr: 9.0000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0446 - accuracy: 0.9846 - val_loss: 0.0826 - val_accuracy: 0.9709 - lr: 2.7000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 37ms/step - loss: 1.2494 - accuracy: 0.5722 - val_loss: 0.3456 - val_accuracy: 0.8530 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.2572 - accuracy: 0.8932 - val_loss: 0.1469 - val_accuracy: 0.9470 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1370 - accuracy: 0.9489 - val_loss: 0.1009 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1068 - accuracy: 0.9621 - val_loss: 0.1282 - val_accuracy: 0.9556 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0870 - accuracy: 0.9677 - val_loss: 0.0942 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0754 - accuracy: 0.9745 - val_loss: 0.1134 - val_accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0752 - accuracy: 0.9726 - val_loss: 0.0811 - val_accuracy: 0.9761 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0490 - accuracy: 0.9815 - val_loss: 0.1162 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0495 - accuracy: 0.9843\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0495 - accuracy: 0.9843 - val_loss: 0.0940 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0276 - accuracy: 0.9894 - val_loss: 0.0756 - val_accuracy: 0.9761 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 41ms/step - loss: 0.9106 - accuracy: 0.5009 - val_loss: 0.6969 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.6929 - accuracy: 0.5165 - val_loss: 0.6999 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6927 - accuracy: 0.5165\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.6927 - accuracy: 0.5165 - val_loss: 0.7034 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.6927 - accuracy: 0.5165 - val_loss: 0.7040 - val_accuracy: 0.2701 - lr: 3.0000e-04\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6927 - accuracy: 0.5165\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.6927 - accuracy: 0.5165 - val_loss: 0.7046 - val_accuracy: 0.2701 - lr: 3.0000e-04\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7047 - val_accuracy: 0.2701 - lr: 9.0000e-05\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.5165\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7048 - val_accuracy: 0.2701 - lr: 9.0000e-05\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7048 - val_accuracy: 0.2701 - lr: 2.7000e-05\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.5165\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7048 - val_accuracy: 0.2701 - lr: 2.7000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7049 - val_accuracy: 0.2701 - lr: 8.1000e-06\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 13s 61ms/step - loss: 0.9432 - accuracy: 0.6219 - val_loss: 0.3514 - val_accuracy: 0.8581 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.3225 - accuracy: 0.8510 - val_loss: 0.2743 - val_accuracy: 0.8752 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.2360 - accuracy: 0.8998 - val_loss: 0.2062 - val_accuracy: 0.9197 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.1529 - accuracy: 0.9417 - val_loss: 0.1026 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.1153 - accuracy: 0.9576 - val_loss: 0.1335 - val_accuracy: 0.9470 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0889 - accuracy: 0.9689 - val_loss: 0.1066 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0741 - accuracy: 0.9731 - val_loss: 0.1272 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0631 - accuracy: 0.9772 - val_loss: 0.0715 - val_accuracy: 0.9761 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0494 - accuracy: 0.9826 - val_loss: 0.0580 - val_accuracy: 0.9812 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0425 - accuracy: 0.9864 - val_loss: 0.0612 - val_accuracy: 0.9795 - lr: 0.0010\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 10s 52ms/step - loss: 1.0064 - accuracy: 0.6896 - val_loss: 0.3347 - val_accuracy: 0.8564 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.2963 - accuracy: 0.8724 - val_loss: 0.2699 - val_accuracy: 0.8632 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.2258 - accuracy: 0.9024 - val_loss: 0.2190 - val_accuracy: 0.9077 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1712 - accuracy: 0.9354 - val_loss: 0.1813 - val_accuracy: 0.9231 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1447 - accuracy: 0.9426 - val_loss: 0.1668 - val_accuracy: 0.9470 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1230 - accuracy: 0.9560 - val_loss: 0.1649 - val_accuracy: 0.9436 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.1043 - accuracy: 0.9602\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1043 - accuracy: 0.9602 - val_loss: 0.1850 - val_accuracy: 0.9265 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0704 - accuracy: 0.9751 - val_loss: 0.1104 - val_accuracy: 0.9641 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0542 - accuracy: 0.9809 - val_loss: 0.1009 - val_accuracy: 0.9744 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0453 - accuracy: 0.9846 - val_loss: 0.1044 - val_accuracy: 0.9641 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 16s 71ms/step - loss: 0.9920 - accuracy: 0.8154 - val_loss: 0.2210 - val_accuracy: 0.9179 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1458 - accuracy: 0.9478 - val_loss: 0.1457 - val_accuracy: 0.9453 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1196 - accuracy: 0.9580 - val_loss: 0.1523 - val_accuracy: 0.9487 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1025 - accuracy: 0.9615 - val_loss: 0.1511 - val_accuracy: 0.9333 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0946 - accuracy: 0.9676 - val_loss: 0.1157 - val_accuracy: 0.9556 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0819 - accuracy: 0.9713 - val_loss: 0.1087 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0844 - accuracy: 0.9702 - val_loss: 0.1027 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0675 - accuracy: 0.9755\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0675 - accuracy: 0.9755 - val_loss: 0.1276 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0477 - accuracy: 0.9832 - val_loss: 0.1123 - val_accuracy: 0.9624 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0451 - accuracy: 0.9842 - val_loss: 0.0977 - val_accuracy: 0.9658 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 8s 45ms/step - loss: 0.6363 - accuracy: 0.7505 - val_loss: 0.2208 - val_accuracy: 0.9060 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1510 - accuracy: 0.9430 - val_loss: 0.1040 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1109 - accuracy: 0.9601 - val_loss: 0.1113 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1068 - accuracy: 0.9618 - val_loss: 0.1040 - val_accuracy: 0.9504 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0873 - accuracy: 0.9683\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0873 - accuracy: 0.9683 - val_loss: 0.0692 - val_accuracy: 0.9726 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0611 - accuracy: 0.9791 - val_loss: 0.0631 - val_accuracy: 0.9812 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0535 - accuracy: 0.9798 - val_loss: 0.0611 - val_accuracy: 0.9829 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0474 - accuracy: 0.9833 - val_loss: 0.0551 - val_accuracy: 0.9846 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0427 - accuracy: 0.9847 - val_loss: 0.0573 - val_accuracy: 0.9812 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0390 - accuracy: 0.9857\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0390 - accuracy: 0.9857 - val_loss: 0.0648 - val_accuracy: 0.9795 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 14s 66ms/step - loss: 1.0352 - accuracy: 0.6886 - val_loss: 0.2993 - val_accuracy: 0.8718 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1974 - accuracy: 0.9184 - val_loss: 0.2515 - val_accuracy: 0.9009 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1285 - accuracy: 0.9492 - val_loss: 0.1243 - val_accuracy: 0.9607 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 40ms/step - loss: 0.0974 - accuracy: 0.9666 - val_loss: 0.1398 - val_accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0835 - accuracy: 0.9696\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0835 - accuracy: 0.9696 - val_loss: 0.1102 - val_accuracy: 0.9556 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 40ms/step - loss: 0.0568 - accuracy: 0.9818 - val_loss: 0.0651 - val_accuracy: 0.9795 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 40ms/step - loss: 0.0501 - accuracy: 0.9810 - val_loss: 0.0665 - val_accuracy: 0.9744 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0449 - accuracy: 0.9846\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 40ms/step - loss: 0.0449 - accuracy: 0.9846 - val_loss: 0.0737 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 40ms/step - loss: 0.0356 - accuracy: 0.9871 - val_loss: 0.0615 - val_accuracy: 0.9761 - lr: 9.0000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0331 - accuracy: 0.9887\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0331 - accuracy: 0.9887 - val_loss: 0.0585 - val_accuracy: 0.9778 - lr: 9.0000e-05\n",
            "Best Accuracy at the generation 13: 99.54732060432434\n",
            "[[49 39 88  4 13 20]\n",
            " [45 53 86  9 15 19]\n",
            " [50 39 84  4 15 18]\n",
            " [49 39 89  6 13 18]\n",
            " [45 39 86  4 13 19]\n",
            " [49 41 86  4 13 20]\n",
            " [45 56 84  9 18 18]\n",
            " [53 39 89  4 17 18]\n",
            " [49 40 86  6 15 19]\n",
            " [45 40 88  4 13 19]]\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 39ms/step - loss: 0.6071 - accuracy: 0.7295 - val_loss: 0.2433 - val_accuracy: 0.9231 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.2598 - accuracy: 0.8902 - val_loss: 0.1153 - val_accuracy: 0.9607 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1289 - accuracy: 0.9512 - val_loss: 0.1358 - val_accuracy: 0.9726 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0869 - accuracy: 0.9690 - val_loss: 0.0952 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0792 - accuracy: 0.9696\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0792 - accuracy: 0.9696 - val_loss: 0.0927 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0527 - accuracy: 0.9813 - val_loss: 0.0763 - val_accuracy: 0.9812 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0448 - accuracy: 0.9843 - val_loss: 0.0746 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 0.9861\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0369 - accuracy: 0.9861 - val_loss: 0.0690 - val_accuracy: 0.9692 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0296 - accuracy: 0.9894 - val_loss: 0.0714 - val_accuracy: 0.9726 - lr: 9.0000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0291 - accuracy: 0.9901\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0291 - accuracy: 0.9901 - val_loss: 0.0649 - val_accuracy: 0.9726 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 42ms/step - loss: 0.8298 - accuracy: 0.6817 - val_loss: 0.3359 - val_accuracy: 0.8581 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1870 - accuracy: 0.9266 - val_loss: 0.1706 - val_accuracy: 0.9385 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1195 - accuracy: 0.9549 - val_loss: 0.1239 - val_accuracy: 0.9521 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 40ms/step - loss: 0.1911 - accuracy: 0.9352 - val_loss: 0.1574 - val_accuracy: 0.9436 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.1107 - accuracy: 0.9607\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1107 - accuracy: 0.9607 - val_loss: 0.1180 - val_accuracy: 0.9521 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0738 - accuracy: 0.9726 - val_loss: 0.0961 - val_accuracy: 0.9624 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0681 - accuracy: 0.9754 - val_loss: 0.0868 - val_accuracy: 0.9761 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0603 - accuracy: 0.9774 - val_loss: 0.0811 - val_accuracy: 0.9709 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0571 - accuracy: 0.9786\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0571 - accuracy: 0.9786 - val_loss: 0.0961 - val_accuracy: 0.9573 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0468 - accuracy: 0.9837 - val_loss: 0.0831 - val_accuracy: 0.9726 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 40ms/step - loss: 0.9365 - accuracy: 0.6478 - val_loss: 0.2910 - val_accuracy: 0.8718 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.3155 - accuracy: 0.8612 - val_loss: 0.3022 - val_accuracy: 0.8615 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.2241 - accuracy: 0.9073 - val_loss: 0.1761 - val_accuracy: 0.9453 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.1478 - accuracy: 0.9430 - val_loss: 0.1096 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0966 - accuracy: 0.9651 - val_loss: 0.0920 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0738 - accuracy: 0.9724\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0738 - accuracy: 0.9724 - val_loss: 0.0902 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0499 - accuracy: 0.9843 - val_loss: 0.0787 - val_accuracy: 0.9641 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0387 - accuracy: 0.9859 - val_loss: 0.0709 - val_accuracy: 0.9709 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0355 - accuracy: 0.9864 - val_loss: 0.0778 - val_accuracy: 0.9692 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 0.9883\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0324 - accuracy: 0.9883 - val_loss: 0.0745 - val_accuracy: 0.9641 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 38ms/step - loss: 0.6073 - accuracy: 0.7717 - val_loss: 0.3156 - val_accuracy: 0.8650 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.2181 - accuracy: 0.9195 - val_loss: 0.1205 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1142 - accuracy: 0.9593 - val_loss: 0.1412 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0897 - accuracy: 0.9697 - val_loss: 0.1142 - val_accuracy: 0.9607 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0880 - accuracy: 0.9686 - val_loss: 0.1381 - val_accuracy: 0.9521 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0721 - accuracy: 0.9760 - val_loss: 0.0713 - val_accuracy: 0.9795 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0681 - accuracy: 0.9752 - val_loss: 0.1353 - val_accuracy: 0.9556 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0555 - accuracy: 0.9802 - val_loss: 0.0652 - val_accuracy: 0.9812 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0445 - accuracy: 0.9832 - val_loss: 0.0665 - val_accuracy: 0.9761 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0403 - accuracy: 0.9843\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0403 - accuracy: 0.9843 - val_loss: 0.0814 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 36ms/step - loss: 0.7151 - accuracy: 0.7738 - val_loss: 0.2885 - val_accuracy: 0.8889 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1934 - accuracy: 0.9274 - val_loss: 0.1524 - val_accuracy: 0.9350 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.1738 - accuracy: 0.9335 - val_loss: 0.1730 - val_accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1344 - accuracy: 0.9532 - val_loss: 0.1185 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1093 - accuracy: 0.9615 - val_loss: 0.1169 - val_accuracy: 0.9504 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.1027 - accuracy: 0.9648\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1027 - accuracy: 0.9648 - val_loss: 0.1357 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0838 - accuracy: 0.9720 - val_loss: 0.0873 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0729 - accuracy: 0.9744 - val_loss: 0.0882 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0684 - accuracy: 0.9776\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0684 - accuracy: 0.9776 - val_loss: 0.0844 - val_accuracy: 0.9709 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0592 - accuracy: 0.9803 - val_loss: 0.0869 - val_accuracy: 0.9778 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 13s 60ms/step - loss: 0.8269 - accuracy: 0.6086 - val_loss: 0.4263 - val_accuracy: 0.8120 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.2967 - accuracy: 0.8757 - val_loss: 0.2384 - val_accuracy: 0.9128 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1995 - accuracy: 0.9209 - val_loss: 0.1584 - val_accuracy: 0.9402 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1286 - accuracy: 0.9528 - val_loss: 0.1029 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0925 - accuracy: 0.9644 - val_loss: 0.0887 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0829 - accuracy: 0.9711 - val_loss: 0.0800 - val_accuracy: 0.9846 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0653 - accuracy: 0.9785 - val_loss: 0.0670 - val_accuracy: 0.9778 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0558 - accuracy: 0.9816\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0558 - accuracy: 0.9816 - val_loss: 0.1368 - val_accuracy: 0.9419 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0336 - accuracy: 0.9897 - val_loss: 0.0644 - val_accuracy: 0.9744 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0245 - accuracy: 0.9925 - val_loss: 0.0469 - val_accuracy: 0.9863 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 17s 76ms/step - loss: 0.6828 - accuracy: 0.6434 - val_loss: 0.2882 - val_accuracy: 0.8872 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 5s 42ms/step - loss: 0.3086 - accuracy: 0.8683 - val_loss: 0.1745 - val_accuracy: 0.9487 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 5s 42ms/step - loss: 0.1809 - accuracy: 0.9287 - val_loss: 0.1438 - val_accuracy: 0.9470 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 5s 42ms/step - loss: 0.1009 - accuracy: 0.9646 - val_loss: 0.0828 - val_accuracy: 0.9761 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 5s 42ms/step - loss: 0.0785 - accuracy: 0.9713 - val_loss: 0.0607 - val_accuracy: 0.9778 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 5s 42ms/step - loss: 0.0691 - accuracy: 0.9768 - val_loss: 0.0817 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0653 - accuracy: 0.9744\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 5s 42ms/step - loss: 0.0653 - accuracy: 0.9744 - val_loss: 0.0871 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 5s 42ms/step - loss: 0.0392 - accuracy: 0.9859 - val_loss: 0.0591 - val_accuracy: 0.9812 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 5s 42ms/step - loss: 0.0266 - accuracy: 0.9897 - val_loss: 0.0752 - val_accuracy: 0.9778 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 0.9908\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 5s 42ms/step - loss: 0.0236 - accuracy: 0.9908 - val_loss: 0.0569 - val_accuracy: 0.9795 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 17s 75ms/step - loss: 1.3571 - accuracy: 0.7407 - val_loss: 0.3417 - val_accuracy: 0.8684 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.3324 - accuracy: 0.8542 - val_loss: 0.3033 - val_accuracy: 0.8564 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.2584 - accuracy: 0.8929 - val_loss: 0.2429 - val_accuracy: 0.8991 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1814 - accuracy: 0.9315 - val_loss: 0.1727 - val_accuracy: 0.9333 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1243 - accuracy: 0.9567 - val_loss: 0.1303 - val_accuracy: 0.9504 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1065 - accuracy: 0.9624 - val_loss: 0.1480 - val_accuracy: 0.9556 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0837 - accuracy: 0.9716 - val_loss: 0.0722 - val_accuracy: 0.9795 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0670 - accuracy: 0.9761 - val_loss: 0.0965 - val_accuracy: 0.9607 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0662 - accuracy: 0.9764 - val_loss: 0.0555 - val_accuracy: 0.9846 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0494 - accuracy: 0.9806 - val_loss: 0.0758 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 15s 67ms/step - loss: 1.1090 - accuracy: 0.6984 - val_loss: 0.2983 - val_accuracy: 0.8786 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.2325 - accuracy: 0.9110 - val_loss: 0.2271 - val_accuracy: 0.9111 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.1721 - accuracy: 0.9341 - val_loss: 0.1556 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.1302 - accuracy: 0.9542 - val_loss: 0.0937 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0901 - accuracy: 0.9679\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0901 - accuracy: 0.9679 - val_loss: 0.1085 - val_accuracy: 0.9607 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0650 - accuracy: 0.9775 - val_loss: 0.0752 - val_accuracy: 0.9829 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0565 - accuracy: 0.9805 - val_loss: 0.0655 - val_accuracy: 0.9846 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0511 - accuracy: 0.9816 - val_loss: 0.0639 - val_accuracy: 0.9846 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0457 - accuracy: 0.9851\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0457 - accuracy: 0.9851 - val_loss: 0.0692 - val_accuracy: 0.9812 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0364 - accuracy: 0.9877 - val_loss: 0.0641 - val_accuracy: 0.9812 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 12s 56ms/step - loss: 0.6429 - accuracy: 0.7072 - val_loss: 0.2310 - val_accuracy: 0.9231 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1733 - accuracy: 0.9308 - val_loss: 0.1313 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.1194 - accuracy: 0.9547 - val_loss: 0.1199 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0950 - accuracy: 0.9656 - val_loss: 0.0851 - val_accuracy: 0.9726 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0936 - accuracy: 0.9658 - val_loss: 0.0922 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0763 - accuracy: 0.9711 - val_loss: 0.1090 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0729 - accuracy: 0.9734\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0729 - accuracy: 0.9734 - val_loss: 0.1113 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0512 - accuracy: 0.9815 - val_loss: 0.0914 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0438 - accuracy: 0.9830\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0438 - accuracy: 0.9830 - val_loss: 0.0978 - val_accuracy: 0.9658 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0364 - accuracy: 0.9864 - val_loss: 0.0813 - val_accuracy: 0.9726 - lr: 9.0000e-05\n",
            "Best Accuracy at the generation 14: 99.54732060432434\n",
            "[[49 41 86  4 13 20]\n",
            " [45 56 84  9 18 18]\n",
            " [49 39 88  4 13 20]\n",
            " [50 39 84  4 15 18]\n",
            " [49 40 86  6 15 19]\n",
            " [49 41 86  4 16 18]\n",
            " [45 56 92  9 20 20]\n",
            " [54 39 84  6 13 18]\n",
            " [50 39 91  5 15 19]\n",
            " [49 40 88  8 15 20]]\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 38ms/step - loss: 0.8357 - accuracy: 0.6858 - val_loss: 0.2555 - val_accuracy: 0.8940 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1787 - accuracy: 0.9308 - val_loss: 0.1060 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1185 - accuracy: 0.9566 - val_loss: 0.1258 - val_accuracy: 0.9761 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0844 - accuracy: 0.9690 - val_loss: 0.0738 - val_accuracy: 0.9761 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0773 - accuracy: 0.9711 - val_loss: 0.0806 - val_accuracy: 0.9795 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0664 - accuracy: 0.9757 - val_loss: 0.0862 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0588 - accuracy: 0.9772\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0588 - accuracy: 0.9772 - val_loss: 0.0680 - val_accuracy: 0.9795 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0363 - accuracy: 0.9874 - val_loss: 0.0662 - val_accuracy: 0.9812 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0313 - accuracy: 0.9876 - val_loss: 0.0710 - val_accuracy: 0.9812 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0257 - accuracy: 0.9908 - val_loss: 0.0547 - val_accuracy: 0.9863 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 7s 46ms/step - loss: 1.0110 - accuracy: 0.5794 - val_loss: 0.4595 - val_accuracy: 0.8308 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 5s 43ms/step - loss: 0.2863 - accuracy: 0.8783 - val_loss: 0.3848 - val_accuracy: 0.8222 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 5s 43ms/step - loss: 0.2087 - accuracy: 0.9206 - val_loss: 0.2913 - val_accuracy: 0.9026 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 5s 43ms/step - loss: 0.1665 - accuracy: 0.9380 - val_loss: 0.1653 - val_accuracy: 0.9402 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 5s 43ms/step - loss: 0.1418 - accuracy: 0.9486 - val_loss: 0.1608 - val_accuracy: 0.9436 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 5s 43ms/step - loss: 0.1291 - accuracy: 0.9542 - val_loss: 0.1079 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 5s 43ms/step - loss: 0.1241 - accuracy: 0.9564 - val_loss: 0.1557 - val_accuracy: 0.9487 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.1086 - accuracy: 0.9607\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 5s 43ms/step - loss: 0.1086 - accuracy: 0.9607 - val_loss: 0.1175 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 5s 43ms/step - loss: 0.0871 - accuracy: 0.9690 - val_loss: 0.1069 - val_accuracy: 0.9624 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0835 - accuracy: 0.9696\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 5s 43ms/step - loss: 0.0835 - accuracy: 0.9696 - val_loss: 0.1084 - val_accuracy: 0.9607 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 38ms/step - loss: 0.8924 - accuracy: 0.5080 - val_loss: 0.6968 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.6929 - accuracy: 0.5165 - val_loss: 0.6999 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6927 - accuracy: 0.5165\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.6927 - accuracy: 0.5165 - val_loss: 0.7034 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.6927 - accuracy: 0.5165 - val_loss: 0.7040 - val_accuracy: 0.2701 - lr: 3.0000e-04\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6927 - accuracy: 0.5165\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.6927 - accuracy: 0.5165 - val_loss: 0.7046 - val_accuracy: 0.2701 - lr: 3.0000e-04\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7047 - val_accuracy: 0.2701 - lr: 9.0000e-05\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.5165\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7048 - val_accuracy: 0.2701 - lr: 9.0000e-05\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7048 - val_accuracy: 0.2701 - lr: 2.7000e-05\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.5165\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7048 - val_accuracy: 0.2701 - lr: 2.7000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7049 - val_accuracy: 0.2701 - lr: 8.1000e-06\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 40ms/step - loss: 0.8670 - accuracy: 0.6596 - val_loss: 0.3685 - val_accuracy: 0.8359 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.2504 - accuracy: 0.8973 - val_loss: 0.1727 - val_accuracy: 0.9521 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1596 - accuracy: 0.9445 - val_loss: 0.1206 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1235 - accuracy: 0.9540 - val_loss: 0.0931 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0922 - accuracy: 0.9656\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0922 - accuracy: 0.9656 - val_loss: 0.0999 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0660 - accuracy: 0.9758 - val_loss: 0.0767 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0568 - accuracy: 0.9799 - val_loss: 0.0710 - val_accuracy: 0.9778 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0484 - accuracy: 0.9834 - val_loss: 0.0622 - val_accuracy: 0.9846 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0444 - accuracy: 0.9849 - val_loss: 0.0673 - val_accuracy: 0.9812 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0420 - accuracy: 0.9854\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0420 - accuracy: 0.9854 - val_loss: 0.0755 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 39ms/step - loss: 0.7000 - accuracy: 0.7215 - val_loss: 0.2337 - val_accuracy: 0.9043 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1712 - accuracy: 0.9402 - val_loss: 0.1390 - val_accuracy: 0.9419 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1291 - accuracy: 0.9547 - val_loss: 0.1448 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1063 - accuracy: 0.9622 - val_loss: 0.0955 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.1072 - accuracy: 0.9636\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1072 - accuracy: 0.9636 - val_loss: 0.1320 - val_accuracy: 0.9556 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0749 - accuracy: 0.9750 - val_loss: 0.0843 - val_accuracy: 0.9675 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0670 - accuracy: 0.9767 - val_loss: 0.0798 - val_accuracy: 0.9709 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0568 - accuracy: 0.9808 - val_loss: 0.0799 - val_accuracy: 0.9675 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0552 - accuracy: 0.9803 - val_loss: 0.0667 - val_accuracy: 0.9795 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0513 - accuracy: 0.9819 - val_loss: 0.0851 - val_accuracy: 0.9675 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 15s 69ms/step - loss: 1.1220 - accuracy: 0.5112 - val_loss: 0.7129 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.6928 - accuracy: 0.5165 - val_loss: 0.7068 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6928 - accuracy: 0.5165\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.6928 - accuracy: 0.5165 - val_loss: 0.7050 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.6927 - accuracy: 0.5165 - val_loss: 0.7050 - val_accuracy: 0.2701 - lr: 3.0000e-04\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6927 - accuracy: 0.5165\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.6927 - accuracy: 0.5165 - val_loss: 0.7040 - val_accuracy: 0.2701 - lr: 3.0000e-04\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7046 - val_accuracy: 0.2701 - lr: 9.0000e-05\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.5165\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7044 - val_accuracy: 0.2701 - lr: 9.0000e-05\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7045 - val_accuracy: 0.2701 - lr: 2.7000e-05\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.5165\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7047 - val_accuracy: 0.2701 - lr: 2.7000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7048 - val_accuracy: 0.2701 - lr: 8.1000e-06\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 21s 90ms/step - loss: 1.2210 - accuracy: 0.6261 - val_loss: 0.6412 - val_accuracy: 0.4718 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 5s 45ms/step - loss: 0.4796 - accuracy: 0.7564 - val_loss: 0.3489 - val_accuracy: 0.8427 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 5s 45ms/step - loss: 0.2883 - accuracy: 0.8793 - val_loss: 0.3241 - val_accuracy: 0.8598 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 5s 45ms/step - loss: 0.1880 - accuracy: 0.9279 - val_loss: 0.1643 - val_accuracy: 0.9453 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 5s 45ms/step - loss: 0.1383 - accuracy: 0.9489 - val_loss: 0.1332 - val_accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 5s 45ms/step - loss: 0.1148 - accuracy: 0.9605 - val_loss: 0.1186 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 5s 45ms/step - loss: 0.0987 - accuracy: 0.9663 - val_loss: 0.1525 - val_accuracy: 0.9436 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.1016 - accuracy: 0.9617\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 5s 45ms/step - loss: 0.1016 - accuracy: 0.9617 - val_loss: 0.1326 - val_accuracy: 0.9521 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 5s 45ms/step - loss: 0.0667 - accuracy: 0.9750 - val_loss: 0.0948 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 5s 45ms/step - loss: 0.0584 - accuracy: 0.9788 - val_loss: 0.0967 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 12s 56ms/step - loss: 0.9497 - accuracy: 0.7424 - val_loss: 0.3323 - val_accuracy: 0.8684 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.2050 - accuracy: 0.9189 - val_loss: 0.1419 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.1306 - accuracy: 0.9499 - val_loss: 0.1116 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0967 - accuracy: 0.9648 - val_loss: 0.0906 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0976 - accuracy: 0.9632\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0976 - accuracy: 0.9632 - val_loss: 0.1058 - val_accuracy: 0.9607 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0642 - accuracy: 0.9758 - val_loss: 0.0788 - val_accuracy: 0.9761 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0562 - accuracy: 0.9786 - val_loss: 0.0754 - val_accuracy: 0.9778 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0496 - accuracy: 0.9822 - val_loss: 0.0872 - val_accuracy: 0.9709 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0473 - accuracy: 0.9836\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0473 - accuracy: 0.9836 - val_loss: 0.0982 - val_accuracy: 0.9641 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0386 - accuracy: 0.9859 - val_loss: 0.0773 - val_accuracy: 0.9726 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 8s 46ms/step - loss: 1.2657 - accuracy: 0.7015 - val_loss: 0.3194 - val_accuracy: 0.8701 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.1688 - accuracy: 0.9380 - val_loss: 0.1141 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.1139 - accuracy: 0.9614 - val_loss: 0.0974 - val_accuracy: 0.9778 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0975 - accuracy: 0.9645 - val_loss: 0.1047 - val_accuracy: 0.9556 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0890 - accuracy: 0.9700\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0890 - accuracy: 0.9700 - val_loss: 0.1244 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0643 - accuracy: 0.9771 - val_loss: 0.0836 - val_accuracy: 0.9692 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0534 - accuracy: 0.9810\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0534 - accuracy: 0.9810 - val_loss: 0.0754 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0459 - accuracy: 0.9847 - val_loss: 0.0864 - val_accuracy: 0.9624 - lr: 9.0000e-05\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0439 - accuracy: 0.9840\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0439 - accuracy: 0.9840 - val_loss: 0.0916 - val_accuracy: 0.9590 - lr: 9.0000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0400 - accuracy: 0.9850 - val_loss: 0.0862 - val_accuracy: 0.9624 - lr: 2.7000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 11s 48ms/step - loss: 0.8424 - accuracy: 0.7592 - val_loss: 0.2191 - val_accuracy: 0.9248 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.1542 - accuracy: 0.9436 - val_loss: 0.1145 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.1116 - accuracy: 0.9569 - val_loss: 0.1260 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0913 - accuracy: 0.9660 - val_loss: 0.0891 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0801 - accuracy: 0.9714 - val_loss: 0.1134 - val_accuracy: 0.9607 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0676 - accuracy: 0.9772 - val_loss: 0.0899 - val_accuracy: 0.9761 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0704 - accuracy: 0.9750 - val_loss: 0.1004 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0636 - accuracy: 0.9758\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0636 - accuracy: 0.9758 - val_loss: 0.0888 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0364 - accuracy: 0.9867 - val_loss: 0.0795 - val_accuracy: 0.9692 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0306 - accuracy: 0.9887\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0306 - accuracy: 0.9887 - val_loss: 0.0826 - val_accuracy: 0.9675 - lr: 3.0000e-04\n",
            "Best Accuracy at the generation 15: 99.54732060432434\n",
            "[[49 41 86  4 13 20]\n",
            " [49 40 88  8 15 20]\n",
            " [54 39 84  6 13 18]\n",
            " [50 39 84  4 15 18]\n",
            " [50 39 91  5 15 19]\n",
            " [49 43 88  4 15 20]\n",
            " [50 40 84  8 18 18]\n",
            " [54 39 87  8 13 18]\n",
            " [50 41 91  5 15 19]\n",
            " [51 39 86  5 16 20]]\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 39ms/step - loss: 0.8646 - accuracy: 0.6858 - val_loss: 0.2790 - val_accuracy: 0.8906 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1957 - accuracy: 0.9246 - val_loss: 0.1336 - val_accuracy: 0.9504 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1225 - accuracy: 0.9537 - val_loss: 0.1349 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1012 - accuracy: 0.9628 - val_loss: 0.1305 - val_accuracy: 0.9470 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0896 - accuracy: 0.9656 - val_loss: 0.0831 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0745 - accuracy: 0.9743 - val_loss: 0.1052 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0756 - accuracy: 0.9728 - val_loss: 0.0864 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0610 - accuracy: 0.9784\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0610 - accuracy: 0.9784 - val_loss: 0.1018 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0383 - accuracy: 0.9860 - val_loss: 0.0725 - val_accuracy: 0.9709 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0336 - accuracy: 0.9883\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0336 - accuracy: 0.9883 - val_loss: 0.0659 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 40ms/step - loss: 1.0514 - accuracy: 0.5233 - val_loss: 0.7043 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.5945 - accuracy: 0.6841 - val_loss: 0.4075 - val_accuracy: 0.7983 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.2492 - accuracy: 0.8970 - val_loss: 0.2009 - val_accuracy: 0.9402 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.1352 - accuracy: 0.9505 - val_loss: 0.1152 - val_accuracy: 0.9521 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.1252 - accuracy: 0.9559 - val_loss: 0.1122 - val_accuracy: 0.9607 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.1141 - accuracy: 0.9586 - val_loss: 0.1443 - val_accuracy: 0.9470 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0987 - accuracy: 0.9632 - val_loss: 0.1133 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0847 - accuracy: 0.9699 - val_loss: 0.0991 - val_accuracy: 0.9607 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.2363 - accuracy: 0.9291\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.2363 - accuracy: 0.9291 - val_loss: 0.1405 - val_accuracy: 0.9470 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0933 - accuracy: 0.9660 - val_loss: 0.1282 - val_accuracy: 0.9573 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 39ms/step - loss: 0.6756 - accuracy: 0.7425 - val_loss: 0.3120 - val_accuracy: 0.8838 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1959 - accuracy: 0.9212 - val_loss: 0.1811 - val_accuracy: 0.9316 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1456 - accuracy: 0.9465 - val_loss: 0.1725 - val_accuracy: 0.9521 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1263 - accuracy: 0.9546 - val_loss: 0.1206 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1211 - accuracy: 0.9557 - val_loss: 0.1472 - val_accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1051 - accuracy: 0.9629 - val_loss: 0.1378 - val_accuracy: 0.9487 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.1027 - accuracy: 0.9621\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1027 - accuracy: 0.9621 - val_loss: 0.1431 - val_accuracy: 0.9521 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0783 - accuracy: 0.9730 - val_loss: 0.1067 - val_accuracy: 0.9573 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0718 - accuracy: 0.9737\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0718 - accuracy: 0.9737 - val_loss: 0.1122 - val_accuracy: 0.9573 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0651 - accuracy: 0.9772 - val_loss: 0.0988 - val_accuracy: 0.9624 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 41ms/step - loss: 0.9458 - accuracy: 0.6527 - val_loss: 0.3605 - val_accuracy: 0.8496 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.3200 - accuracy: 0.8673 - val_loss: 0.2966 - val_accuracy: 0.8615 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.2247 - accuracy: 0.9076 - val_loss: 0.1934 - val_accuracy: 0.9265 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1749 - accuracy: 0.9327 - val_loss: 0.1449 - val_accuracy: 0.9402 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1415 - accuracy: 0.9447 - val_loss: 0.1729 - val_accuracy: 0.9316 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.1304 - accuracy: 0.9478\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1304 - accuracy: 0.9478 - val_loss: 0.1622 - val_accuracy: 0.9333 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0952 - accuracy: 0.9659 - val_loss: 0.0963 - val_accuracy: 0.9692 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0866 - accuracy: 0.9686 - val_loss: 0.0969 - val_accuracy: 0.9658 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0755 - accuracy: 0.9730 - val_loss: 0.0852 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0721 - accuracy: 0.9738 - val_loss: 0.0820 - val_accuracy: 0.9692 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 41ms/step - loss: 1.4518 - accuracy: 0.6557 - val_loss: 0.3561 - val_accuracy: 0.8444 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.2801 - accuracy: 0.8857 - val_loss: 0.2058 - val_accuracy: 0.9299 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1753 - accuracy: 0.9361 - val_loss: 0.1312 - val_accuracy: 0.9607 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1348 - accuracy: 0.9496 - val_loss: 0.0825 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1072 - accuracy: 0.9610 - val_loss: 0.0857 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0856 - accuracy: 0.9700 - val_loss: 0.1043 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0864 - accuracy: 0.9659 - val_loss: 0.0814 - val_accuracy: 0.9761 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0806 - accuracy: 0.9711 - val_loss: 0.0767 - val_accuracy: 0.9726 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0621 - accuracy: 0.9762\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0621 - accuracy: 0.9762 - val_loss: 0.0888 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0418 - accuracy: 0.9857 - val_loss: 0.0619 - val_accuracy: 0.9795 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 15s 69ms/step - loss: 1.3882 - accuracy: 0.5148 - val_loss: 0.7019 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.6927 - accuracy: 0.5168 - val_loss: 0.6784 - val_accuracy: 0.4940 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.7209 - accuracy: 0.5336 - val_loss: 0.5691 - val_accuracy: 0.5709 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.4491 - accuracy: 0.7789 - val_loss: 0.2694 - val_accuracy: 0.8974 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.2264 - accuracy: 0.9092 - val_loss: 0.2239 - val_accuracy: 0.9077 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1754 - accuracy: 0.9337 - val_loss: 0.1585 - val_accuracy: 0.9453 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1326 - accuracy: 0.9506 - val_loss: 0.1320 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1046 - accuracy: 0.9617 - val_loss: 0.1152 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0899 - accuracy: 0.9670 - val_loss: 0.0758 - val_accuracy: 0.9778 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0776 - accuracy: 0.9718 - val_loss: 0.0801 - val_accuracy: 0.9761 - lr: 0.0010\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 20s 83ms/step - loss: 1.0715 - accuracy: 0.7138 - val_loss: 0.3375 - val_accuracy: 0.8274 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.2190 - accuracy: 0.9113 - val_loss: 0.2064 - val_accuracy: 0.9162 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1580 - accuracy: 0.9386 - val_loss: 0.1196 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1356 - accuracy: 0.9489 - val_loss: 0.1530 - val_accuracy: 0.9436 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1003 - accuracy: 0.9634 - val_loss: 0.0960 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0917 - accuracy: 0.9675 - val_loss: 0.1327 - val_accuracy: 0.9504 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0958 - accuracy: 0.9653\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0958 - accuracy: 0.9653 - val_loss: 0.0891 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0645 - accuracy: 0.9769 - val_loss: 0.0864 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0628 - accuracy: 0.9784 - val_loss: 0.1007 - val_accuracy: 0.9624 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0575 - accuracy: 0.9792\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0575 - accuracy: 0.9792 - val_loss: 0.1010 - val_accuracy: 0.9590 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 8s 45ms/step - loss: 0.7816 - accuracy: 0.6816 - val_loss: 0.3094 - val_accuracy: 0.8684 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.2244 - accuracy: 0.9129 - val_loss: 0.1750 - val_accuracy: 0.9385 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.1439 - accuracy: 0.9434 - val_loss: 0.1360 - val_accuracy: 0.9521 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0981 - accuracy: 0.9641 - val_loss: 0.0998 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0895 - accuracy: 0.9683 - val_loss: 0.0791 - val_accuracy: 0.9726 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0794 - accuracy: 0.9716 - val_loss: 0.1065 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0616 - accuracy: 0.9765 - val_loss: 0.0851 - val_accuracy: 0.9761 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0439 - accuracy: 0.9854 - val_loss: 0.0930 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0336 - accuracy: 0.9883\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0336 - accuracy: 0.9883 - val_loss: 0.0748 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 35ms/step - loss: 0.0190 - accuracy: 0.9946 - val_loss: 0.0678 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 15s 66ms/step - loss: 0.7399 - accuracy: 0.7377 - val_loss: 0.2401 - val_accuracy: 0.9026 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.2119 - accuracy: 0.9172 - val_loss: 0.1223 - val_accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.1429 - accuracy: 0.9451 - val_loss: 0.1449 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1038 - accuracy: 0.9598 - val_loss: 0.0764 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0909 - accuracy: 0.9683 - val_loss: 0.0996 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0814 - accuracy: 0.9699 - val_loss: 0.0954 - val_accuracy: 0.9607 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0738 - accuracy: 0.9733 - val_loss: 0.0798 - val_accuracy: 0.9726 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0651 - accuracy: 0.9776 - val_loss: 0.0931 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0585 - accuracy: 0.9784 - val_loss: 0.0563 - val_accuracy: 0.9829 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0518 - accuracy: 0.9822 - val_loss: 0.1210 - val_accuracy: 0.9504 - lr: 0.0010\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 17s 74ms/step - loss: 0.8473 - accuracy: 0.7315 - val_loss: 0.3411 - val_accuracy: 0.8479 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.2326 - accuracy: 0.9085 - val_loss: 0.1389 - val_accuracy: 0.9556 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1585 - accuracy: 0.9428 - val_loss: 0.1191 - val_accuracy: 0.9556 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1213 - accuracy: 0.9560 - val_loss: 0.1092 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0861 - accuracy: 0.9709 - val_loss: 0.0921 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0786 - accuracy: 0.9697 - val_loss: 0.1223 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0744 - accuracy: 0.9748\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0744 - accuracy: 0.9748 - val_loss: 0.1348 - val_accuracy: 0.9419 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0525 - accuracy: 0.9805 - val_loss: 0.0617 - val_accuracy: 0.9863 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0400 - accuracy: 0.9863 - val_loss: 0.0916 - val_accuracy: 0.9692 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0379 - accuracy: 0.9857\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0379 - accuracy: 0.9857 - val_loss: 0.0697 - val_accuracy: 0.9795 - lr: 3.0000e-04\n",
            "Best Accuracy at the generation 16: 99.54732060432434\n",
            "[[54 39 87  8 13 18]\n",
            " [49 41 86  4 13 20]\n",
            " [51 39 86  5 16 20]\n",
            " [50 39 91  5 15 19]\n",
            " [50 41 91  5 15 19]\n",
            " [54 39 90  8 14 20]\n",
            " [49 41 88  4 13 17]\n",
            " [51 39 93  5 18 19]\n",
            " [50 41 91  5 15 16]\n",
            " [50 45 87  5 15 19]]\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 38ms/step - loss: 0.6770 - accuracy: 0.6577 - val_loss: 0.2713 - val_accuracy: 0.8906 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.2100 - accuracy: 0.9168 - val_loss: 0.1687 - val_accuracy: 0.9402 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1431 - accuracy: 0.9465 - val_loss: 0.1473 - val_accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1309 - accuracy: 0.9508 - val_loss: 0.1497 - val_accuracy: 0.9504 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.1095 - accuracy: 0.9617\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1095 - accuracy: 0.9617 - val_loss: 0.1182 - val_accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0863 - accuracy: 0.9692 - val_loss: 0.1063 - val_accuracy: 0.9675 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0810 - accuracy: 0.9704 - val_loss: 0.1027 - val_accuracy: 0.9709 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0732 - accuracy: 0.9721 - val_loss: 0.1027 - val_accuracy: 0.9624 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0718 - accuracy: 0.9726\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0718 - accuracy: 0.9726 - val_loss: 0.0921 - val_accuracy: 0.9709 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0627 - accuracy: 0.9761 - val_loss: 0.0903 - val_accuracy: 0.9692 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 38ms/step - loss: 0.9491 - accuracy: 0.6332 - val_loss: 0.4670 - val_accuracy: 0.8085 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.2337 - accuracy: 0.9045 - val_loss: 0.1154 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1192 - accuracy: 0.9563 - val_loss: 0.1299 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0891 - accuracy: 0.9670\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0891 - accuracy: 0.9670 - val_loss: 0.1037 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0596 - accuracy: 0.9801 - val_loss: 0.1085 - val_accuracy: 0.9590 - lr: 3.0000e-04\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0532 - accuracy: 0.9816 - val_loss: 0.0786 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0497 - accuracy: 0.9826 - val_loss: 0.0824 - val_accuracy: 0.9675 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0402 - accuracy: 0.9864\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0402 - accuracy: 0.9864 - val_loss: 0.0904 - val_accuracy: 0.9658 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0322 - accuracy: 0.9877 - val_loss: 0.0894 - val_accuracy: 0.9675 - lr: 9.0000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 0.9915\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0292 - accuracy: 0.9915 - val_loss: 0.0851 - val_accuracy: 0.9709 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 42ms/step - loss: 0.8632 - accuracy: 0.7615 - val_loss: 0.1728 - val_accuracy: 0.9470 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1485 - accuracy: 0.9454 - val_loss: 0.1049 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1175 - accuracy: 0.9574 - val_loss: 0.1408 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0962 - accuracy: 0.9655 - val_loss: 0.0871 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0871 - accuracy: 0.9682 - val_loss: 0.1038 - val_accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0784 - accuracy: 0.9730 - val_loss: 0.0987 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0738 - accuracy: 0.9706 - val_loss: 0.1095 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0580 - accuracy: 0.9781 - val_loss: 0.0831 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0545 - accuracy: 0.9805 - val_loss: 0.1010 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0499 - accuracy: 0.9815\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0499 - accuracy: 0.9815 - val_loss: 0.0925 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 40ms/step - loss: 1.1700 - accuracy: 0.6901 - val_loss: 0.3043 - val_accuracy: 0.8547 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.3061 - accuracy: 0.8716 - val_loss: 0.2825 - val_accuracy: 0.8701 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.2245 - accuracy: 0.9089 - val_loss: 0.2022 - val_accuracy: 0.9333 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1583 - accuracy: 0.9395 - val_loss: 0.1672 - val_accuracy: 0.9350 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1285 - accuracy: 0.9528 - val_loss: 0.1527 - val_accuracy: 0.9385 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1154 - accuracy: 0.9542 - val_loss: 0.1055 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0926 - accuracy: 0.9659 - val_loss: 0.1224 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0750 - accuracy: 0.9733\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0750 - accuracy: 0.9733 - val_loss: 0.1211 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0516 - accuracy: 0.9832 - val_loss: 0.0896 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0414 - accuracy: 0.9859 - val_loss: 0.0678 - val_accuracy: 0.9778 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 41ms/step - loss: 0.9309 - accuracy: 0.6773 - val_loss: 0.3175 - val_accuracy: 0.8650 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.2193 - accuracy: 0.9134 - val_loss: 0.1149 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1374 - accuracy: 0.9488 - val_loss: 0.0892 - val_accuracy: 0.9880 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1014 - accuracy: 0.9624 - val_loss: 0.0928 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0853 - accuracy: 0.9676\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0853 - accuracy: 0.9676 - val_loss: 0.0854 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0593 - accuracy: 0.9781 - val_loss: 0.0826 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0510 - accuracy: 0.9820\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0510 - accuracy: 0.9820 - val_loss: 0.0544 - val_accuracy: 0.9863 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0411 - accuracy: 0.9871 - val_loss: 0.0692 - val_accuracy: 0.9778 - lr: 9.0000e-05\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0386 - accuracy: 0.9864\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0386 - accuracy: 0.9864 - val_loss: 0.0720 - val_accuracy: 0.9778 - lr: 9.0000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0359 - accuracy: 0.9887 - val_loss: 0.0722 - val_accuracy: 0.9761 - lr: 2.7000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 15s 67ms/step - loss: 0.7584 - accuracy: 0.6910 - val_loss: 0.4433 - val_accuracy: 0.8274 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.2559 - accuracy: 0.8987 - val_loss: 0.1981 - val_accuracy: 0.9333 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.1539 - accuracy: 0.9406 - val_loss: 0.1383 - val_accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.1031 - accuracy: 0.9615 - val_loss: 0.1344 - val_accuracy: 0.9436 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0860 - accuracy: 0.9680\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0860 - accuracy: 0.9680 - val_loss: 0.1250 - val_accuracy: 0.9504 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0620 - accuracy: 0.9789 - val_loss: 0.0788 - val_accuracy: 0.9692 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0517 - accuracy: 0.9801 - val_loss: 0.0799 - val_accuracy: 0.9675 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0404 - accuracy: 0.9847 - val_loss: 0.0754 - val_accuracy: 0.9709 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0350 - accuracy: 0.9867 - val_loss: 0.0934 - val_accuracy: 0.9658 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0323 - accuracy: 0.9880\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0323 - accuracy: 0.9880 - val_loss: 0.0931 - val_accuracy: 0.9607 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 8s 44ms/step - loss: 0.6769 - accuracy: 0.8039 - val_loss: 0.1463 - val_accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1393 - accuracy: 0.9495 - val_loss: 0.1131 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1181 - accuracy: 0.9608 - val_loss: 0.1309 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.1100 - accuracy: 0.9608\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1100 - accuracy: 0.9608 - val_loss: 0.1124 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0736 - accuracy: 0.9751 - val_loss: 0.1163 - val_accuracy: 0.9556 - lr: 3.0000e-04\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0661 - accuracy: 0.9791 - val_loss: 0.0800 - val_accuracy: 0.9709 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0638 - accuracy: 0.9775 - val_loss: 0.0935 - val_accuracy: 0.9658 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0556 - accuracy: 0.9812 - val_loss: 0.0778 - val_accuracy: 0.9744 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0539 - accuracy: 0.9823 - val_loss: 0.0706 - val_accuracy: 0.9778 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0482 - accuracy: 0.9834 - val_loss: 0.0749 - val_accuracy: 0.9761 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 20s 84ms/step - loss: 1.0266 - accuracy: 0.6807 - val_loss: 0.2867 - val_accuracy: 0.8564 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 5s 41ms/step - loss: 0.2876 - accuracy: 0.8751 - val_loss: 0.2583 - val_accuracy: 0.8769 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 40ms/step - loss: 0.2157 - accuracy: 0.9150 - val_loss: 0.1703 - val_accuracy: 0.9453 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 40ms/step - loss: 0.1385 - accuracy: 0.9518 - val_loss: 0.1754 - val_accuracy: 0.9214 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 40ms/step - loss: 0.1127 - accuracy: 0.9591 - val_loss: 0.1011 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 40ms/step - loss: 0.0875 - accuracy: 0.9677 - val_loss: 0.0831 - val_accuracy: 0.9761 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 40ms/step - loss: 0.0732 - accuracy: 0.9744 - val_loss: 0.1009 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0678 - accuracy: 0.9771\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 40ms/step - loss: 0.0678 - accuracy: 0.9771 - val_loss: 0.0822 - val_accuracy: 0.9726 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 40ms/step - loss: 0.0369 - accuracy: 0.9864 - val_loss: 0.0828 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0309 - accuracy: 0.9877\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 40ms/step - loss: 0.0309 - accuracy: 0.9877 - val_loss: 0.0716 - val_accuracy: 0.9761 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 8s 46ms/step - loss: 0.8037 - accuracy: 0.7022 - val_loss: 0.2085 - val_accuracy: 0.9214 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1967 - accuracy: 0.9250 - val_loss: 0.1125 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1368 - accuracy: 0.9479 - val_loss: 0.1251 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.1058 - accuracy: 0.9615 - val_loss: 0.0910 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0861 - accuracy: 0.9721\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0861 - accuracy: 0.9721 - val_loss: 0.1158 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0588 - accuracy: 0.9818 - val_loss: 0.0745 - val_accuracy: 0.9795 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0520 - accuracy: 0.9834 - val_loss: 0.0707 - val_accuracy: 0.9761 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0471 - accuracy: 0.9847\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0471 - accuracy: 0.9847 - val_loss: 0.0656 - val_accuracy: 0.9778 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0377 - accuracy: 0.9887 - val_loss: 0.0663 - val_accuracy: 0.9744 - lr: 9.0000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0338 - accuracy: 0.9900\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0338 - accuracy: 0.9900 - val_loss: 0.0720 - val_accuracy: 0.9692 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 15s 66ms/step - loss: 0.6729 - accuracy: 0.6987 - val_loss: 0.2560 - val_accuracy: 0.9197 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1550 - accuracy: 0.9399 - val_loss: 0.1691 - val_accuracy: 0.9333 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1190 - accuracy: 0.9577 - val_loss: 0.1379 - val_accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0965 - accuracy: 0.9669 - val_loss: 0.1171 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0880 - accuracy: 0.9699 - val_loss: 0.1422 - val_accuracy: 0.9436 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0774 - accuracy: 0.9726 - val_loss: 0.0846 - val_accuracy: 0.9812 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0774 - accuracy: 0.9733 - val_loss: 0.0824 - val_accuracy: 0.9761 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0649 - accuracy: 0.9771\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0649 - accuracy: 0.9771 - val_loss: 0.0942 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0438 - accuracy: 0.9843 - val_loss: 0.0813 - val_accuracy: 0.9692 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0382 - accuracy: 0.9880\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0382 - accuracy: 0.9880 - val_loss: 0.0774 - val_accuracy: 0.9692 - lr: 3.0000e-04\n",
            "Best Accuracy at the generation 17: 99.54732060432434\n",
            "[[49 41 86  4 13 20]\n",
            " [50 41 91  5 15 16]\n",
            " [50 41 91  5 15 19]\n",
            " [54 39 90  8 14 20]\n",
            " [50 45 87  5 15 19]\n",
            " [53 41 91  4 14 16]\n",
            " [54 41 91  5 16 19]\n",
            " [50 41 91  8 15 20]\n",
            " [54 44 87  8 14 20]\n",
            " [50 45 89  5 18 20]]\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 39ms/step - loss: 0.6343 - accuracy: 0.7861 - val_loss: 0.2971 - val_accuracy: 0.8803 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1643 - accuracy: 0.9368 - val_loss: 0.1421 - val_accuracy: 0.9487 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1255 - accuracy: 0.9546 - val_loss: 0.1499 - val_accuracy: 0.9487 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1120 - accuracy: 0.9587 - val_loss: 0.1232 - val_accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.1098 - accuracy: 0.9600 - val_loss: 0.1183 - val_accuracy: 0.9504 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0848 - accuracy: 0.9690 - val_loss: 0.1016 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0884 - accuracy: 0.9685 - val_loss: 0.1153 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0750 - accuracy: 0.9727\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0750 - accuracy: 0.9727 - val_loss: 0.0970 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0522 - accuracy: 0.9810 - val_loss: 0.0957 - val_accuracy: 0.9641 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 36ms/step - loss: 0.0504 - accuracy: 0.9812 - val_loss: 0.0771 - val_accuracy: 0.9761 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 41ms/step - loss: 0.9457 - accuracy: 0.5035 - val_loss: 0.6963 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.6929 - accuracy: 0.5165 - val_loss: 0.6995 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6927 - accuracy: 0.5165\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.6927 - accuracy: 0.5165 - val_loss: 0.7031 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.6927 - accuracy: 0.5165 - val_loss: 0.7038 - val_accuracy: 0.2701 - lr: 3.0000e-04\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6927 - accuracy: 0.5165\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.6927 - accuracy: 0.5165 - val_loss: 0.7044 - val_accuracy: 0.2701 - lr: 3.0000e-04\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7045 - val_accuracy: 0.2701 - lr: 9.0000e-05\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.5165\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7046 - val_accuracy: 0.2701 - lr: 9.0000e-05\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7046 - val_accuracy: 0.2701 - lr: 2.7000e-05\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.5165\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7047 - val_accuracy: 0.2701 - lr: 2.7000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7047 - val_accuracy: 0.2701 - lr: 8.1000e-06\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 42ms/step - loss: 0.8330 - accuracy: 0.6942 - val_loss: 0.2846 - val_accuracy: 0.8906 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1866 - accuracy: 0.9311 - val_loss: 0.1769 - val_accuracy: 0.9368 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1467 - accuracy: 0.9509 - val_loss: 0.1522 - val_accuracy: 0.9556 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1235 - accuracy: 0.9561 - val_loss: 0.1427 - val_accuracy: 0.9470 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.1125 - accuracy: 0.9625\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1125 - accuracy: 0.9625 - val_loss: 0.1335 - val_accuracy: 0.9504 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0812 - accuracy: 0.9721 - val_loss: 0.0965 - val_accuracy: 0.9744 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0775 - accuracy: 0.9726 - val_loss: 0.1013 - val_accuracy: 0.9709 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0710 - accuracy: 0.9744\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0710 - accuracy: 0.9744 - val_loss: 0.1042 - val_accuracy: 0.9675 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0623 - accuracy: 0.9782 - val_loss: 0.1087 - val_accuracy: 0.9675 - lr: 9.0000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0616 - accuracy: 0.9779\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0616 - accuracy: 0.9779 - val_loss: 0.0956 - val_accuracy: 0.9709 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 41ms/step - loss: 1.3642 - accuracy: 0.6690 - val_loss: 0.3459 - val_accuracy: 0.8376 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.1958 - accuracy: 0.9233 - val_loss: 0.1767 - val_accuracy: 0.9282 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.1409 - accuracy: 0.9485 - val_loss: 0.1840 - val_accuracy: 0.9350 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.1187 - accuracy: 0.9549 - val_loss: 0.1398 - val_accuracy: 0.9453 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0992 - accuracy: 0.9658 - val_loss: 0.1304 - val_accuracy: 0.9470 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0897 - accuracy: 0.9673 - val_loss: 0.1553 - val_accuracy: 0.9470 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0867 - accuracy: 0.9680\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0867 - accuracy: 0.9680 - val_loss: 0.1467 - val_accuracy: 0.9470 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0631 - accuracy: 0.9776 - val_loss: 0.1105 - val_accuracy: 0.9521 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0529 - accuracy: 0.9796 - val_loss: 0.1217 - val_accuracy: 0.9419 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.0486 - accuracy: 0.9829 - val_loss: 0.0961 - val_accuracy: 0.9624 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 42ms/step - loss: 0.6783 - accuracy: 0.7247 - val_loss: 0.3756 - val_accuracy: 0.8598 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1947 - accuracy: 0.9226 - val_loss: 0.1710 - val_accuracy: 0.9282 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1351 - accuracy: 0.9519 - val_loss: 0.1432 - val_accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.1219 - accuracy: 0.9544 - val_loss: 0.1326 - val_accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1303 - accuracy: 0.9542 - val_loss: 0.1111 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0927 - accuracy: 0.9683 - val_loss: 0.1188 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0837 - accuracy: 0.9697 - val_loss: 0.1134 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0761 - accuracy: 0.9726 - val_loss: 0.0989 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0661 - accuracy: 0.9768 - val_loss: 0.0755 - val_accuracy: 0.9778 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0673 - accuracy: 0.9781 - val_loss: 0.0817 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 12s 60ms/step - loss: 1.1701 - accuracy: 0.6881 - val_loss: 0.3742 - val_accuracy: 0.8615 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.2444 - accuracy: 0.9038 - val_loss: 0.1904 - val_accuracy: 0.9316 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1381 - accuracy: 0.9505 - val_loss: 0.1367 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0882 - accuracy: 0.9683 - val_loss: 0.1051 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0715 - accuracy: 0.9735 - val_loss: 0.0862 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0616 - accuracy: 0.9782 - val_loss: 0.0930 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0529 - accuracy: 0.9805 - val_loss: 0.0672 - val_accuracy: 0.9778 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0474 - accuracy: 0.9836 - val_loss: 0.0755 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0417 - accuracy: 0.9853\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0417 - accuracy: 0.9853 - val_loss: 0.0561 - val_accuracy: 0.9778 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0213 - accuracy: 0.9921 - val_loss: 0.0537 - val_accuracy: 0.9778 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 14s 66ms/step - loss: 1.0673 - accuracy: 0.7519 - val_loss: 0.3077 - val_accuracy: 0.8838 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 40ms/step - loss: 0.2070 - accuracy: 0.9196 - val_loss: 0.1289 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 40ms/step - loss: 0.1601 - accuracy: 0.9410 - val_loss: 0.1245 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 40ms/step - loss: 0.1193 - accuracy: 0.9566 - val_loss: 0.0810 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 40ms/step - loss: 0.1070 - accuracy: 0.9634 - val_loss: 0.0969 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0988 - accuracy: 0.9638\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 40ms/step - loss: 0.0988 - accuracy: 0.9638 - val_loss: 0.0922 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 40ms/step - loss: 0.0689 - accuracy: 0.9767 - val_loss: 0.0575 - val_accuracy: 0.9795 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 40ms/step - loss: 0.0594 - accuracy: 0.9812 - val_loss: 0.0714 - val_accuracy: 0.9761 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0517 - accuracy: 0.9834\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 40ms/step - loss: 0.0517 - accuracy: 0.9834 - val_loss: 0.0765 - val_accuracy: 0.9692 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 40ms/step - loss: 0.0440 - accuracy: 0.9856 - val_loss: 0.0749 - val_accuracy: 0.9692 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 9s 48ms/step - loss: 0.8986 - accuracy: 0.5083 - val_loss: 0.6990 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.6928 - accuracy: 0.5165 - val_loss: 0.7027 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6927 - accuracy: 0.5165\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.6927 - accuracy: 0.5165 - val_loss: 0.7063 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7068 - val_accuracy: 0.2701 - lr: 3.0000e-04\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.5165\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7072 - val_accuracy: 0.2701 - lr: 3.0000e-04\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7072 - val_accuracy: 0.2701 - lr: 9.0000e-05\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.5165\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7071 - val_accuracy: 0.2701 - lr: 9.0000e-05\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7072 - val_accuracy: 0.2701 - lr: 2.7000e-05\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.5165\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7072 - val_accuracy: 0.2701 - lr: 2.7000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 37ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7072 - val_accuracy: 0.2701 - lr: 8.1000e-06\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 15s 67ms/step - loss: 0.9327 - accuracy: 0.7039 - val_loss: 0.2830 - val_accuracy: 0.9128 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1657 - accuracy: 0.9370 - val_loss: 0.2184 - val_accuracy: 0.9094 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.1227 - accuracy: 0.9528 - val_loss: 0.1467 - val_accuracy: 0.9470 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0960 - accuracy: 0.9663 - val_loss: 0.0840 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0899 - accuracy: 0.9660 - val_loss: 0.0957 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0709 - accuracy: 0.9740 - val_loss: 0.0835 - val_accuracy: 0.9761 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 39ms/step - loss: 0.0699 - accuracy: 0.9774 - val_loss: 0.1041 - val_accuracy: 0.9726 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0597 - accuracy: 0.9776\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0597 - accuracy: 0.9776 - val_loss: 0.1289 - val_accuracy: 0.9607 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0407 - accuracy: 0.9846 - val_loss: 0.1009 - val_accuracy: 0.9692 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0361 - accuracy: 0.9861\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 4s 38ms/step - loss: 0.0361 - accuracy: 0.9861 - val_loss: 0.0839 - val_accuracy: 0.9709 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 20s 84ms/step - loss: 1.1490 - accuracy: 0.6937 - val_loss: 0.3224 - val_accuracy: 0.8838 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 5s 41ms/step - loss: 0.2663 - accuracy: 0.8908 - val_loss: 0.2099 - val_accuracy: 0.9060 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 5s 41ms/step - loss: 0.1934 - accuracy: 0.9242 - val_loss: 0.1385 - val_accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 5s 41ms/step - loss: 0.1541 - accuracy: 0.9434 - val_loss: 0.1464 - val_accuracy: 0.9436 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 5s 41ms/step - loss: 0.1283 - accuracy: 0.9553 - val_loss: 0.1066 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 5s 41ms/step - loss: 0.1074 - accuracy: 0.9602 - val_loss: 0.0820 - val_accuracy: 0.9812 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 5s 41ms/step - loss: 0.0952 - accuracy: 0.9629 - val_loss: 0.0974 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0819 - accuracy: 0.9713\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 5s 41ms/step - loss: 0.0819 - accuracy: 0.9713 - val_loss: 0.0954 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 5s 41ms/step - loss: 0.0554 - accuracy: 0.9808 - val_loss: 0.0879 - val_accuracy: 0.9607 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - ETA: 0s - loss: 0.0483 - accuracy: 0.9825\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 5s 41ms/step - loss: 0.0483 - accuracy: 0.9825 - val_loss: 0.0710 - val_accuracy: 0.9709 - lr: 3.0000e-04\n",
            "Best Accuracy at the generation 18: 99.54732060432434\n",
            "[[53 41 91  4 14 16]\n",
            " [54 44 87  8 14 20]\n",
            " [54 41 91  5 16 19]\n",
            " [54 39 90  8 14 20]\n",
            " [50 45 89  5 18 20]\n",
            " [58 41 87  4 14 19]\n",
            " [54 44 94 10 14 19]\n",
            " [54 41 92  6 16 20]\n",
            " [54 39 92 11 14 20]\n",
            " [50 46 91  5 18 19]]\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 6s 42ms/step - loss: 0.7326 - accuracy: 0.6855 - val_loss: 0.3527 - val_accuracy: 0.8308 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 9s 78ms/step - loss: 0.3026 - accuracy: 0.8687 - val_loss: 0.2633 - val_accuracy: 0.8940 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 9s 78ms/step - loss: 0.2270 - accuracy: 0.9061 - val_loss: 0.1646 - val_accuracy: 0.9453 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 9s 78ms/step - loss: 0.1621 - accuracy: 0.9385 - val_loss: 0.1068 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 9s 78ms/step - loss: 0.1343 - accuracy: 0.9495 - val_loss: 0.1129 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 9s 78ms/step - loss: 0.1018 - accuracy: 0.9638 - val_loss: 0.1021 - val_accuracy: 0.9726 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "110/111 [============================>.] - ETA: 0s - loss: 0.0824 - accuracy: 0.9703\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 9s 78ms/step - loss: 0.0830 - accuracy: 0.9700 - val_loss: 0.1068 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 9s 78ms/step - loss: 0.0588 - accuracy: 0.9798 - val_loss: 0.0738 - val_accuracy: 0.9812 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 9s 79ms/step - loss: 0.0468 - accuracy: 0.9843 - val_loss: 0.0852 - val_accuracy: 0.9641 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "110/111 [============================>.] - ETA: 0s - loss: 0.0444 - accuracy: 0.9831\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 9s 79ms/step - loss: 0.0442 - accuracy: 0.9832 - val_loss: 0.0575 - val_accuracy: 0.9795 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 11s 81ms/step - loss: 0.8935 - accuracy: 0.5956 - val_loss: 0.5237 - val_accuracy: 0.7932 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 9s 78ms/step - loss: 0.2951 - accuracy: 0.8775 - val_loss: 0.2269 - val_accuracy: 0.9077 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 9s 78ms/step - loss: 0.1519 - accuracy: 0.9424 - val_loss: 0.1191 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 9s 78ms/step - loss: 0.1059 - accuracy: 0.9611 - val_loss: 0.1097 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 9s 78ms/step - loss: 0.0836 - accuracy: 0.9699 - val_loss: 0.0776 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 9s 78ms/step - loss: 0.0727 - accuracy: 0.9726 - val_loss: 0.1326 - val_accuracy: 0.9726 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "110/111 [============================>.] - ETA: 0s - loss: 0.0684 - accuracy: 0.9764\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 9s 78ms/step - loss: 0.0692 - accuracy: 0.9761 - val_loss: 0.1028 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 9s 78ms/step - loss: 0.0456 - accuracy: 0.9844 - val_loss: 0.0889 - val_accuracy: 0.9675 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "110/111 [============================>.] - ETA: 0s - loss: 0.0371 - accuracy: 0.9874\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 9s 78ms/step - loss: 0.0370 - accuracy: 0.9874 - val_loss: 0.0893 - val_accuracy: 0.9692 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 9s 78ms/step - loss: 0.0330 - accuracy: 0.9874 - val_loss: 0.0703 - val_accuracy: 0.9761 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 12s 98ms/step - loss: 0.6850 - accuracy: 0.7662 - val_loss: 0.1807 - val_accuracy: 0.9333 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 11s 95ms/step - loss: 0.1636 - accuracy: 0.9403 - val_loss: 0.0829 - val_accuracy: 0.9829 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 10s 95ms/step - loss: 0.1129 - accuracy: 0.9615 - val_loss: 0.1105 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "110/111 [============================>.] - ETA: 0s - loss: 0.0935 - accuracy: 0.9695\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 11s 95ms/step - loss: 0.0932 - accuracy: 0.9696 - val_loss: 0.0750 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 10s 94ms/step - loss: 0.0686 - accuracy: 0.9769 - val_loss: 0.0831 - val_accuracy: 0.9692 - lr: 3.0000e-04\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 10s 94ms/step - loss: 0.0604 - accuracy: 0.9801 - val_loss: 0.0720 - val_accuracy: 0.9846 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 10s 95ms/step - loss: 0.0575 - accuracy: 0.9810 - val_loss: 0.0628 - val_accuracy: 0.9880 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 11s 95ms/step - loss: 0.0516 - accuracy: 0.9837 - val_loss: 0.0634 - val_accuracy: 0.9829 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "110/111 [============================>.] - ETA: 0s - loss: 0.0468 - accuracy: 0.9837\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 11s 95ms/step - loss: 0.0466 - accuracy: 0.9837 - val_loss: 0.0575 - val_accuracy: 0.9846 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 11s 95ms/step - loss: 0.0404 - accuracy: 0.9851 - val_loss: 0.0642 - val_accuracy: 0.9846 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 11s 80ms/step - loss: 0.8293 - accuracy: 0.5037 - val_loss: 0.6962 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 9s 77ms/step - loss: 0.6929 - accuracy: 0.5165 - val_loss: 0.6993 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "110/111 [============================>.] - ETA: 0s - loss: 0.6927 - accuracy: 0.5168\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 9s 77ms/step - loss: 0.6928 - accuracy: 0.5165 - val_loss: 0.7028 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 9s 77ms/step - loss: 0.6927 - accuracy: 0.5165 - val_loss: 0.7035 - val_accuracy: 0.2701 - lr: 3.0000e-04\n",
            "Epoch 5/10\n",
            "110/111 [============================>.] - ETA: 0s - loss: 0.6927 - accuracy: 0.5163\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 9s 77ms/step - loss: 0.6927 - accuracy: 0.5165 - val_loss: 0.7041 - val_accuracy: 0.2701 - lr: 3.0000e-04\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 9s 78ms/step - loss: 0.6927 - accuracy: 0.5165 - val_loss: 0.7043 - val_accuracy: 0.2701 - lr: 9.0000e-05\n",
            "Epoch 7/10\n",
            "110/111 [============================>.] - ETA: 0s - loss: 0.6926 - accuracy: 0.5172\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 9s 77ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7044 - val_accuracy: 0.2701 - lr: 9.0000e-05\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 9s 77ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7044 - val_accuracy: 0.2701 - lr: 2.7000e-05\n",
            "Epoch 9/10\n",
            "110/111 [============================>.] - ETA: 0s - loss: 0.6927 - accuracy: 0.5163\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "111/111 [==============================] - 9s 78ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7045 - val_accuracy: 0.2701 - lr: 2.7000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 9s 77ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7045 - val_accuracy: 0.2701 - lr: 8.1000e-06\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 16s 109ms/step - loss: 1.1378 - accuracy: 0.6461 - val_loss: 0.4924 - val_accuracy: 0.7966 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 12s 107ms/step - loss: 0.2448 - accuracy: 0.9004 - val_loss: 0.2090 - val_accuracy: 0.9214 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 12s 106ms/step - loss: 0.1479 - accuracy: 0.9460 - val_loss: 0.1380 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 12s 107ms/step - loss: 0.1165 - accuracy: 0.9595 - val_loss: 0.1167 - val_accuracy: 0.9556 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "110/111 [============================>.] - ETA: 0s - loss: 0.1361 - accuracy: 0.9526\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 12s 106ms/step - loss: 0.1357 - accuracy: 0.9528 - val_loss: 0.1336 - val_accuracy: 0.9487 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 12s 106ms/step - loss: 0.0926 - accuracy: 0.9682 - val_loss: 0.1118 - val_accuracy: 0.9590 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "110/111 [============================>.] - ETA: 0s - loss: 0.0813 - accuracy: 0.9717\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 12s 107ms/step - loss: 0.0814 - accuracy: 0.9716 - val_loss: 0.1001 - val_accuracy: 0.9607 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 12s 107ms/step - loss: 0.0689 - accuracy: 0.9761 - val_loss: 0.0882 - val_accuracy: 0.9675 - lr: 9.0000e-05\n",
            "Epoch 9/10\n",
            "110/111 [============================>.] - ETA: 0s - loss: 0.0677 - accuracy: 0.9763\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 12s 107ms/step - loss: 0.0674 - accuracy: 0.9764 - val_loss: 0.0981 - val_accuracy: 0.9658 - lr: 9.0000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 12s 107ms/step - loss: 0.0626 - accuracy: 0.9782 - val_loss: 0.0888 - val_accuracy: 0.9692 - lr: 2.7000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 19s 105ms/step - loss: 0.8186 - accuracy: 0.6800 - val_loss: 0.2835 - val_accuracy: 0.8667 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 8s 75ms/step - loss: 0.2532 - accuracy: 0.8949 - val_loss: 0.1246 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 8s 75ms/step - loss: 0.1272 - accuracy: 0.9546 - val_loss: 0.1125 - val_accuracy: 0.9812 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 8s 75ms/step - loss: 0.1019 - accuracy: 0.9608 - val_loss: 0.1225 - val_accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "110/111 [============================>.] - ETA: 0s - loss: 0.0874 - accuracy: 0.9676\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 8s 76ms/step - loss: 0.0871 - accuracy: 0.9677 - val_loss: 0.0916 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 8s 76ms/step - loss: 0.0654 - accuracy: 0.9757 - val_loss: 0.0703 - val_accuracy: 0.9761 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 8s 75ms/step - loss: 0.0592 - accuracy: 0.9779 - val_loss: 0.0693 - val_accuracy: 0.9829 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 8s 75ms/step - loss: 0.0512 - accuracy: 0.9802 - val_loss: 0.0679 - val_accuracy: 0.9744 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "110/111 [============================>.] - ETA: 0s - loss: 0.0468 - accuracy: 0.9830\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 8s 76ms/step - loss: 0.0467 - accuracy: 0.9830 - val_loss: 0.0712 - val_accuracy: 0.9812 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 8s 75ms/step - loss: 0.0399 - accuracy: 0.9861 - val_loss: 0.0679 - val_accuracy: 0.9761 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 14s 91ms/step - loss: 1.3237 - accuracy: 0.5619 - val_loss: 0.5542 - val_accuracy: 0.7299 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 9s 80ms/step - loss: 0.4102 - accuracy: 0.8218 - val_loss: 0.1916 - val_accuracy: 0.9265 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 9s 80ms/step - loss: 0.1608 - accuracy: 0.9379 - val_loss: 0.1456 - val_accuracy: 0.9385 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 9s 80ms/step - loss: 0.1011 - accuracy: 0.9631 - val_loss: 0.1165 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 9s 80ms/step - loss: 0.0808 - accuracy: 0.9696 - val_loss: 0.0973 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 9s 80ms/step - loss: 0.0701 - accuracy: 0.9752 - val_loss: 0.1230 - val_accuracy: 0.9504 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "110/111 [============================>.] - ETA: 0s - loss: 0.0593 - accuracy: 0.9787\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 9s 80ms/step - loss: 0.0602 - accuracy: 0.9782 - val_loss: 0.0991 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 9s 80ms/step - loss: 0.0393 - accuracy: 0.9861 - val_loss: 0.0843 - val_accuracy: 0.9675 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "110/111 [============================>.] - ETA: 0s - loss: 0.0347 - accuracy: 0.9874\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 9s 80ms/step - loss: 0.0346 - accuracy: 0.9874 - val_loss: 0.0797 - val_accuracy: 0.9675 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 9s 80ms/step - loss: 0.0268 - accuracy: 0.9902 - val_loss: 0.0711 - val_accuracy: 0.9709 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 15s 105ms/step - loss: 0.7294 - accuracy: 0.6674 - val_loss: 0.3073 - val_accuracy: 0.8701 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 10s 94ms/step - loss: 0.2678 - accuracy: 0.8895 - val_loss: 0.2351 - val_accuracy: 0.9214 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 10s 94ms/step - loss: 0.1923 - accuracy: 0.9270 - val_loss: 0.1588 - val_accuracy: 0.9607 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 10s 94ms/step - loss: 0.1100 - accuracy: 0.9617 - val_loss: 0.0882 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 10s 94ms/step - loss: 0.0862 - accuracy: 0.9696 - val_loss: 0.1204 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "110/111 [============================>.] - ETA: 0s - loss: 0.0751 - accuracy: 0.9734\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 10s 94ms/step - loss: 0.0750 - accuracy: 0.9734 - val_loss: 0.0913 - val_accuracy: 0.9607 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 10s 94ms/step - loss: 0.0470 - accuracy: 0.9825 - val_loss: 0.0594 - val_accuracy: 0.9812 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 10s 94ms/step - loss: 0.0375 - accuracy: 0.9863 - val_loss: 0.0689 - val_accuracy: 0.9709 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "110/111 [============================>.] - ETA: 0s - loss: 0.0319 - accuracy: 0.9881\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 10s 94ms/step - loss: 0.0318 - accuracy: 0.9881 - val_loss: 0.0596 - val_accuracy: 0.9795 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 10s 94ms/step - loss: 0.0247 - accuracy: 0.9919 - val_loss: 0.0595 - val_accuracy: 0.9778 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 13s 90ms/step - loss: 0.7886 - accuracy: 0.6295 - val_loss: 0.4728 - val_accuracy: 0.7949 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 9s 80ms/step - loss: 0.3772 - accuracy: 0.8416 - val_loss: 0.2673 - val_accuracy: 0.9026 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 9s 80ms/step - loss: 0.3288 - accuracy: 0.8785 - val_loss: 0.3347 - val_accuracy: 0.8889 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 9s 79ms/step - loss: 0.2424 - accuracy: 0.9271 - val_loss: 0.1896 - val_accuracy: 0.9231 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 9s 80ms/step - loss: 0.1044 - accuracy: 0.9614 - val_loss: 0.1210 - val_accuracy: 0.9521 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 9s 80ms/step - loss: 0.1065 - accuracy: 0.9608 - val_loss: 0.1479 - val_accuracy: 0.9470 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "110/111 [============================>.] - ETA: 0s - loss: 0.0896 - accuracy: 0.9666\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 9s 80ms/step - loss: 0.0902 - accuracy: 0.9665 - val_loss: 0.1348 - val_accuracy: 0.9504 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 9s 80ms/step - loss: 0.0505 - accuracy: 0.9834 - val_loss: 0.1015 - val_accuracy: 0.9573 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 9s 80ms/step - loss: 0.0392 - accuracy: 0.9856 - val_loss: 0.1065 - val_accuracy: 0.9641 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 9s 80ms/step - loss: 0.0363 - accuracy: 0.9864 - val_loss: 0.0983 - val_accuracy: 0.9675 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 27s 145ms/step - loss: 1.7108 - accuracy: 0.6414 - val_loss: 0.3222 - val_accuracy: 0.8889 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 11s 102ms/step - loss: 0.2425 - accuracy: 0.9051 - val_loss: 0.1176 - val_accuracy: 0.9778 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 11s 102ms/step - loss: 0.1378 - accuracy: 0.9509 - val_loss: 0.1224 - val_accuracy: 0.9556 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "110/111 [============================>.] - ETA: 0s - loss: 0.1125 - accuracy: 0.9598\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 11s 102ms/step - loss: 0.1121 - accuracy: 0.9600 - val_loss: 0.0930 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 11s 102ms/step - loss: 0.0883 - accuracy: 0.9682 - val_loss: 0.1039 - val_accuracy: 0.9573 - lr: 3.0000e-04\n",
            "Epoch 6/10\n",
            "110/111 [============================>.] - ETA: 0s - loss: 0.0799 - accuracy: 0.9724\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 11s 103ms/step - loss: 0.0798 - accuracy: 0.9724 - val_loss: 0.0978 - val_accuracy: 0.9573 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 11s 103ms/step - loss: 0.0728 - accuracy: 0.9735 - val_loss: 0.0798 - val_accuracy: 0.9778 - lr: 9.0000e-05\n",
            "Epoch 8/10\n",
            "110/111 [============================>.] - ETA: 0s - loss: 0.0725 - accuracy: 0.9751\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 11s 103ms/step - loss: 0.0725 - accuracy: 0.9751 - val_loss: 0.0856 - val_accuracy: 0.9692 - lr: 9.0000e-05\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 11s 103ms/step - loss: 0.0693 - accuracy: 0.9747 - val_loss: 0.0868 - val_accuracy: 0.9692 - lr: 2.7000e-05\n",
            "Epoch 10/10\n",
            "110/111 [============================>.] - ETA: 0s - loss: 0.0695 - accuracy: 0.9764\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "111/111 [==============================] - 11s 103ms/step - loss: 0.0693 - accuracy: 0.9765 - val_loss: 0.0894 - val_accuracy: 0.9641 - lr: 2.7000e-05\n",
            "Best Accuracy at the generation 19: 99.54732060432434\n",
            "[[54 41 92  6 16 20]\n",
            " [54 44 94 10 14 19]\n",
            " [54 44 87  8 14 20]\n",
            " [54 39 92 11 14 20]\n",
            " [58 41 87  4 14 19]\n",
            " [54 45 94  9 16 19]\n",
            " [54 44 88 10 14 19]\n",
            " [54 46 92  8 15 20]\n",
            " [54 39 90 12 14 19]\n",
            " [58 46 92  4 14 18]]\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 12s 98ms/step - loss: 0.9814 - accuracy: 0.6315 - val_loss: 0.4434 - val_accuracy: 0.8256 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 11s 95ms/step - loss: 0.3133 - accuracy: 0.8735 - val_loss: 0.3326 - val_accuracy: 0.8752 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 11s 95ms/step - loss: 0.1767 - accuracy: 0.9298 - val_loss: 0.1694 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 11s 95ms/step - loss: 0.1227 - accuracy: 0.9540 - val_loss: 0.1798 - val_accuracy: 0.9333 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "110/111 [============================>.] - ETA: 0s - loss: 0.0973 - accuracy: 0.9673\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 11s 95ms/step - loss: 0.0971 - accuracy: 0.9673 - val_loss: 0.1754 - val_accuracy: 0.9179 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 11s 95ms/step - loss: 0.0693 - accuracy: 0.9758 - val_loss: 0.0896 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 11s 95ms/step - loss: 0.0571 - accuracy: 0.9791 - val_loss: 0.0778 - val_accuracy: 0.9744 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 11s 95ms/step - loss: 0.0518 - accuracy: 0.9796 - val_loss: 0.0851 - val_accuracy: 0.9709 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 11s 95ms/step - loss: 0.0462 - accuracy: 0.9826 - val_loss: 0.0863 - val_accuracy: 0.9761 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 11s 95ms/step - loss: 0.0453 - accuracy: 0.9833 - val_loss: 0.0742 - val_accuracy: 0.9726 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 11s 84ms/step - loss: 0.7969 - accuracy: 0.6316 - val_loss: 0.4183 - val_accuracy: 0.8085 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 9s 81ms/step - loss: 0.1790 - accuracy: 0.9270 - val_loss: 0.1263 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 9s 81ms/step - loss: 0.1156 - accuracy: 0.9570 - val_loss: 0.1283 - val_accuracy: 0.9607 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 9s 81ms/step - loss: 0.1657 - accuracy: 0.9414 - val_loss: 0.1960 - val_accuracy: 0.9214 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "110/111 [============================>.] - ETA: 0s - loss: 0.1148 - accuracy: 0.9587\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 9s 81ms/step - loss: 0.1146 - accuracy: 0.9587 - val_loss: 0.1227 - val_accuracy: 0.9556 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 9s 81ms/step - loss: 0.0785 - accuracy: 0.9728 - val_loss: 0.1151 - val_accuracy: 0.9624 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 9s 81ms/step - loss: 0.0744 - accuracy: 0.9731 - val_loss: 0.1379 - val_accuracy: 0.9487 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "110/111 [============================>.] - ETA: 0s - loss: 0.0632 - accuracy: 0.9784\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 9s 81ms/step - loss: 0.0632 - accuracy: 0.9784 - val_loss: 0.1128 - val_accuracy: 0.9607 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 9s 80ms/step - loss: 0.0571 - accuracy: 0.9805 - val_loss: 0.1015 - val_accuracy: 0.9692 - lr: 9.0000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 9s 80ms/step - loss: 0.0511 - accuracy: 0.9819 - val_loss: 0.1023 - val_accuracy: 0.9641 - lr: 9.0000e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 11s 81ms/step - loss: 1.2457 - accuracy: 0.5145 - val_loss: 0.6986 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 9s 78ms/step - loss: 0.6928 - accuracy: 0.5165 - val_loss: 0.7021 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "110/111 [============================>.] - ETA: 0s - loss: 0.6927 - accuracy: 0.5168\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 9s 78ms/step - loss: 0.6927 - accuracy: 0.5165 - val_loss: 0.7058 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 9s 78ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7063 - val_accuracy: 0.2701 - lr: 3.0000e-04\n",
            "Epoch 5/10\n",
            "110/111 [============================>.] - ETA: 0s - loss: 0.6926 - accuracy: 0.5163\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 9s 78ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7067 - val_accuracy: 0.2701 - lr: 3.0000e-04\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 9s 78ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7068 - val_accuracy: 0.2701 - lr: 9.0000e-05\n",
            "Epoch 7/10\n",
            "110/111 [============================>.] - ETA: 0s - loss: 0.6926 - accuracy: 0.5172\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 9s 78ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7068 - val_accuracy: 0.2701 - lr: 9.0000e-05\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 9s 78ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7068 - val_accuracy: 0.2701 - lr: 2.7000e-05\n",
            "Epoch 9/10\n",
            "110/111 [============================>.] - ETA: 0s - loss: 0.6926 - accuracy: 0.5163\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "111/111 [==============================] - 9s 78ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7068 - val_accuracy: 0.2701 - lr: 2.7000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 9s 78ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7068 - val_accuracy: 0.2701 - lr: 8.1000e-06\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 11s 83ms/step - loss: 0.7797 - accuracy: 0.5030 - val_loss: 0.7006 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 9s 79ms/step - loss: 0.6928 - accuracy: 0.5165 - val_loss: 0.7060 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "110/111 [============================>.] - ETA: 0s - loss: 0.6933 - accuracy: 0.5162\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 9s 79ms/step - loss: 0.6933 - accuracy: 0.5159 - val_loss: 0.7035 - val_accuracy: 0.2701 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 9s 80ms/step - loss: 0.6927 - accuracy: 0.5165 - val_loss: 0.7048 - val_accuracy: 0.2701 - lr: 3.0000e-04\n",
            "Epoch 5/10\n",
            "110/111 [============================>.] - ETA: 0s - loss: 0.6927 - accuracy: 0.5163\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "111/111 [==============================] - 9s 80ms/step - loss: 0.6927 - accuracy: 0.5165 - val_loss: 0.7047 - val_accuracy: 0.2701 - lr: 3.0000e-04\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 9s 79ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7052 - val_accuracy: 0.2701 - lr: 9.0000e-05\n",
            "Epoch 7/10\n",
            "110/111 [============================>.] - ETA: 0s - loss: 0.6926 - accuracy: 0.5172\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "111/111 [==============================] - 9s 80ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7051 - val_accuracy: 0.2701 - lr: 9.0000e-05\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 9s 79ms/step - loss: 0.6926 - accuracy: 0.5165 - val_loss: 0.7052 - val_accuracy: 0.2701 - lr: 2.7000e-05\n",
            "Epoch 9/10\n",
            "110/111 [============================>.] - ETA: 0s - loss: 0.6907 - accuracy: 0.5163\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "111/111 [==============================] - 9s 79ms/step - loss: 0.6907 - accuracy: 0.5165 - val_loss: 0.7368 - val_accuracy: 0.2701 - lr: 2.7000e-05\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 9s 79ms/step - loss: 0.6798 - accuracy: 0.5165 - val_loss: 0.7373 - val_accuracy: 0.2701 - lr: 8.1000e-06\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 10s 78ms/step - loss: 0.6929 - accuracy: 0.7510 - val_loss: 0.2650 - val_accuracy: 0.9077 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 14s 124ms/step - loss: 0.1736 - accuracy: 0.9339 - val_loss: 0.1754 - val_accuracy: 0.9282 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 14s 124ms/step - loss: 0.1262 - accuracy: 0.9569 - val_loss: 0.1382 - val_accuracy: 0.9556 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 14s 124ms/step - loss: 0.1159 - accuracy: 0.9574 - val_loss: 0.1306 - val_accuracy: 0.9521 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 14s 124ms/step - loss: 0.1150 - accuracy: 0.9588 - val_loss: 0.1081 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 14s 124ms/step - loss: 0.0905 - accuracy: 0.9693 - val_loss: 0.1274 - val_accuracy: 0.9487 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 14s 124ms/step - loss: 0.0863 - accuracy: 0.9692 - val_loss: 0.1272 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 14s 124ms/step - loss: 0.0746 - accuracy: 0.9731 - val_loss: 0.1071 - val_accuracy: 0.9607 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "110/111 [============================>.] - ETA: 0s - loss: 0.0621 - accuracy: 0.9781\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "111/111 [==============================] - 14s 123ms/step - loss: 0.0618 - accuracy: 0.9782 - val_loss: 0.0793 - val_accuracy: 0.9726 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 14s 124ms/step - loss: 0.0457 - accuracy: 0.9827 - val_loss: 0.0733 - val_accuracy: 0.9761 - lr: 3.0000e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 25s 146ms/step - loss: 0.6951 - accuracy: 0.7208 - val_loss: 0.2380 - val_accuracy: 0.9026 - lr: 0.0010\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "Graph execution error:\n\nDetected at node gradient_tape/cnn_205/conv2d_616/Conv2D/Conv2DBackpropInput defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 250, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 748, in __init__\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-22-f68f58fdd20f>\", line 9, in <cell line: 7>\n\n  File \"<ipython-input-20-fa3d34b1078e>\", line 119, in fitness\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1154, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\", line 543, in minimize\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\", line 276, in compute_gradients\n\nOOM when allocating tensor with shape[64,54,75,75] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/cnn_205/conv2d_616/Conv2D/Conv2DBackpropInput}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_1418703]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-f68f58fdd20f>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_generations\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mpop_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenCNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best Accuracy at the generation {}: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenCNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mparents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenCNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_parents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpop_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-fa3d34b1078e>\u001b[0m in \u001b[0;36mfitness\u001b[0;34m(self, pop, X, Y, epochs)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msfilters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mlearning_rate_reduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.000001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlearning_rate_reduction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mpop_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node gradient_tape/cnn_205/conv2d_616/Conv2D/Conv2DBackpropInput defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 250, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 748, in __init__\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-22-f68f58fdd20f>\", line 9, in <cell line: 7>\n\n  File \"<ipython-input-20-fa3d34b1078e>\", line 119, in fitness\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1154, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\", line 543, in minimize\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\", line 276, in compute_gradients\n\nOOM when allocating tensor with shape[64,54,75,75] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/cnn_205/conv2d_616/Conv2D/Conv2DBackpropInput}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_1418703]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "genCNN.smooth_curve(0.5,num_generations)"
      ],
      "metadata": {
        "id": "JtSc49f0y-63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "a0da21c5-6d56-4895-b6d4-68fd083a6863"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "x and y must have same first dimension, but have shapes (21,) and (20,)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-1e5e6287b52c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenCNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmooth_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_generations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-fa3d34b1078e>\u001b[0m in \u001b[0;36msmooth_curve\u001b[0;34m(self, factor, gen)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0msmoothed_points\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmoothed_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'g'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Smoothed training acc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2810\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2811\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2812\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   2813\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2814\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \"\"\"\n\u001b[1;32m   1687\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1689\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             yield from self._plot_args(\n\u001b[0m\u001b[1;32m    312\u001b[0m                 this, kwargs, ambiguous_fmt_datakey=ambiguous_fmt_datakey)\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    505\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    506\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (21,) and (20,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "genCNN.best_arch"
      ],
      "metadata": {
        "id": "9hzalxDzy-3i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b27ab102-2330-4c38-e987-a7f8919c0e37"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([45, 37, 85,  4, 10, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "genCNN.max_acc"
      ],
      "metadata": {
        "id": "BL0qywwAy-1K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6579cf88-5832-4e79-dc87-59534b184ce2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "99.54732060432434"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "genCNN.gen_acc"
      ],
      "metadata": {
        "id": "UI7XPPiHy-xx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4572c1d-06ea-44ad-dc97-b06b82c7410a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[99.17951822280884,\n",
              " 99.46244359016418,\n",
              " 99.17951822280884,\n",
              " 99.37756657600403,\n",
              " 99.4200050830841,\n",
              " 99.25024509429932,\n",
              " 99.25024509429932,\n",
              " 99.54732060432434,\n",
              " 99.0663468837738,\n",
              " 99.0663468837738,\n",
              " 99.46244359016418,\n",
              " 98.86829853057861,\n",
              " 99.53317046165466,\n",
              " 98.93903136253357,\n",
              " 99.25024509429932,\n",
              " 99.080491065979,\n",
              " 99.46244359016418,\n",
              " 99.15122389793396,\n",
              " 99.20780658721924,\n",
              " 99.19366240501404]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bestModelEachGeneration"
      ],
      "metadata": {
        "id": "0wsArZ-Yy-vK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71af09a0-0741-4919-c122-aa1697e135ea"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([40, 44, 84,  5, 13, 20]),\n",
              " array([44, 36, 84,  4,  8, 18]),\n",
              " array([44, 36, 84,  4,  8, 18]),\n",
              " array([44, 36, 84,  4,  8, 18]),\n",
              " array([44, 36, 84,  4,  8, 18]),\n",
              " array([44, 36, 84,  4,  8, 18]),\n",
              " array([44, 36, 84,  4,  8, 18]),\n",
              " array([45, 37, 85,  4, 10, 20]),\n",
              " array([45, 37, 85,  4, 10, 20]),\n",
              " array([45, 37, 85,  4, 10, 20]),\n",
              " array([45, 37, 85,  4, 10, 20]),\n",
              " array([45, 37, 85,  4, 10, 20]),\n",
              " array([45, 37, 85,  4, 10, 20]),\n",
              " array([45, 37, 85,  4, 10, 20]),\n",
              " array([45, 37, 85,  4, 10, 20]),\n",
              " array([45, 37, 85,  4, 10, 20]),\n",
              " array([45, 37, 85,  4, 10, 20]),\n",
              " array([45, 37, 85,  4, 10, 20]),\n",
              " array([45, 37, 85,  4, 10, 20]),\n",
              " array([45, 37, 85,  4, 10, 20])]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Next pop\n",
        "# for gen 11\n",
        "# array([[38, 47, 79,  4,  5, 13],\n",
        "#        [37, 47, 77,  4,  4, 11],\n",
        "#        [32, 52, 79,  4,  4, 12],\n",
        "#        [32, 47, 78,  4,  4,  6],\n",
        "#        [40, 51, 77,  5,  9, 11],\n",
        "#        [40, 47, 77,  4,  5, 13],\n",
        "#        [37, 47, 81,  7,  4, 12],\n",
        "#        [32, 52, 83,  4,  4,  7],\n",
        "#        [32, 47, 79,  7,  4, 11],\n",
        "#        [40, 51, 82,  5,  9, 14]])\n",
        "\n",
        "# for gen 21\n",
        "pop"
      ],
      "metadata": {
        "id": "UfFeS9SVy-sC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "190a8401-b7c0-4f26-b8f3-9826d4238654"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[54, 41, 92,  6, 16, 20],\n",
              "       [54, 44, 94, 10, 14, 19],\n",
              "       [54, 44, 87,  8, 14, 20],\n",
              "       [54, 39, 92, 11, 14, 20],\n",
              "       [58, 41, 87,  4, 14, 19],\n",
              "       [54, 45, 94,  9, 16, 19],\n",
              "       [54, 44, 88, 10, 14, 19],\n",
              "       [54, 46, 92,  8, 15, 20],\n",
              "       [54, 39, 90, 12, 14, 19],\n",
              "       [58, 46, 92,  4, 14, 18]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimized Model"
      ],
      "metadata": {
        "id": "XQS_gzj-zoWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bestParam = genCNN.best_arch\n",
        "# bestParam = [35, 64, 98,  7,  8, 17]\n",
        "# array([38, 47, 79,  4,  5, 13]) Gen 1 ~ 10\n",
        "# array([35, 64, 98,  7,  8, 17]) Gen 21 ~ 30\n",
        "bestParam"
      ],
      "metadata": {
        "id": "LX4Q1NGFzlky",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b22fac12-7954-40c0-8fc5-0d4c05b5014e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([45, 37, 85,  4, 10, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(bestParam[0] , (bestParam[3],bestParam[3]) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (150,150,1)))\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
        "\n",
        "model.add(Conv2D(bestParam[1] , (bestParam[4],bestParam[4]) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
        "\n",
        "model.add(Conv2D(bestParam[2] , (bestParam[5],bestParam[5]) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units = 128 , activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units = 1 , activation = 'sigmoid'))\n",
        "model.compile(optimizer = \"adam\" , loss = 'binary_crossentropy' , metrics = ['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "PHOJEycgzlhi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bcb1720-beb6-419f-bf65-19375239eed4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_618 (Conv2D)         (None, 150, 150, 45)      765       \n",
            "                                                                 \n",
            " max_pooling2d_618 (MaxPool  (None, 75, 75, 45)        0         \n",
            " ing2D)                                                          \n",
            "                                                                 \n",
            " conv2d_619 (Conv2D)         (None, 75, 75, 37)        166537    \n",
            "                                                                 \n",
            " dropout_618 (Dropout)       (None, 75, 75, 37)        0         \n",
            "                                                                 \n",
            " max_pooling2d_619 (MaxPool  (None, 38, 38, 37)        0         \n",
            " ing2D)                                                          \n",
            "                                                                 \n",
            " conv2d_620 (Conv2D)         (None, 38, 38, 85)        1258085   \n",
            "                                                                 \n",
            " dropout_619 (Dropout)       (None, 38, 38, 85)        0         \n",
            "                                                                 \n",
            " max_pooling2d_620 (MaxPool  (None, 19, 19, 85)        0         \n",
            " ing2D)                                                          \n",
            "                                                                 \n",
            " flatten_206 (Flatten)       (None, 30685)             0         \n",
            "                                                                 \n",
            " dense_412 (Dense)           (None, 128)               3927808   \n",
            "                                                                 \n",
            " dropout_620 (Dropout)       (None, 128)               0         \n",
            "                                                                 \n",
            " dense_413 (Dense)           (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5353324 (20.42 MB)\n",
            "Trainable params: 5353324 (20.42 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.3, min_lr=0.000001)"
      ],
      "metadata": {
        "id": "m2tJ8ptnzlea"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train,y_train, batch_size = 64 ,epochs = 10 , validation_data = [x_val, y_val] ,callbacks = [learning_rate_reduction])"
      ],
      "metadata": {
        "id": "YRnzh-eBzlbq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "66a31696-0579-4503-d2b4-a9a888aa1e1b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "Graph execution error:\n\nDetected at node sequential/conv2d_618/Relu defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-32-1a0b18bca590>\", line 1, in <cell line: 1>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1150, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/sequential.py\", line 398, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py\", line 321, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/activations.py\", line 306, in relu\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5395, in relu\n\nOOM when allocating tensor with shape[64,150,150,45] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node sequential/conv2d_618/Relu}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_1420978]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-1a0b18bca590>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlearning_rate_reduction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node sequential/conv2d_618/Relu defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-32-1a0b18bca590>\", line 1, in <cell line: 1>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1150, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/sequential.py\", line 398, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py\", line 321, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/activations.py\", line 306, in relu\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5395, in relu\n\nOOM when allocating tensor with shape[64,150,150,45] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node sequential/conv2d_618/Relu}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_1420978]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjust the range to match the number of epochs in your history data\n",
        "epochs = [i for i in range(len(history.history['accuracy']))]\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
        "\n",
        "train_acc = history.history['accuracy']\n",
        "train_loss = history.history['loss']\n",
        "val_acc = history.history['val_accuracy']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "ax[0].plot(epochs, train_acc, 'go-', label='Training Accuracy')\n",
        "ax[0].plot(epochs, val_acc, 'ro-', label='Validation Accuracy')\n",
        "ax[0].set_title('Training & Validation Accuracy')\n",
        "ax[0].legend()\n",
        "ax[0].set_xlabel(\"Epochs\")\n",
        "ax[0].set_ylabel(\"Accuracy\")\n",
        "\n",
        "ax[1].plot(epochs, train_loss, 'g-o', label='Training Loss')\n",
        "ax[1].plot(epochs, val_loss, 'r-o', label='Validation Loss')\n",
        "ax[1].set_title('Training & Validation Loss')\n",
        "ax[1].legend()\n",
        "ax[1].set_xlabel(\"Epochs\")\n",
        "ax[1].set_ylabel(\"Loss\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bNAedZ-Ky-pT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x_test)\n",
        "predictions = predictions.reshape(1,-1)[0]\n",
        "predictions[:15]"
      ],
      "metadata": {
        "id": "DjCaVYN-y-jL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming predictions are probabilities, convert them to binary labels\n",
        "binary_predictions = [1 if i > 0.5 else 0 for i in predictions]\n",
        "\n",
        "# Generate a classification report\n",
        "print(classification_report(y_test, binary_predictions, target_names=['Pneumonia (Class 0)', 'Normal (Class 1)']))\n"
      ],
      "metadata": {
        "id": "3f7K1GQxYPL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test,binary_predictions)\n",
        "cm"
      ],
      "metadata": {
        "id": "HNrdxZZ6YO9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = pd.DataFrame(cm , index = ['0','1'] , columns = ['0','1'])"
      ],
      "metadata": {
        "id": "rWd5175bzyJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10,10))\n",
        "sns.heatmap(cm,cmap= \"Blues\", linecolor = 'black' , linewidth = 1 , annot = True, fmt='',xticklabels = labels,yticklabels = labels)"
      ],
      "metadata": {
        "id": "gSK3mWofzyHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JFtRKM-4zyES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7VMycPpdzyBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qXm_Io4wzx-p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}